<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>MaxBill の博客</title>
  
  <subtitle>MaxBill个人博客</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.maxbill.cn/"/>
  <updated>2020-07-04T11:49:10.906Z</updated>
  <id>https://www.maxbill.cn/</id>
  
  <author>
    <name>MaxBill</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Java多线程之volatile关键字</title>
    <link href="https://www.maxbill.cn/3332402747.html"/>
    <id>https://www.maxbill.cn/3332402747.html</id>
    <published>2020-07-04T11:49:22.000Z</published>
    <updated>2020-07-04T11:49:10.906Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在java多线程并发编程中，为了解决多线程并发的问题，在语言内部引入了同步块和volatile关键字机制。volatile是java的一个类型修饰符，它被设计用来修饰被不同线程访问和修改的变量。被volatile关键字修饰的变量，线程在每次使用变量的时候，都会读取变量修改后的最新的值。</p><h2 id="volatile关键字的作用"><a href="#volatile关键字的作用" class="headerlink" title="volatile关键字的作用"></a>volatile关键字的作用</h2><h3 id="保证线程可见性"><a href="#保证线程可见性" class="headerlink" title="保证线程可见性"></a>保证线程可见性</h3><p>volatile保证线程可见性是指：被volatile修饰的变量在多线程情况下线程能够自动发现volatile变量的最新值。</p><p>为什么多线程之间共同访问的变量的值是相互不可见的？这就需要从JMM开始说起：在java内存模型中，每个线程都会被分配一个线程栈，如果对象是多线程间的共享资源时，当线程访问某一个对象值的时候，首先通过对象的引用找到对应在堆内存的变量的值，然后把堆内存变量的值load到线程栈中，建立一个变量副本，之后线程操作的都是副本变量，当修改完副本变量之后，会将值写回到主内存中。但由于线程栈是线程间相互隔离的，即多线程间不可见，如果有其他线程修改了这个变量，但还未写回到主内存中时，其他线程读取的仍是自己线程栈的副本时，就会出现数据不一致的问题。</p><p>下面我通过编码举个例子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.maxbill.thread.volatiles;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">VolatileTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Boolean val = <span class="keyword">true</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// private static volatile Boolean val = true;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">for</span> (; ; ) &#123;</span><br><span class="line">                <span class="keyword">if</span> (!val) <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(<span class="string">&quot;VAL当前的值 : &quot;</span> + val);</span><br><span class="line">        &#125;).start();</span><br><span class="line">        Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">        val = <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面这个程序是启动一个线程，当主线程修把变量val改为false后子线程会结束，否则子线程一直运行不退出，运行结果是：虽然主线程修改了值但是子线程无法感知到，还是一直在运行。解决方案就是给val变量加上volatile关键字，保证主线程修改了val后，子线程能读取到新值。</p><h3 id="禁止指令重排序"><a href="#禁止指令重排序" class="headerlink" title="禁止指令重排序"></a>禁止指令重排序</h3><p>volatile禁止指令重排序是指：volatile通过JVM的内存屏障，让多条指令顺序执行。</p><p>为什么cpu执行程序会对指令重新排序？因为在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。虽然代码顺序是有先后顺序，但真正执行时却不一定按照代码顺序执行。这样在多线程下就可能存在问题。另外指令重排序在实际下发生情况比较少，由于Java、CPU和内存之间都有一套严格的指令重排序规则，具体可参照JSR和JVM相关资料。重排序分三种类型：<br>1.编译器优化的重排序：编译器在不改变单线程程序语义的前提下，重新安排语句的执行顺序。<br>2.指令级并行的重排序：现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。<br>3.内存系统的重排序：由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。</p><h2 id="volatile关键字的底层"><a href="#volatile关键字的底层" class="headerlink" title="volatile关键字的底层"></a>volatile关键字的底层</h2><p>volatile关键字可以保证执行执行的可见性和顺序性，那它底层的实现是如何的？通过查看底层汇编代码，是通过给变量加上lock ，通过底层硬件的内存屏障实现指令的顺序执行，而且lock指令还可以强制把写缓冲区/高速缓存中的数据写回主内存，同时让其他cpu中对应的缓存行无效（MESI缓存一致性协议），这就保证了线程间数据的可见性。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#ifdef AMD64</span><br><span class="line">    __asm__ volatile (&quot;lock; addl $0,0(%%rsp)&quot; : : : &quot;cc&quot;, &quot;memory&quot;);</span><br><span class="line">#else</span><br><span class="line">    __asm__ volatile (&quot;lock; addl $0,0(%%esp)&quot; : : : &quot;cc&quot;, &quot;memory&quot;);</span><br><span class="line">#endif</span><br></pre></td></tr></table></figure><h2 id="volatile关键字的误区"><a href="#volatile关键字的误区" class="headerlink" title="volatile关键字的误区"></a>volatile关键字的误区</h2><p>volatile可以保证可见性和顺序性，但是不能保证原子性。即volatile并不能保证一个线程执行时操作该变量是一个原子操作，会被其他线程中断，引起数据不一致。</p><p>原子性是指这个操作是不可中断，要么全部执行成功要么全部执行失败，就算在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程所干扰。volatile并不能保证原子操作，例如i++操作时，分为Load、Increment、Store、Memory Barriers四个步骤，即装载、新增、存储和内存屏障四个步骤，第四步则是保证jvm让最新的变量值在所有线程可见，但从Load、Increment、到Store是不安全的，中间如果其他的CPU线程修改值将会存在问题。</p>]]></content>
    
    <summary type="html">
    
      Java多线程之volatile关键字
    
    </summary>
    
    
      <category term="学多线程" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
    
      <category term="Java" scheme="https://www.maxbill.cn/marks/Java/"/>
    
      <category term="volatile" scheme="https://www.maxbill.cn/marks/volatile/"/>
    
      <category term="多线程" scheme="https://www.maxbill.cn/marks/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>使用Hexo写第一篇文章</title>
    <link href="https://www.maxbill.cn/3439513514.html"/>
    <id>https://www.maxbill.cn/3439513514.html</id>
    <published>2020-01-20T02:07:20.000Z</published>
    <updated>2020-07-06T13:46:36.937Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>欢迎来到<a href="https://hexo.io/">Hexo</a>这是你的第一篇文章， 查看文档<a href="https://hexo.io/docs/">Hexo文档</a> 以获取更多信息。 如果你在使用Hexo时遇到任何问题，你可以在<a href="https://hexo.io/docs/troubleshooting.html">故障排除文档</a>中找到答案，或者也可以在<a href="https://github.com/hexojs/hexo/issues">GitHub</a>上咨询。</p><h3 id="建一篇新文章"><a href="#建一篇新文章" class="headerlink" title="建一篇新文章"></a>建一篇新文章</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;使用Hexo写第一篇文章&quot;</span></span><br></pre></td></tr></table></figure><p>更多信息: 请参考Hexo官网 <a href="https://hexo.io/docs/writing.html">Writing写作文档</a></p><h3 id="启动Hexo服务"><a href="#启动Hexo服务" class="headerlink" title="启动Hexo服务"></a>启动Hexo服务</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server (hexo s)</span><br></pre></td></tr></table></figure><p>更多信息: 请参考Hexo官网 <a href="https://hexo.io/docs/server.html">Server服务文档</a></p><h3 id="生成静态资源"><a href="#生成静态资源" class="headerlink" title="生成静态资源"></a>生成静态资源</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate (hexo g)</span><br></pre></td></tr></table></figure><p>更多信息: 请参考Hexo官网 <a href="https://hexo.io/docs/generating.html">Generating静态化文档</a></p><h3 id="远程部署站点"><a href="#远程部署站点" class="headerlink" title="远程部署站点"></a>远程部署站点</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy (hexo d)</span><br></pre></td></tr></table></figure><p>更多信息: 请参考Hexo官网 <a href="https://hexo.io/docs/one-command-deployment.html">Deployment部署文档</a></p>]]></content>
    
    <summary type="html">
    
      使用Hexo写第一篇文章
    
    </summary>
    
    
      <category term="建站过程" scheme="https://www.maxbill.cn/kinds/%E5%BB%BA%E7%AB%99%E8%BF%87%E7%A8%8B/"/>
    
    
      <category term="Hexo" scheme="https://www.maxbill.cn/marks/Hexo/"/>
    
      <category term="Hexo博客" scheme="https://www.maxbill.cn/marks/Hexo%E5%8D%9A%E5%AE%A2/"/>
    
  </entry>
  
  <entry>
    <title>分布式文件系统FastDFS安装部署(高可用)</title>
    <link href="https://www.maxbill.cn/4293262294.html"/>
    <id>https://www.maxbill.cn/4293262294.html</id>
    <published>2019-11-20T05:34:30.000Z</published>
    <updated>2020-03-07T08:03:19.434Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>本文会搭建一个适合低业务访问业务量的高可用的FastDFS集群环境：两个Tracker服务，一个storage group中两个storage服务节点；该方案仅适用于业务访问量较低的环境下。对于大量业务系统的高并发访问，为了保证存储系统正常工作一般的架构思路：安装多个Tracker服务(至少两个，根据业务量调整)，搭建多个storage group(至少两个，根据业务量调整)，每个storage group中多个storage node(至少两个，做数据的冗余备份，进行容灾机制，而且node必须在不同的机器上)</p><h2 id="FastDFS简介"><a href="#FastDFS简介" class="headerlink" title="FastDFS简介"></a><strong>FastDFS简介</strong></h2><p>FastDFS是一个开源的轻量级分布式文件系统，它对文件进行管理，功能包括：文件存储、文件同步、文件访问（文件上传、文件下载）等，解决了大容量存储和负载均衡的问题。特别适合以文件为载体的在线服务，如相册网站、视频网站等等。<br>FastDFS为互联网量身定制，充分考虑了冗余备份、负载均衡、线性扩容等机制，并注重高可用、高性能等指标，使用FastDFS很容易搭建一套高性能的文件服务器集群提供文件上传、下载等服务。FastDFS服务端有两个角色：跟踪器（tracker）和存储节点（storage）。跟踪器主要做调度工作，在访问上起负载均衡的作用。存储节点存储文件，完成文件管理的所有功能：就是这样的存储、同步和提供存取接口，FastDFS同时对文件的metadata进行管理。所谓文件的meta data就是文件的相关属性，以键值对（key value）方式表示，如：width=1024，其中的key为width，value为1024。文件metadata是文件属性列表，可以包含多个键值对。跟踪器和存储节点都可以由一台或多台服务器构成。跟踪器和存储节点中的服务器均可以随时增加或下线而不会影响线上服务。其中跟踪器中的所有服务器都是对等的，可以根据服务器的压力情况随时增加或减少。为了支持大容量，存储节点（服务器）采用了分卷（或分组）的组织方式。存储系统由一个或多个卷组成，卷与卷之间的文件是相互独立的，所有卷的文件容量累加就是整个存储系统中的文件容量。一个卷可以由一台或多台存储服务器组成，一个卷下的存储服务器中的文件都是相同的，卷中的多台存储服务器起到了冗余备份和负载均衡的作用。在卷中增加服务器时，同步已有的文件由系统自动完成，同步完成后，系统自动将新增服务器切换到线上提供服务。当存储空间不足或即将耗尽时，可以动态添加卷。只需要增加一台或多台服务器，并将它们配置为一个新的卷，这样就扩大了存储系统的容量。FastDFS中的文件标识分为两个部分：卷名和文件名，二者缺一不可。(简介摘自百度百科)</p><h2 id="FastDFS原理介绍"><a href="#FastDFS原理介绍" class="headerlink" title="FastDFS原理介绍"></a><strong>FastDFS原理介绍</strong></h2><h3 id="文件上传"><a href="#文件上传" class="headerlink" title="文件上传"></a>文件上传</h3><p>FastDFS以客户端库的方式提供基本的文件访问接口如upload、download、append、delete等，Storage 服务会定时的向Tracker服务发送自己的存储信息。当Tracker 服务集群中的Tracker 服务是多个时，各个Tracker服务之间的关系是对等的，因此客户端上传时会任意选择一个Trackre服务。当Tracker服务收到客户端上传文件请求时，会为该文件分配一个可以存储文件的group，当选定了group后就要决定给客户端分配group中的哪一个storage服务。当分配好storage 服务后，客户端向storage发送写文件请求，storage将会为文件分配一个数据存储目录。然后为文件分配一个文件ID标示，然后根据以上的信息生成文件名存储文件。</p><h3 id="文件同步"><a href="#文件同步" class="headerlink" title="文件同步"></a>文件同步</h3><p>上传文件后，客户端将文件写到group内的一个storage 服务即为上传文件成功，storage服务写完文件后，会由后台线程将文件同步至同group内的其他的storage 服务节点上。 每个storage服务写文件后，会同时写一份binlog，binlog里不包含文件数据，只包含文件名等元信息，这份binlog用于后台同步，storage会记录向group内其他storage同步的进度，以便重启后能接上次的进度继续同步；进度以时间戳的方式进行记录，所以最好能保证集群内的所有server的始终保持同步。最后Storage服务的同步进度会作为元数据的一部分汇报到tracker服务上，tracker服务在选择读storage的时候会以同步进度作为参考指标。</p><h3 id="下载文件"><a href="#下载文件" class="headerlink" title="下载文件"></a>下载文件</h3><p>当下载文件时，客户端先询问tracker服务下载文件的storage，参数为文件标识（卷名和文件名）；然后tracker向客户端返回一台可用的storage；最后客户端直接和storage通讯完成文件下载。</p><h2 id="部署环境准备"><a href="#部署环境准备" class="headerlink" title="部署环境准备"></a><strong>部署环境准备</strong></h2><h3 id="环境说明"><a href="#环境说明" class="headerlink" title="环境说明"></a>环境说明</h3><p>操作系统CentOS7.6<br>fastdfs版本：6.01<br>nginx版本：1.16.1<br>keepalived版本：2.0.19</p><h3 id="系统依赖"><a href="#系统依赖" class="headerlink" title="系统依赖"></a>系统依赖</h3><p>gcc gcc-c++ perl pcre pcre-devel zlib zlib-devel openssl openssl-devel libnl libnl-devel</p><h3 id="软件环境"><a href="#软件环境" class="headerlink" title="软件环境"></a>软件环境</h3><p>libevent下载地址：<a href="http://libevent.org/">http://libevent.org/</a><br>nginx下载地址：<a href="http://nginx.org/en/download.html">http://nginx.org/en/download.html</a><br>keepalived下载地址：<a href="https://www.keepalived.org/software/">https://www.keepalived.org/software/</a><br>fastdfs下载地址：<a href="https://github.com/happyfish100/fastdfs/releases">https://github.com/happyfish100/fastdfs/releases</a><br>libfasttcommon下载地址：<a href="https://github.com/happyfish100/libfastcommon/releases">https://github.com/happyfish100/libfastcommon/releases</a><br>fastdfs-nginx-module下载地址：<a href="https://github.com/happyfish100/fastdfs-nginx-module/releases">https://github.com/happyfish100/fastdfs-nginx-module/releases</a></p><h3 id="机器及网络环境规划"><a href="#机器及网络环境规划" class="headerlink" title="机器及网络环境规划"></a>机器及网络环境规划</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Fdfs Server VIP：         192.168.100.110</span><br><span class="line"></span><br><span class="line">Tracker Server1：         192.168.100.111</span><br><span class="line"></span><br><span class="line">Tracker Server2：         192.168.100.112</span><br><span class="line"></span><br><span class="line">Storage Group1 Node1：    192.168.100.111</span><br><span class="line"></span><br><span class="line">Storage Group1 Node2：    192.168.100.112</span><br></pre></td></tr></table></figure><h3 id="防火墙设置"><a href="#防火墙设置" class="headerlink" title="防火墙设置"></a>防火墙设置</h3><p>关闭系统防火墙：sudo systemctl stop firewalld &amp;&amp; systemctl disable firewalld</p><h2 id="Keepalived服务安装配置"><a href="#Keepalived服务安装配置" class="headerlink" title="Keepalived服务安装配置"></a><strong>Keepalived服务安装配置</strong></h2><h3 id="下载Keepalived源码包"><a href="#下载Keepalived源码包" class="headerlink" title="下载Keepalived源码包"></a>下载Keepalived源码包</h3><p>官网地址：<a href="https://www.keepalived.org/">https://www.keepalived.org/</a><br>下载地址：<a href="https://www.keepalived.org/software/keepalived-2.0.19.tar.gz">https://www.keepalived.org/software/keepalived-2.0.19.tar.gz</a></p><h3 id="上传并解压Keepalived源码包"><a href="#上传并解压Keepalived源码包" class="headerlink" title="上传并解压Keepalived源码包"></a>上传并解压Keepalived源码包</h3><p>tar -zxvf keepalived-2.0.19.tar.gz</p><h3 id="编译Keepalived准备"><a href="#编译Keepalived准备" class="headerlink" title="编译Keepalived准备"></a>编译Keepalived准备</h3><p>进入解压目录：cd keepalived-2.0.19<br>执行编译准备：./configure –prefix=/work/keepalived<br>注意：一定要有gcc和openssl编译相关的依赖</p><h3 id="编译安装Keepalived"><a href="#编译安装Keepalived" class="headerlink" title="编译安装Keepalived"></a>编译安装Keepalived</h3><p>make &amp;&amp; make install</p><h3 id="安装配置Keepalived"><a href="#安装配置Keepalived" class="headerlink" title="安装配置Keepalived"></a>安装配置Keepalived</h3><p>keepalived启动时会从/etc/keepalived/中相关的目录下查找keepalived.conf配置文件，因此将keepalived安装录/usr/local/keepalived/etc/keepalived.conf 拷贝到/etc/keepalived/中。<br>mkdir /etc/keepalived/<br>cp /work/keepalived/etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf<br>cp /work/keepalived/etc/sysconfig/keepalived /etc/sysconfig/keepalived</p><h3 id="设置Keepalived开机启动项"><a href="#设置Keepalived开机启动项" class="headerlink" title="设置Keepalived开机启动项"></a>设置Keepalived开机启动项</h3><p>systemctl enable keepalived<br>然后就能使用systemctl start/stop/status keepalived管理keepalived了</p><h3 id="配置Keepalived服务"><a href="#配置Keepalived服务" class="headerlink" title="配置Keepalived服务"></a>配置Keepalived服务</h3><p>192.168.100.111机器上配置：vi /etc/keepalived/keepalived.conf</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">vrrp_script check_nginx &#123;</span><br><span class="line">       interval 3</span><br><span class="line">       script &quot;/work/script/check_nginx.sh&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance fdfs_server &#123;</span><br><span class="line">       state MASTER</span><br><span class="line">       interface enp0s3</span><br><span class="line">       virtual_router_id 110</span><br><span class="line">       priority 100</span><br><span class="line">       advert_int 3</span><br><span class="line">       authentication &#123;</span><br><span class="line">            auth_type PASS</span><br><span class="line">            auth_pass password</span><br><span class="line">       &#125;</span><br><span class="line">       virtual_ipaddress &#123;</span><br><span class="line">            192.168.100.110</span><br><span class="line">       &#125;</span><br><span class="line">       track_script &#123;</span><br><span class="line">            check_nginx</span><br><span class="line">       &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>192.168.100.112机器上配置：vi /etc/keepalived/keepalived.conf</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">vrrp_script check_nginx &#123;</span><br><span class="line">       interval 3</span><br><span class="line">       script &quot;/work/script/check_nginx.sh&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance fdfs_server &#123;</span><br><span class="line">       state BACKUP</span><br><span class="line">       interface enp0s3</span><br><span class="line">       virtual_router_id 110</span><br><span class="line">       priority 90</span><br><span class="line">       advert_int 3</span><br><span class="line">       authentication &#123;</span><br><span class="line">            auth_type PASS</span><br><span class="line">            auth_pass password</span><br><span class="line">       &#125;</span><br><span class="line">       virtual_ipaddress &#123;</span><br><span class="line">            192.168.100.110</span><br><span class="line">       &#125;</span><br><span class="line">       track_script &#123;</span><br><span class="line">            check_nginx</span><br><span class="line">       &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="编写nginx服务检测脚本"><a href="#编写nginx服务检测脚本" class="headerlink" title="编写nginx服务检测脚本"></a>编写nginx服务检测脚本</h3><p>vi /work/script/check_nginx.sh</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">active_status=`netstat -lntp|grep nginx|wc -l`</span><br><span class="line">if [ $active_status -gt 0 ]; then</span><br><span class="line">    exit 0</span><br><span class="line">else</span><br><span class="line">    exit 1</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p>然后给脚本赋予执行权限：chmod +x /work/script/check_nginx.sh</p><h3 id="修改内核参数"><a href="#修改内核参数" class="headerlink" title="修改内核参数"></a>修改内核参数</h3><p>vi /etc/sysctl.conf<br>增加如下内容：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.ip_nonlocal_bind = 1  #允许忽视VIP的存在</span><br><span class="line">net.ipv4.ip_forward = 1  #允许转发</span><br></pre></td></tr></table></figure><p>sysctl –system 使配置生效</p><h2 id="安装FastDFS依赖库"><a href="#安装FastDFS依赖库" class="headerlink" title="安装FastDFS依赖库"></a><strong>安装FastDFS依赖库</strong></h2><h3 id="安装libevent依赖"><a href="#安装libevent依赖" class="headerlink" title="安装libevent依赖"></a>安装libevent依赖</h3><p>解压libevent源码包：tar -zxvf libevent-2.1.11-stable.tar.gz<br>进入源码目录：cd libevent-2.1.11-stable<br>编译安装前配置：./configure<br>编译安装：make &amp;&amp; make install<br>默认安装位置：/usr/local/lib</p><h3 id="安装libfasttcommon依赖"><a href="#安装libfasttcommon依赖" class="headerlink" title="安装libfasttcommon依赖"></a>安装libfasttcommon依赖</h3><p>解压libfasttcommon源码包：tar -zxvf libfastcommon-1.0.41.tar.gz<br>进入源码目录：cd libfastcommon-1.0.41<br>编译安装：./make.sh &amp;&amp; ./make.sh install<br>默认安装位置：/usr/lib64</p><h2 id="安装部署Tracker服务和Storage服务"><a href="#安装部署Tracker服务和Storage服务" class="headerlink" title="安装部署Tracker服务和Storage服务"></a><strong>安装部署Tracker服务和Storage服务</strong></h2><h3 id="安装fastdfs服务"><a href="#安装fastdfs服务" class="headerlink" title="安装fastdfs服务"></a>安装fastdfs服务</h3><p>解压fastdfs源码包：tar -zxvf fastdfs-6.01.tar.gz<br>进入fastdfs源码包：cd fastdfs-6.01<br>编译安装：./make.sh &amp;&amp; ./make.sh install</p><h3 id="fastdfs服务目录信息"><a href="#fastdfs服务目录信息" class="headerlink" title="fastdfs服务目录信息"></a>fastdfs服务目录信息</h3><p>安装完成后服务及脚本拷贝到/usr/bin 目录，配置文件拷贝到/etc/fdfs目录，启动脚本拷贝到/etc/init.d/目录</p><h3 id="注册开机启动"><a href="#注册开机启动" class="headerlink" title="注册开机启动"></a>注册开机启动</h3><p>chkconfig –add fdfs_trackerd<br>chkconfig fdfs_trackerd on<br>chkconfig –add fdfs_storaged<br>chkconfig fdfs_storaged on</p><h3 id="数据目录规划"><a href="#数据目录规划" class="headerlink" title="数据目录规划"></a>数据目录规划</h3><p>创建fdfs数据主目录：mkdir /work/fdfs<br>创建tracker数据目录：mkdir /work/fdfs/tracker<br>创建storage数据目录：mkdir /work/fdfs/storage</p><h3 id="配置tracker服务"><a href="#配置tracker服务" class="headerlink" title="配置tracker服务"></a>配置tracker服务</h3><p>将/etc/fdfs目录下的tracker.conf.sample改为tracker.conf：mv tracker.conf.sample  tracker.conf修改内容如下：<br>将base_path=/home/yuqing/fastdfs 改为：/work/fdfs/tracker(该目录为上面定义创建)<br>启动Tracker服务：systemctl start fdfs_trackerd</p><h3 id="配置storage服务"><a href="#配置storage服务" class="headerlink" title="配置storage服务"></a>配置storage服务</h3><p>将/etc/fdfs目录下的storage.conf.sample改为storage.conf：mv storage.conf.sample storage.conf修改内容如下：<br>base_path=/home/yuqing/fastdfs 改为：base_path=/work/fdfs/storage(该目录为上面定义创建)<br>store_path0=/home/yuqing/fastdfs 改为：store_path0=/work/fdfs/storage(该目录为上面定义创建)<br>tracker_server=192.168.209.121:22122 改为：tracker_server=192.168.100.111:22122和tracker_server=192.168.100.112:22122<br>将/etc/fdfs/torage_ids.conf.sample 为storage_ids.conf，内容修改为当前group的storage节点信息：<br>100001    group1    192.168.100.111<br>100002    group1    192.168.100.112<br>启动Storage服务：systemctl start fdfs_storaged</p><h2 id="Nginx服务安装配置"><a href="#Nginx服务安装配置" class="headerlink" title="Nginx服务安装配置"></a><strong>Nginx服务安装配置</strong></h2><h3 id="下载Nginx源码包"><a href="#下载Nginx源码包" class="headerlink" title="下载Nginx源码包"></a>下载Nginx源码包</h3><p>官网地址：<a href="http://nginx.org/">http://nginx.org/</a><br>下载地址：<a href="http://nginx.org/en/download.html">http://nginx.org/en/download.html</a></p><h3 id="上传并解压Nginx源码包及fastdfs插件包"><a href="#上传并解压Nginx源码包及fastdfs插件包" class="headerlink" title="上传并解压Nginx源码包及fastdfs插件包"></a>上传并解压Nginx源码包及fastdfs插件包</h3><p>tar -zxvf nginx-1.16.1.tar.gz<br>tar -zxvf fastdfs-nginx-module-1.21.tar.gz</p><h3 id="编译Nginx准备"><a href="#编译Nginx准备" class="headerlink" title="编译Nginx准备"></a>编译Nginx准备</h3><p>进入解压目录：cd nginx-1.16.1<br>拷贝fastdfs插件包到nginx源码目录：mv ../fastdfs-nginx-module-1.21 .<br>执行编译准备：./configure –prefix=/work/nginx \–with-stream \–add-module=fastdfs-nginx-module-1.21/src<br>注意：一定要有gcc和openssl编译相关的依赖</p><h3 id="编译安装Nginx"><a href="#编译安装Nginx" class="headerlink" title="编译安装Nginx"></a>编译安装Nginx</h3><p>make &amp;&amp; make install</p><h3 id="注册到系统服务"><a href="#注册到系统服务" class="headerlink" title="注册到系统服务"></a>注册到系统服务</h3><p>vi /usr/lib/systemd/system/nginx.service</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=nginx</span><br><span class="line">Documentation=http://nginx.org/en/docs/</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=forking</span><br><span class="line">PIDFile=/work/nginx/logs/nginx.pid</span><br><span class="line">ExecStartPre=/work/nginx/sbin/nginx -t -c /work/nginx/conf/nginx.conf</span><br><span class="line">ExecStart=/work/nginx/sbin/nginx -c /work/nginx/conf/nginx.conf</span><br><span class="line">ExecReload=/bin/kill -s HUP $MAINPID</span><br><span class="line">ExecStop=/bin/kill -s QUIT $MAINPID</span><br><span class="line">PrivateTmp=true</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><h3 id="设置Nginx开机启动项"><a href="#设置Nginx开机启动项" class="headerlink" title="设置Nginx开机启动项"></a>设置Nginx开机启动项</h3><p>systemctl enable nginx<br>然后就能使用systemctl start/stop/status nginx管理nginx了</p><h3 id="修改Nginx配置"><a href="#修改Nginx配置" class="headerlink" title="修改Nginx配置"></a>修改Nginx配置</h3><p>vi /work/nginx/conf/nginx.conf</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">#user  nobody;</span><br><span class="line">worker_processes  1;</span><br><span class="line">#error_log  logs/error.log;</span><br><span class="line">#error_log  logs/error.log  notice;</span><br><span class="line">#error_log  logs/error.log  info;</span><br><span class="line">#pid        logs/nginx.pid;</span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections  1024;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">stream &#123;</span><br><span class="line"></span><br><span class="line">    upstream tracker &#123;</span><br><span class="line">         server 192.168.100.111:22122 weight=1 max_fails=2 fail_timeout=10s;</span><br><span class="line">         server 192.168.100.112:22122 weight=1 max_fails=2 fail_timeout=10s;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line">        listen       7777;</span><br><span class="line">        proxy_timeout 5m;</span><br><span class="line">        proxy_pass tracker;</span><br><span class="line">        proxy_connect_timeout 10s;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line"></span><br><span class="line">    include       mime.types;</span><br><span class="line">    default_type  application/octet-stream;</span><br><span class="line">    sendfile        on;</span><br><span class="line">    keepalive_timeout  65;</span><br><span class="line"></span><br><span class="line">    upstream storage &#123;</span><br><span class="line">         server 192.168.100.111:8888 weight=1 max_fails=2 fail_timeout=10s;</span><br><span class="line">         server 192.168.100.112:8888 weight=1 max_fails=2 fail_timeout=10s;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line">        listen       80;</span><br><span class="line">        server_name  localhost;</span><br><span class="line">        </span><br><span class="line">        location /group1 &#123;</span><br><span class="line">            proxy_pass         http://storage;</span><br><span class="line">            proxy_set_header   Host             $host;</span><br><span class="line">            proxy_set_header   X-Real-IP        $remote_addr;</span><br><span class="line">            proxy_set_header   X-Forwarded-For  $proxy_add_x_forwarded_for;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        error_page   500 502 503 504  /50x.html;</span><br><span class="line">        location = /50x.html &#123;</span><br><span class="line">            root   html;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line">        listen       8888;</span><br><span class="line">        server_name  localhost;</span><br><span class="line"></span><br><span class="line">        location / &#123;</span><br><span class="line">            alias /work/fdfs/storage/data/;</span><br><span class="line">            ngx_fastdfs_module;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="配置nginx的fdfs插件"><a href="#配置nginx的fdfs插件" class="headerlink" title="配置nginx的fdfs插件"></a>配置nginx的fdfs插件</h3><p>将/etc/fdfs下的http.conf.sample和mime.types.sample重命名为：http.conf和mime.types<br>将fastdfs-nginx-module-1.21/src下的mod_fastdfs.conf拷贝到/etc/fdfs下<br>修改mod_fastdfs.conf如下：<br>连接超时时间： connect_timeout=5<br>Tracker服务地址：tracker_server=192.168.100.111:22122  和tracker_server=192.168.100.112:22122<br>Storage服务端口：storage\server_port=23000<br>如果文件ID的uri中包含/group**，则要设置为true：url_have_group_name = true<br>Storage配置的store_path0路径，必须和storage.conf中的一致：store_path0=/work/fdfs/storage<br>其他详细配置如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"># connect timeout in seconds</span><br><span class="line"># default value is 30s</span><br><span class="line">connect_timeout=5</span><br><span class="line"></span><br><span class="line"># network recv and send timeout in seconds</span><br><span class="line"># default value is 30s</span><br><span class="line">network_timeout=10</span><br><span class="line"></span><br><span class="line"># the base path to store log files</span><br><span class="line">base_path=/work/fdfs/storage</span><br><span class="line"></span><br><span class="line"># if load FastDFS parameters from tracker server</span><br><span class="line"># since V1.12</span><br><span class="line"># default value is false</span><br><span class="line">load_fdfs_parameters_from_tracker=true</span><br><span class="line"></span><br><span class="line"># storage sync file max delay seconds</span><br><span class="line"># same as tracker.conf</span><br><span class="line"># valid only when load_fdfs_parameters_from_tracker is false</span><br><span class="line"># since V1.12</span><br><span class="line"># default value is 86400 seconds (one day)</span><br><span class="line">storage_sync_file_max_delay = 86400</span><br><span class="line"></span><br><span class="line"># if use storage ID instead of IP address</span><br><span class="line"># same as tracker.conf</span><br><span class="line"># valid only when load_fdfs_parameters_from_tracker is false</span><br><span class="line"># default value is false</span><br><span class="line"># since V1.13</span><br><span class="line">use_storage_id = false</span><br><span class="line"></span><br><span class="line"># specify storage ids filename, can use relative or absolute path</span><br><span class="line"># same as tracker.conf</span><br><span class="line"># valid only when load_fdfs_parameters_from_tracker is false</span><br><span class="line"># since V1.13</span><br><span class="line">storage_ids_filename = storage_ids.conf</span><br><span class="line"></span><br><span class="line"># FastDFS tracker_server can ocur more than once, and tracker_server format is</span><br><span class="line">#  &quot;host:port&quot;, host can be hostname or ip address</span><br><span class="line"># valid only when load_fdfs_parameters_from_tracker is true</span><br><span class="line">tracker_server=192.168.100.111:22122</span><br><span class="line">tracker_server=192.168.100.112:22122</span><br><span class="line"></span><br><span class="line"># the port of the local storage server</span><br><span class="line"># the default value is 23000</span><br><span class="line">storage_server_port=23000</span><br><span class="line"></span><br><span class="line"># the group name of the local storage server</span><br><span class="line">group_name=group1</span><br><span class="line"></span><br><span class="line"># if the url / uri including the group name</span><br><span class="line"># set to false when uri like /M00/00/00/xxx</span><br><span class="line"># set to true when uri like $&#123;group_name&#125;/M00/00/00/xxx, such as group1/M00/xxx</span><br><span class="line"># default value is false</span><br><span class="line">url_have_group_name = true</span><br><span class="line"></span><br><span class="line"># path(disk or mount point) count, default value is 1</span><br><span class="line"># must same as storage.conf</span><br><span class="line">store_path_count=1</span><br><span class="line"></span><br><span class="line"># store_path#, based 0, if store_path0 not exists, it&#x27;s value is base_path</span><br><span class="line"># the paths must be exist</span><br><span class="line"># must same as storage.conf</span><br><span class="line">store_path0=/work/fdfs/storage</span><br><span class="line"></span><br><span class="line"># standard log level as syslog, case insensitive, value list:</span><br><span class="line">### emerg for emergency</span><br><span class="line">### alert</span><br><span class="line">### crit for critical</span><br><span class="line">### error</span><br><span class="line">### warn for warning</span><br><span class="line">### notice</span><br><span class="line">### info</span><br><span class="line">### debug</span><br><span class="line">log_level=info</span><br><span class="line"></span><br><span class="line"># set the log filename, such as /usr/local/apache2/logs/mod_fastdfs.log</span><br><span class="line"># empty for output to stderr (apache and nginx error_log file)</span><br><span class="line">log_filename=</span><br><span class="line"></span><br><span class="line"># response mode when the file not exist in the local file system</span><br><span class="line">## proxy: get the content from other storage server, then send to client</span><br><span class="line">## redirect: redirect to the original storage server (HTTP Header is Location)</span><br><span class="line">response_mode=proxy</span><br><span class="line"></span><br><span class="line"># the NIC alias prefix, such as eth in Linux, you can see it by ifconfig -a</span><br><span class="line"># multi aliases split by comma. empty value means auto set by OS type</span><br><span class="line"># this paramter used to get all ip address of the local host</span><br><span class="line"># default values is empty</span><br><span class="line">if_alias_prefix=</span><br><span class="line"></span><br><span class="line"># use &quot;#include&quot; directive to include HTTP config file</span><br><span class="line"># NOTE: #include is an include directive, do NOT remove the # before include</span><br><span class="line">#include http.conf</span><br><span class="line"></span><br><span class="line"># if support flv</span><br><span class="line"># default value is false</span><br><span class="line"># since v1.15</span><br><span class="line">flv_support = true</span><br><span class="line"></span><br><span class="line"># flv file extension name</span><br><span class="line"># default value is flv</span><br><span class="line"># since v1.15</span><br><span class="line">flv_extension = flv</span><br><span class="line"></span><br><span class="line"># set the group count</span><br><span class="line"># set to none zero to support multi-group on this storage server</span><br><span class="line"># set to 0  for single group only</span><br><span class="line"># groups settings section as [group1], [group2], ..., [groupN]</span><br><span class="line"># default value is 0</span><br><span class="line"># since v1.14</span><br><span class="line">group_count = 1</span><br><span class="line"></span><br><span class="line"># group settings for group #1</span><br><span class="line"># since v1.14</span><br><span class="line"># when support multi-group on this storage server, uncomment following section</span><br><span class="line">[group1]</span><br><span class="line">group_name=group1</span><br><span class="line">storage_server_port=23000</span><br><span class="line">store_path_count=1</span><br><span class="line">store_path0=/work/fdfs/storage</span><br><span class="line"></span><br><span class="line"># group settings for group #2</span><br><span class="line"># since v1.14</span><br><span class="line"># when support multi-group, uncomment following section as neccessary</span><br><span class="line">#[group2]</span><br><span class="line">#group_name=group2</span><br><span class="line">#storage_server_port=23000</span><br><span class="line">#store_path_count=1</span><br><span class="line">#store_path0=/home/yuqing/fastdfs</span><br></pre></td></tr></table></figure><h2 id="服务启动及验证"><a href="#服务启动及验证" class="headerlink" title="服务启动及验证"></a><strong>服务启动及验证</strong></h2><p>分别启动keepalive、nginx、tracker、storage服务<br>查看服务是否正常服务：<br><img src="https://oscimg.oschina.net/oscnet/0e39fd8468a028040406cce85bde48b5586.png" alt=""><br>在任意Storage机器上查看集群状态：fdfs_monitor /etc/fdfs/storage.conf<br><img src="https://oscimg.oschina.net/oscnet/fda6e27aedde1ebc7a92d3db5af2048e9e9.png" alt=""></p><h2 id="Java客户端测试"><a href="#Java客户端测试" class="headerlink" title="Java客户端测试"></a><strong>Java客户端测试</strong></h2><h3 id="java项目Maven依赖"><a href="#java项目Maven依赖" class="headerlink" title="java项目Maven依赖"></a>java项目Maven依赖</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">项目地址：https://github.com/tobato/FastDFS_Client</span><br><span class="line">目前客户端主要依赖于SpringBoot，因此必须引入:</span><br><span class="line">&lt;parent&gt;</span><br><span class="line">       &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">       &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;</span><br><span class="line">       &lt;version&gt;2.0.0.RELEASE&lt;/version&gt;</span><br><span class="line">       &lt;relativePath/&gt;</span><br><span class="line">&lt;/parent&gt;</span><br><span class="line"></span><br><span class="line">FastDFS 依赖包：</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;com.github.tobato&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;fastdfs-client&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;1.26.7&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">将FastDFS引入项目：</span><br><span class="line">@Import(FdfsClientConfig.class)</span><br><span class="line"></span><br><span class="line">在application.yml当中配置Fdfs相关参数：</span><br><span class="line">fdfs:</span><br><span class="line">  pool:</span><br><span class="line">    #连接池最大数量</span><br><span class="line">    max-total: 200</span><br><span class="line">    #每个tracker地址的最大连接数</span><br><span class="line">    max-total-per-key: 50</span><br><span class="line">    #连接耗尽时等待获取连接的最大毫秒数</span><br><span class="line">    max-wait-millis: 5000</span><br><span class="line">  so-timeout: 1500</span><br><span class="line">  connect-timeout: 600</span><br><span class="line">  thumb-image:</span><br><span class="line">    width: 150</span><br><span class="line">    height: 150</span><br><span class="line">  tracker-list:</span><br><span class="line">    - 192.168.100.110:7777</span><br><span class="line"></span><br><span class="line">或者</span><br><span class="line">fdfs:</span><br><span class="line">  pool:</span><br><span class="line">    #连接池最大数量</span><br><span class="line">    max-total: 200</span><br><span class="line">    #每个tracker地址的最大连接数</span><br><span class="line">    max-total-per-key: 50</span><br><span class="line">    #连接耗尽时等待获取连接的最大毫秒数</span><br><span class="line">    max-wait-millis: 5000</span><br><span class="line">  so-timeout: 1500</span><br><span class="line">  connect-timeout: 600</span><br><span class="line">  thumb-image:</span><br><span class="line">    width: 150</span><br><span class="line">    height: 150</span><br><span class="line">  tracker-list:</span><br><span class="line">    - 192.168.100.111:22122</span><br><span class="line">    - 192.168.100.112:22122</span><br><span class="line"></span><br><span class="line">使用接口服务对Fdfs服务端进行操作，主要接口包括：</span><br><span class="line">TrackerClient - TrackerServer接口</span><br><span class="line">GenerateStorageClient - 一般文件存储接口 (StorageServer接口)</span><br><span class="line">FastFileStorageClient - 为方便项目开发集成的简单接口(StorageServer接口)</span><br><span class="line">AppendFileStorageClient - 支持文件续传操作的接口 (StorageServer接口)</span><br></pre></td></tr></table></figure><h3 id="代码测试"><a href="#代码测试" class="headerlink" title="代码测试"></a>代码测试</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.maxbill;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.github.tobato.fastdfs.FdfsClientConfig;</span><br><span class="line"><span class="keyword">import</span> com.github.tobato.fastdfs.domain.fdfs.MetaData;</span><br><span class="line"><span class="keyword">import</span> com.github.tobato.fastdfs.domain.fdfs.StorePath;</span><br><span class="line"><span class="keyword">import</span> com.github.tobato.fastdfs.domain.proto.storage.DownloadByteArray;</span><br><span class="line"><span class="keyword">import</span> com.github.tobato.fastdfs.service.FastFileStorageClient;</span><br><span class="line"><span class="keyword">import</span> lombok.extern.log4j.Log4j2;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.lang3.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Import;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.annotation.PostConstruct;</span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.FileInputStream;</span><br><span class="line"><span class="keyword">import</span> java.text.DateFormat;</span><br><span class="line"><span class="keyword">import</span> java.text.SimpleDateFormat;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Log4j2</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="meta">@Import(FdfsClientConfig.class)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FdfsClientUtil</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String BASE_URL = <span class="string">&quot;http://192.168.100.110:8888/&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> FastFileStorageClient storageClient;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> FdfsClientUtil fdfsClientUtil;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@PostConstruct</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        fdfsClientUtil = <span class="keyword">this</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 文件上传</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> file    文件信息</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> infoMap 文件扩展信息</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 上传路径</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Map&lt;String, Object&gt; <span class="title">uploadFile</span><span class="params">(File file, Map&lt;String, String&gt; infoMap)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            String fileName = file.getName();</span><br><span class="line">            String fileType = fileName.substring(fileName.lastIndexOf(<span class="string">&quot;\\&quot;</span>) + <span class="number">1</span>);</span><br><span class="line">            <span class="comment">//String fileType = FilenameUtils.getExtension(file.getName())</span></span><br><span class="line">            log.info(<span class="string">&quot;[fdfs-upload]-start upload file ... &quot;</span>);</span><br><span class="line">            log.info(<span class="string">&quot;[fdfs-upload]-request upload file name: &#123;&#125;&quot;</span>, fileName);</span><br><span class="line">            log.info(<span class="string">&quot;[fdfs-upload]-request upload file info: &#123;&#125;&quot;</span>, infoMap);</span><br><span class="line">            StorePath path = fdfsClientUtil.storageClient.uploadFile(<span class="keyword">new</span> FileInputStream(file), file.length(), fileType, getMetaData(infoMap));</span><br><span class="line">            log.info(<span class="string">&quot;[fdfs-upload]-upload success path: &#123;&#125;&quot;</span>, path.getFullPath());</span><br><span class="line">            <span class="keyword">return</span> getResultMap(BASE_URL.concat(path.getFullPath()), <span class="keyword">null</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            log.error(<span class="string">&quot;[fdfs-upload]-upload file exception info: &#123;&#125;&quot;</span>, e.getMessage());</span><br><span class="line">            <span class="keyword">return</span> getResultMap(<span class="keyword">null</span>, e.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 下载文件</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> filePath 文件路径标识</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 文件字节</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Map&lt;String, Object&gt; <span class="title">downloadFile</span><span class="params">(String filePath)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            filePath = filePath.replace(BASE_URL, <span class="string">&quot;&quot;</span>);</span><br><span class="line">            StorePath storePath = StorePath.parseFromUrl(filePath);</span><br><span class="line">            String group = storePath.getGroup();</span><br><span class="line">            String path = storePath.getPath();</span><br><span class="line">            log.info(<span class="string">&quot;[fdfs-download]-start download file ... &quot;</span>);</span><br><span class="line">            log.info(<span class="string">&quot;[fdfs-download]-request download file group: &#123;&#125;&quot;</span>, group);</span><br><span class="line">            log.info(<span class="string">&quot;[fdfs-download]-request download file path: &#123;&#125;&quot;</span>, path);</span><br><span class="line">            <span class="keyword">byte</span>[] data = fdfsClientUtil.storageClient.downloadFile(group, path, <span class="keyword">new</span> DownloadByteArray());</span><br><span class="line">            log.info(<span class="string">&quot;[fdfs-download]-request download file success ... &quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> getResultMap(data, <span class="keyword">null</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            log.error(<span class="string">&quot;[fdfs-download]-download file exception info: &#123;&#125;&quot;</span>, e.getMessage());</span><br><span class="line">            <span class="keyword">return</span> getResultMap(<span class="keyword">null</span>, e.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 删除文件</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> filePath 文件路径标识</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 操作结果</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">deleteFile</span><span class="params">(String filePath)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            filePath = filePath.replace(BASE_URL, <span class="string">&quot;&quot;</span>);</span><br><span class="line">            StorePath storePath = StorePath.parseFromUrl(filePath);</span><br><span class="line">            String group = storePath.getGroup();</span><br><span class="line">            String path = storePath.getPath();</span><br><span class="line">            log.info(<span class="string">&quot;[fdfs-delete]-start delete file ... &quot;</span>);</span><br><span class="line">            log.info(<span class="string">&quot;[fdfs-delete]-request delete file group: &#123;&#125;&quot;</span>, group);</span><br><span class="line">            log.info(<span class="string">&quot;[fdfs-delete]-request delete file path: &#123;&#125;&quot;</span>, path);</span><br><span class="line">            fdfsClientUtil.storageClient.deleteFile(storePath.getGroup(), storePath.getPath());</span><br><span class="line">            log.info(<span class="string">&quot;[fdfs-delete]-request delete file success ... &quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            log.error(<span class="string">&quot;[fdfs-delete]-delete file exception info: &#123;&#125;&quot;</span>, e.getMessage());</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 查看文件元信息</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> filePath 文件路径标识</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 文件信息</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Map&lt;String, Object&gt; <span class="title">getFileInfo</span><span class="params">(String filePath)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            filePath = filePath.replace(BASE_URL, <span class="string">&quot;&quot;</span>);</span><br><span class="line">            StorePath storePath = StorePath.parseFromUrl(filePath);</span><br><span class="line">            String group = storePath.getGroup();</span><br><span class="line">            String path = storePath.getPath();</span><br><span class="line">            log.info(<span class="string">&quot;[fdfs-meta]-start meta file ... &quot;</span>);</span><br><span class="line">            log.info(<span class="string">&quot;[fdfs-meta]-request meta file group: &#123;&#125;&quot;</span>, group);</span><br><span class="line">            log.info(<span class="string">&quot;[fdfs-meta]-request meta file path: &#123;&#125;&quot;</span>, path);</span><br><span class="line">            Map&lt;String, String&gt; infoMap = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">            infoMap.put(<span class="string">&quot;createPath&quot;</span>, filePath);</span><br><span class="line">            Set&lt;MetaData&gt; metaData = fdfsClientUtil.storageClient.getMetadata(storePath.getGroup(), storePath.getPath());</span><br><span class="line">            log.info(<span class="string">&quot;[fdfs-meta]-request meta file success ... &quot;</span>);</span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">null</span> != metaData &amp;&amp; !metaData.isEmpty()) &#123;</span><br><span class="line">                metaData.forEach(meta -&gt; &#123;</span><br><span class="line">                    infoMap.put(meta.getName(), meta.getValue());</span><br><span class="line">                &#125;);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> getResultMap(infoMap, <span class="keyword">null</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            log.error(<span class="string">&quot;[fdfs-meta]-meta file exception info: &#123;&#125;&quot;</span>, e.getMessage());</span><br><span class="line">            <span class="keyword">return</span> getResultMap(<span class="keyword">null</span>, e.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 封装附件元信息</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> infoMap 自定义数据</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 附件元信息</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Set&lt;MetaData&gt; <span class="title">getMetaData</span><span class="params">(Map&lt;String, String&gt; infoMap)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">null</span> != infoMap &amp;&amp; !infoMap.isEmpty()) &#123;</span><br><span class="line">            Set&lt;MetaData&gt; metaDataSet = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line">            <span class="keyword">for</span> (String key : infoMap.keySet()) &#123;</span><br><span class="line">                metaDataSet.add(<span class="keyword">new</span> MetaData(key, infoMap.get(key)));</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> metaDataSet;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            DateFormat df = <span class="keyword">new</span> SimpleDateFormat(<span class="string">&quot;yyyy-MM-dd HH:mm:ss&quot;</span>);</span><br><span class="line">            Set&lt;MetaData&gt; metaDataSet = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line">            metaDataSet.add(<span class="keyword">new</span> MetaData(<span class="string">&quot;createUser&quot;</span>, <span class="string">&quot;MaxBill&quot;</span>));</span><br><span class="line">            metaDataSet.add(<span class="keyword">new</span> MetaData(<span class="string">&quot;createDate&quot;</span>, df.format(<span class="keyword">new</span> Date())));</span><br><span class="line">            <span class="keyword">return</span> metaDataSet;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 封装结果信息</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> data 数据</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> info 信息</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 操作结果</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Map&lt;String, Object&gt; <span class="title">getResultMap</span><span class="params">(Object data, String info)</span> </span>&#123;</span><br><span class="line">        Map&lt;String, Object&gt; resultMap = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        <span class="keyword">if</span> (StringUtils.isEmpty(info)) &#123;</span><br><span class="line">            resultMap.put(<span class="string">&quot;flag&quot;</span>, <span class="keyword">true</span>);</span><br><span class="line">            resultMap.put(<span class="string">&quot;data&quot;</span>, data);</span><br><span class="line">            resultMap.put(<span class="string">&quot;info&quot;</span>, <span class="string">&quot;success&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            resultMap.put(<span class="string">&quot;flag&quot;</span>, <span class="keyword">false</span>);</span><br><span class="line">            resultMap.put(<span class="string">&quot;info&quot;</span>, info);</span><br><span class="line">            resultMap.put(<span class="string">&quot;data&quot;</span>, <span class="keyword">null</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> resultMap;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      分布式文件系统FastDFS安装部署(高可用)
    
    </summary>
    
    
      <category term="学分布式" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="FastDFS" scheme="https://www.maxbill.cn/marks/FastDFS/"/>
    
      <category term="分布式文件系统" scheme="https://www.maxbill.cn/marks/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="高可用" scheme="https://www.maxbill.cn/marks/%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
    
  </entry>
  
  <entry>
    <title>分布式文件系统FastDFS安装部署(非高可用)</title>
    <link href="https://www.maxbill.cn/2128340410.html"/>
    <id>https://www.maxbill.cn/2128340410.html</id>
    <published>2019-11-18T10:07:20.000Z</published>
    <updated>2020-03-07T08:03:10.845Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>本文会搭建一个适合低业务访问业务量的非高可用的FastDFS集群环境：一个Tracker服务，一个storage group中两个storage服务节点；该场景不适合生产环境使用，生产环境应该增加Tracker服务数量使用负载均衡器负载或者使用keepalived进行主备，对于storage group应该搭建多个，每组storage group内节点至少在两个及以上。</p><p>在后台管理的web项目中，对于文件存储、上传、下载等操作是必不可少的。对于单节点部署的系统还可将文件存储在本机上进行操作，但是对于分布式部署的系统来说，文件存储操作问题就显现出来了，必须将文件集中存储在某处。目前一般的存储方案有：1.使用云厂商的对象存储服务；2.使用自建的文件服务器(ftp…)；3.文件磁盘挂在方案；4.使用HDFS或FDFS等文件存储解决方案…   如果项目部署在可连接互联网的网络环境中可以使用云厂商的对象存储服务(安全、便利、低成本…)；但是对于很多政企或者金融的项目大部分都是部署在不能连接互联网的网络环境中，那么我们就只能选择在内网搭建文件服务的方式。为了保证文件数据的安全性和完整性，本文使用分布式文件系统服务FastDFS来实践。</p><h2 id="FastDFS简介"><a href="#FastDFS简介" class="headerlink" title="FastDFS简介"></a><strong>FastDFS简介</strong></h2><p>FastDFS是一个开源的轻量级分布式文件系统，它对文件进行管理，功能包括：文件存储、文件同步、文件访问（文件上传、文件下载）等，解决了大容量存储和负载均衡的问题。特别适合以文件为载体的在线服务，如相册网站、视频网站等等。<br>FastDFS为互联网量身定制，充分考虑了冗余备份、负载均衡、线性扩容等机制，并注重高可用、高性能等指标，使用FastDFS很容易搭建一套高性能的文件服务器集群提供文件上传、下载等服务。FastDFS服务端有两个角色：跟踪器（tracker）和存储节点（storage）。跟踪器主要做调度工作，在访问上起负载均衡的作用。存储节点存储文件，完成文件管理的所有功能：就是这样的存储、同步和提供存取接口，FastDFS同时对文件的metadata进行管理。所谓文件的meta data就是文件的相关属性，以键值对（key value）方式表示，如：width=1024，其中的key为width，value为1024。文件metadata是文件属性列表，可以包含多个键值对。跟踪器和存储节点都可以由一台或多台服务器构成。跟踪器和存储节点中的服务器均可以随时增加或下线而不会影响线上服务。其中跟踪器中的所有服务器都是对等的，可以根据服务器的压力情况随时增加或减少。为了支持大容量，存储节点（服务器）采用了分卷（或分组）的组织方式。存储系统由一个或多个卷组成，卷与卷之间的文件是相互独立的，所有卷的文件容量累加就是整个存储系统中的文件容量。一个卷可以由一台或多台存储服务器组成，一个卷下的存储服务器中的文件都是相同的，卷中的多台存储服务器起到了冗余备份和负载均衡的作用。在卷中增加服务器时，同步已有的文件由系统自动完成，同步完成后，系统自动将新增服务器切换到线上提供服务。当存储空间不足或即将耗尽时，可以动态添加卷。只需要增加一台或多台服务器，并将它们配置为一个新的卷，这样就扩大了存储系统的容量。FastDFS中的文件标识分为两个部分：卷名和文件名，二者缺一不可。(简介摘自百度百科)</p><h2 id="原理介绍"><a href="#原理介绍" class="headerlink" title="原理介绍"></a><strong>原理介绍</strong></h2><h3 id="文件上传"><a href="#文件上传" class="headerlink" title="文件上传"></a>文件上传</h3><p>FastDFS以客户端库的方式提供基本的文件访问接口如upload、download、append、delete等，Storage 服务会定时的向Tracker服务发送自己的存储信息。当Tracker 服务集群中的Tracker 服务是多个时，各个Tracker服务之间的关系是对等的，因此客户端上传时会任意选择一个Trackre服务。当Tracker服务收到客户端上传文件请求时，会为该文件分配一个可以存储文件的group，当选定了group后就要决定给客户端分配group中的哪一个storage服务。当分配好storage 服务后，客户端向storage发送写文件请求，storage将会为文件分配一个数据存储目录。然后为文件分配一个文件ID标示，然后根据以上的信息生成文件名存储文件。</p><h3 id="文件同步"><a href="#文件同步" class="headerlink" title="文件同步"></a>文件同步</h3><p>上传文件后，客户端将文件写到group内的一个storage 服务即为上传文件成功，storage服务写完文件后，会由后台线程将文件同步至同group内的其他的storage 服务节点上。 每个storage服务写文件后，会同时写一份binlog，binlog里不包含文件数据，只包含文件名等元信息，这份binlog用于后台同步，storage会记录向group内其他storage同步的进度，以便重启后能接上次的进度继续同步；进度以时间戳的方式进行记录，所以最好能保证集群内的所有server的始终保持同步。最后Storage服务的同步进度会作为元数据的一部分汇报到tracker服务上，tracker服务在选择读storage的时候会以同步进度作为参考指标。</p><h3 id="下载文件"><a href="#下载文件" class="headerlink" title="下载文件"></a>下载文件</h3><p>当下载文件时，客户端先询问tracker服务下载文件的storage，参数为文件标识（卷名和文件名）；然后tracker向客户端返回一台可用的storage；最后客户端直接和storage通讯完成文件下载。</p><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a><strong>环境准备</strong></h2><h3 id="软件环境"><a href="#软件环境" class="headerlink" title="软件环境"></a>软件环境</h3><p>libevent下载地址：<a href="http://libevent.org/">http://libevent.org/</a><br>libfasttcommon下载地址：<a href="https://github.com/happyfish100/libfastcommon/releases">https://github.com/happyfish100/libfastcommon/releases</a><br>fastdfs下载地址：<a href="https://github.com/happyfish100/fastdfs/releases">https://github.com/happyfish100/fastdfs/releases</a><br>fastdfs-nginx-module下载地址：<a href="https://github.com/happyfish100/fastdfs-nginx-module/releases">https://github.com/happyfish100/fastdfs-nginx-module/releases</a></p><h3 id="机器及网络环境"><a href="#机器及网络环境" class="headerlink" title="机器及网络环境"></a>机器及网络环境</h3><p>Tracker Server1：                 192.168.100.101<br>Storage Group1 Node1：    192.168.100.102<br>Storage Group1 Node2：    192.168.100.103<br>Tracker节点需要安装的组件：libevent、libfasttcommon、fastdfs<br>Storage节点需要安装的组件：libfasttcommon、fastdfs、nginx、fastdfs-nginx-module</p><h2 id="部署Tracker服务"><a href="#部署Tracker服务" class="headerlink" title="部署Tracker服务"></a><strong>部署Tracker服务</strong></h2><p>对应机器：192.168.100.101</p><h3 id="安装libevent依赖"><a href="#安装libevent依赖" class="headerlink" title="安装libevent依赖"></a>安装libevent依赖</h3><p>注：如果机器有外网环境直接yum -y install libevent，本文使用源码包编译安装<br>解压libevent源码包：tar -zxvf libevent-2.1.11-stable.tar.gz<br>编译安装前配置：./configure<br>编译安装：make &amp;&amp; make install<br>默认安装位置：/usr/local/lib</p><h3 id="安装libfasttcommon依赖"><a href="#安装libfasttcommon依赖" class="headerlink" title="安装libfasttcommon依赖"></a>安装libfasttcommon依赖</h3><p>解压libfasttcommon源码包：tar -zxvf libfastcommon-1.0.41.tar.gz<br>编译安装：./make.sh &amp;&amp; ./make.sh install<br>默认安装位置：/usr/lib64</p><h3 id="安装FastDFS-Tracker服务"><a href="#安装FastDFS-Tracker服务" class="headerlink" title="安装FastDFS Tracker服务"></a>安装FastDFS Tracker服务</h3><p>解压fastdfs源码包：tar -zxvf fastdfs-6.01.tar.gz<br>编译安装：./make.sh &amp;&amp; ./make.sh install<br>安装完成后服务及脚本都拷贝到/usr/bin 目录了：<br><img src="https://oscimg.oschina.net/oscnet/39cd95b5f74930e3ec6a61c5f09014cbeb1.jpg" alt=""><br>安装完成后配置文件都拷贝到/etc/fdfs目录下了：<br><img src="https://oscimg.oschina.net/oscnet/2c50c35c47593d618dd6839cd509c64eb7f.jpg" alt=""><br>拷贝/etc/fdfs目录下的Tracker配置文件示例：cp /etc/fdfs/tracker.conf.sample /etc/fdfs/tracker.conf<br>修改 /etc/fdfs/tracker.conf中配置项：<br>base_path=/home/yuqing/fastdfs 改为：/work/fastdfs/tracker(该目录为自己定义，启动时会用，没有会报错)<br>安装完成后启动脚本都拷贝到/etc/init.d目录下了：<br><img src="https://oscimg.oschina.net/oscnet/41d522edb4ebd80069b4e02d216ee3662e7.jpg" alt=""><br>将/etc/init.d/fdfs_storaged删掉，因为这台机器只安装Tracker服务<br>注：编译安装fastdfs需要perl库依赖<br>设置Tracker服务开机自启动：<br>chkconfig –add fdfs_trackerd<br>chkconfig fdfs_trackerd on<br><img src="https://oscimg.oschina.net/oscnet/fc1976da6dc24ef90a3bb19cf41f36133a4.jpg" alt=""><br>启动Tracker服务：systemctl start fdfs_trackerd<br>重启Tracker服务：systemctl restart fdfs_trackerd<br>停止Tracker服务：systemctl stop fdfs_trackerd<br>开放Tracker服务端口：iptables -I INPUT -p tcp –dport 22122 -j ACCEPT<br><img src="https://oscimg.oschina.net/oscnet/79a84e0255a538c1be1b7fcaa528b679f75.jpg" alt=""></p><h2 id="部署Storage服务"><a href="#部署Storage服务" class="headerlink" title="部署Storage服务"></a><strong>部署Storage服务</strong></h2><p>对应机器：192.168.100.102/103</p><h3 id="安装libfasttcommon依赖-1"><a href="#安装libfasttcommon依赖-1" class="headerlink" title="安装libfasttcommon依赖"></a>安装libfasttcommon依赖</h3><p>解压libfasttcommon源码包：tar -zxvf libfastcommon-1.0.41.tar.gz<br>编译安装：./make.sh &amp;&amp; ./make.sh install<br>默认安装位置：/usr/lib64</p><h3 id="安装FastDFS-Storage服务"><a href="#安装FastDFS-Storage服务" class="headerlink" title="安装FastDFS Storage服务"></a>安装FastDFS Storage服务</h3><p>解压fastdfs源码包：tar -zxvf fastdfs-6.01.tar.gz<br>编译安装：./make.sh &amp;&amp; ./make.sh install<br>安装完成后服务及脚本都拷贝到/usr/bin 目录了：<br><img src="https://oscimg.oschina.net/oscnet/39cd95b5f74930e3ec6a61c5f09014cbeb1.jpg" alt=""><br>安装完成后配置文件都拷贝到/etc/fdfs目录下了：<br><img src="https://oscimg.oschina.net/oscnet/2c50c35c47593d618dd6839cd509c64eb7f.jpg" alt=""><br>拷贝/etc/fdfs目录下的Storage配置文件示例：cp /etc/fdfs/storage.conf.sample /etc/fdfs/storage.conf<br>修改 /etc/fdfs/storage.conf中配置项：<br>base_path=/home/yuqing/fastdfs 改为：base_path=/work/fastdfs/storage(该目录为自己定义，启动时会用，没有会报错)<br>store_path0=/home/yuqing/fastdfs 改为：store_path0=/work/fastdfs/storage(该目录为自己定义，启动时会用，没有会报错)<br>tracker_server=192.168.209.121:22122 改为：tracker_server=192.168.100.101:22122<br>安装完成后启动脚本都拷贝到/etc/init.d目录下了：<br><img src="https://oscimg.oschina.net/oscnet/41d522edb4ebd80069b4e02d216ee3662e7.jpg" alt=""><br>将/etc/init.d/fdfs_trackerd删掉，因为这台机器只安装Storage服务<br>注：编译安装fastdfs需要perl库依赖<br>设置Storage服务开机自启动：<br>chkconfig –add fdfs_storaged<br>chkconfig fdfs_storaged on<br><img src="https://oscimg.oschina.net/oscnet/f4454c72a831523fd16864f2e143df31c1c.jpg" alt=""><br>启动Storage服务：systemctl start fdfs_storaged<br>重启Storage服务：systemctl restart fdfs_storaged<br>停止Storage服务：systemctl stop fdfs_storaged<br>开放Storage服务端口：<br>iptables -I INPUT -p tcp –dport 23000 -j ACCEPT<br>iptables -I INPUT -p tcp –dport 8888 -j ACCEPT<br><img src="https://oscimg.oschina.net/oscnet/070ac7f4d6651de1ca22ff603a63f3f92c5.jpg" alt=""><br>Storage服务启动正常，进入数据目录中，可以看到已经有了初始数据信息：<br><img src="https://oscimg.oschina.net/oscnet/38304c00e21b90a6288bb2d1bdf3427877d.jpg" alt=""><br>验证当前Storage服务和Tracker服务通信情况：<br>/usr/bin/fdfs_monitor /etc/fdfs/storage.conf<br> <img src="https://oscimg.oschina.net/oscnet/d418bf557ff315a754631c5e7a94fc669f2.jpg" alt=""></p><h3 id="安装Nginx和fdfs-nginx模块"><a href="#安装Nginx和fdfs-nginx模块" class="headerlink" title="安装Nginx和fdfs-nginx模块"></a>安装Nginx和fdfs-nginx模块</h3><p>在每个Storage服务节点上安装Nginx服务以及fdfs-nginx模块。<br>首先安装nginx需要的依赖：yum install -y gcc gcc-c++ pcre pcre-devel zlib zlib-devel openssl openssl-devel<br>解压nginx安装包：tar -zxvf nginx-1.16.1.tar.gz<br>安装配置Nginx：./configure –prefix=/work/nginx –add-module=../fastdfs-nginx-module-1.21/src<br>编译安装Nginx：make &amp;&amp; make install<br>将fastdfs-nginx-module-1.21/src下的mod_fastdfs.conf拷贝到/etc/fdfs下<br>修改mod_fastdfs.conf如下：<br>连接超时时间： connect_timeout=10<br>Tracker服务地址：tracker_server=192.168.100.101:22122<br>Storage服务端口：storage_server_port=23000<br>如果文件ID的uri中包含/group**，则要设置为true：url_have_group_name = true<br>Storage配置的store_path0路径，必须和storage.conf中的一致：store_path0=/work/fastdfs/storage<br>拷贝/etc/fdfs/torage_ids.conf.sample 为torage_ids.conf，内容修改为当前group的storage节点信息：<br><img src="https://oscimg.oschina.net/oscnet/b615441115b8325565fc1d976d943c41596.jpg" alt=""><br>修改各个Storage机器上的nginx服务的配置如下：</p><h2 id="使用Java客户端测试FastDFS"><a href="#使用Java客户端测试FastDFS" class="headerlink" title="使用Java客户端测试FastDFS"></a><strong>使用Java客户端测试FastDFS</strong></h2><h3 id="java项目Maven依赖"><a href="#java项目Maven依赖" class="headerlink" title="java项目Maven依赖"></a>java项目Maven依赖</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">项目地址：https://github.com/tobato/FastDFS_Client</span><br><span class="line">目前客户端主要依赖于SpringBoot，因此必须引入:</span><br><span class="line">&lt;parent&gt;</span><br><span class="line">       &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">       &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;</span><br><span class="line">       &lt;version&gt;2.0.0.RELEASE&lt;/version&gt;</span><br><span class="line">       &lt;relativePath/&gt;</span><br><span class="line">&lt;/parent&gt;</span><br><span class="line"></span><br><span class="line">FastDFS 依赖包：</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;com.github.tobato&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;fastdfs-client&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;1.26.7&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">将FastDFS引入项目：</span><br><span class="line">@Import(FdfsClientConfig.class)</span><br><span class="line"></span><br><span class="line">在application.yml当中配置Fdfs相关参数：</span><br><span class="line"># ===================================================================</span><br><span class="line"># 分布式文件系统FDFS配置</span><br><span class="line"># ===================================================================</span><br><span class="line">fdfs:</span><br><span class="line">  so-timeout: 1500</span><br><span class="line">  connect-timeout: 600</span><br><span class="line">  thumb-image:</span><br><span class="line">    width: 150</span><br><span class="line">    height: 150</span><br><span class="line">  tracker-list:</span><br><span class="line">    - 192.168.100.101:22122</span><br><span class="line"></span><br><span class="line">使用接口服务对Fdfs服务端进行操作，主要接口包括：</span><br><span class="line">TrackerClient - TrackerServer接口</span><br><span class="line">GenerateStorageClient - 一般文件存储接口 (StorageServer接口)</span><br><span class="line">FastFileStorageClient - 为方便项目开发集成的简单接口(StorageServer接口)</span><br><span class="line">AppendFileStorageClient - 支持文件续传操作的接口 (StorageServer接口)</span><br></pre></td></tr></table></figure><h3 id="实际测试案例"><a href="#实际测试案例" class="headerlink" title="实际测试案例"></a>实际测试案例</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.maxbill;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.github.tobato.fastdfs.domain.fdfs.MetaData;</span><br><span class="line"><span class="keyword">import</span> com.github.tobato.fastdfs.domain.fdfs.StorePath;</span><br><span class="line"><span class="keyword">import</span> com.github.tobato.fastdfs.service.FastFileStorageClient;</span><br><span class="line"><span class="keyword">import</span> com.github.tobato.fastdfs.service.TrackerClient;</span><br><span class="line"><span class="keyword">import</span> lombok.extern.log4j.Log4j2;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.annotation.PostConstruct;</span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.FileInputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStream;</span><br><span class="line"><span class="keyword">import</span> java.util.HashSet;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"><span class="keyword">import</span> java.util.Set;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Log4j2</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FdfsClientUtil</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> FdfsClientUtil fdfsClientUtil;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> TrackerClient trackerClient;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> FastFileStorageClient storageClient;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@PostConstruct</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        fdfsClientUtil = <span class="keyword">this</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Set&lt;MetaData&gt; <span class="title">getMetaData</span><span class="params">(Map&lt;String, String&gt; infoMap)</span> </span>&#123;</span><br><span class="line">        Set&lt;MetaData&gt; metaDataSet = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line">        metaDataSet.add(<span class="keyword">new</span> MetaData(<span class="string">&quot;createUser&quot;</span>, <span class="string">&quot;maxbill&quot;</span>));</span><br><span class="line">        metaDataSet.add(<span class="keyword">new</span> MetaData(<span class="string">&quot;createDate&quot;</span>, <span class="string">&quot;2019-11-18&quot;</span>));</span><br><span class="line">        <span class="keyword">return</span> metaDataSet;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">uploadFile</span><span class="params">(File file, Map&lt;String, String&gt; infoMap)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            String fileName = file.getName();</span><br><span class="line">            String fileType = fileName.substring(fileName.lastIndexOf(<span class="string">&quot;\\&quot;</span>) + <span class="number">1</span>);</span><br><span class="line">            log.info(<span class="string">&quot;upload file name: &#123;&#125;&quot;</span>, fileName);</span><br><span class="line">            StorePath path = fdfsClientUtil.storageClient.uploadFile(<span class="keyword">new</span> FileInputStream(file), file.length(), fileType, getMetaData(infoMap));</span><br><span class="line">            log.info(<span class="string">&quot;upload success path: &#123;&#125;&quot;</span>, path);</span><br><span class="line">            Set&lt;MetaData&gt; metaData = fdfsClientUtil.storageClient.getMetadata(path.getGroup(), path.getPath());</span><br><span class="line">            log.info(<span class="string">&quot;upload success meta: &#123;&#125;&quot;</span>, metaData);</span><br><span class="line">            <span class="keyword">return</span> path.getFullPath();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            log.error(e.getMessage());</span><br><span class="line">            <span class="keyword">return</span> e.getMessage();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      分布式文件系统FastDFS安装部署(非高可用)
    
    </summary>
    
    
      <category term="学分布式" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="FastDFS" scheme="https://www.maxbill.cn/marks/FastDFS/"/>
    
      <category term="分布式文件系统" scheme="https://www.maxbill.cn/marks/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="高可用" scheme="https://www.maxbill.cn/marks/%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
    
  </entry>
  
  <entry>
    <title>K8S(04)模拟生产环境搭建高可用集群之Etcd集群部署</title>
    <link href="https://www.maxbill.cn/3877702786.html"/>
    <id>https://www.maxbill.cn/3877702786.html</id>
    <published>2019-11-02T13:54:03.000Z</published>
    <updated>2020-03-07T08:02:41.488Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>本文我们首先要说到什么是etcd，为什么kubernetes要使用etcd ，然后实践下二进制安装部署etcd集群。</p><h2 id="Etcd组件简介"><a href="#Etcd组件简介" class="headerlink" title="Etcd组件简介"></a><strong>Etcd组件简介</strong></h2><p>Etcd是一个高可用的键值存储系统，快速地保存和提供对关键数据的访问。它通过分布式锁定，领导者选举和写入障碍实现可靠的分布式协调。etcd集群旨在实现高可用性和永久数据存储和检索。主要用于共享配置和服务发现，它通过Raft一致性算法处理日志复制以保证强一致性，我们可以理解它为一个高可用强一致性的服务发现存储仓库。Etcd主要解决的是分布式系统中数据一致性的问题，而分布式系统中的数据分为控制数据和应用数据，etcd处理的数据类型为控制数据，对于很少量的应用数据也可以进行处理。</p><p>Etcd和Zookeeper的比较：<br>1.zk相比部署维护复杂复杂，使用也复杂，学习成本较高。而etcd部署简单，使用HTTP作为接口使用简单，使用Raft算法保证强一致性让用户易于理解。<br>2.zk使用Java编写，需要jvm才能运行，会引入大量的依赖，相对偏于中性应用。<br>3.zk发展缓慢。而etcd被k8s作为默认存储系统，升级迭代迅速。<br>4.etcd更安全，支持SSL客户端安全认证。</p><h2 id="K8S和ETCD的关系"><a href="#K8S和ETCD的关系" class="headerlink" title="K8S和ETCD的关系"></a><strong>K8S和ETCD的关系</strong></h2><p>kubernetes官方默认使用etcd组件作为自己的高可用强一致性的服务发现存储仓库，在kubernetes集群中etcd主要用于配置数据共享和服务发现，把关键数据都存放在etcd键值存储中，这使得kubernetes的整体结构变得非常简单。在kubernetes中由于数据是随时发生变化的，提交了新任务、增加了新的Node、Node宕机了、容器死掉了等，都会触发状态数据的变更。集群状态数据变更之后，Master上的kube-scheduler和kube-controller-manager，就会重新安排工作，它们的工作安排结果也是数据。由于集群内状态数据变化都需要及时地通知给每一个组件，刚好etcd有一个特别好的特性，可以调用它的api监听其中的数据，一旦数据发生变化了就会收到通知。有了这个特性之后kubernetes中的每个组件只需要监听etcd中数据，就可以知道自己应该做什么。kube-scheduler和kube-controller-manager也只需要把最新的工作安排写入到etcd中就可以了，不用自己去逐个通知了。还有就是etcd使用raft协议实现一致性，是一个分布式锁可以用来做选举。如果在kubernetes中部署了多个kube-schdeuler，那么同一时刻只能有一个kube-scheduler在工作，要保证只有一个kube-schduler在工作呢就通过etcd选举出一个leader来实现。</p><h2 id="二进制部署etcd集群"><a href="#二进制部署etcd集群" class="headerlink" title="二进制部署etcd集群"></a><strong>二进制部署etcd集群</strong></h2><p>官网地址：<a href="https://etcd.io/">https://etcd.io/</a><br>文档地址：<a href="https://etcd.io/docs/">https://etcd.io/docs/</a><br>项目地址：<a href="https://github.com/etcd-io/etcd">https://github.com/etcd-io/etcd</a><br>下载地址：<a href="https://github.com/etcd-io/etcd/releases">https://github.com/etcd-io/etcd/releases</a></p><h3 id="下载etcd二进制安装包"><a href="#下载etcd二进制安装包" class="headerlink" title="下载etcd二进制安装包"></a>下载etcd二进制安装包</h3><p>本文使用最新版本3.4.3,下载适合自己硬件平台的，本文使用：etcd-v3.4.3-linux-amd64.tar.gz</p><h3 id="解压etcd二进制安装包"><a href="#解压etcd二进制安装包" class="headerlink" title="解压etcd二进制安装包"></a>解压etcd二进制安装包</h3><p>tar -zxvf etcd-v3.4.3-linux-amd64.tar.gz</p><h3 id="安装二进制程序"><a href="#安装二进制程序" class="headerlink" title="安装二进制程序"></a>安装二进制程序</h3><p>mkdir -p /work/etcd/{cfg,bin,dat,run,wal}<br>将etcd和etcdctl文件复制到/work/etcd/bin/目录下<br>创建软连接：<br>ln -s /work/etcd/bin/etcd /usr/local/bin/etcd<br>ln -s /work/etcd/bin/etcdctl /usr/local/bin/etcdctl<br><img src="https://oscimg.oschina.net/oscnet/1b275b9734ebf438516abb3b30aff494a62.jpg" alt=""></p><h3 id="编写注册系统服务文件"><a href="#编写注册系统服务文件" class="headerlink" title="编写注册系统服务文件"></a>编写注册系统服务文件</h3><p>vi /usr/lib/systemd/system/etcd.service   如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=etcd</span><br><span class="line">Documentation=https://github.com/etcd-io/etcd</span><br><span class="line">Conflicts=etcd.service</span><br><span class="line">After=network.target</span><br><span class="line">After=network-online.target</span><br><span class="line">Wants=network-online.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=5s</span><br><span class="line">LimitNOFILE=40000</span><br><span class="line">TimeoutStartSec=0</span><br><span class="line">WorkingDirectory=/work/etcd/run/</span><br><span class="line">ExecStart=/work/etcd/bin/etcd --config-file=/work/etcd/cfg/etcd.yml</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/9212abb74e27d6a235e4dd8472138bcaac1.jpg" alt=""></p><h3 id="生成Etcd服务需要的证书"><a href="#生成Etcd服务需要的证书" class="headerlink" title="生成Etcd服务需要的证书"></a>生成Etcd服务需要的证书</h3><p>准备证书生成工具<br>curl -L <a href="https://pkg.cfssl.org/R1.2/cfssl_linux-amd64">https://pkg.cfssl.org/R1.2/cfssl_linux-amd64</a> -o ./cfssl<br>curl -L <a href="https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64">https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64</a> -o ./cfssljson<br>curl -L <a href="https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64">https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64</a> -o ./cfssl-certinfo  </p><p>注意：本文在模拟内网环境下二进制安装，所以下载完成后传到机器上的/usr/local/bin<br><img src="https://oscimg.oschina.net/oscnet/72d7ba3e589ae7be36bdd8e40524535574c.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/8410625bfe372a2cc3bd5f165b2845d4f46.jpg" alt=""></p><p>创建全局证书目录mkdir cert<br><img src="https://oscimg.oschina.net/oscnet/b1393b7bce91e96a9595a3984889c97db6c.jpg" alt=""></p><p>创建认证中心(CA)<br>cfssl print-defaults config &gt; ca-etcd-config.json  # 默认证书生产策略配置模板<br>cfssl print-defaults csr &gt; ca-etcd-csr.json        #默认csr请求模板</p><p>修改模板自定义内容vi ca-etcd-config.json 如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;signing&quot;: &#123;</span><br><span class="line">        &quot;default&quot;: &#123;</span><br><span class="line">            &quot;expiry&quot;: &quot;87600h&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;profiles&quot;: &#123;</span><br><span class="line">            &quot;etcd&quot;: &#123;</span><br><span class="line">                &quot;expiry&quot;: &quot;87600h&quot;,</span><br><span class="line">                &quot;usages&quot;: [</span><br><span class="line">                    &quot;signing&quot;,</span><br><span class="line">                    &quot;key encipherment&quot;,</span><br><span class="line">                    &quot;server auth&quot;,</span><br><span class="line">                    &quot;client auth&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意：<br>ca-config.json：可以定义多个 profiles，分别指定不同的过期时间、使用场景等参数；后续在签名证书时可以指定使用某个 profile；此实例只有一个etcd。<br>signing：表示该证书可用于签名其它证书；生成的 ca-etcd.pem 证书中 CA=TRUE；<br>server auth：表示client可以用该 CA 对server提供的证书进行验证；<br>client auth：表示server可以用该CA对client提供的证书进行验证；</p><p>修改模板自定义内容ca-etcd-csr.json  如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;etcd&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;SH&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;BS&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;etcd&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;System&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>生成证书（ca-etcd-key.pem）和秘钥(ca-etcd.pem)<br>cfssl gencert -initca ca-etcd-csr.json | cfssljson -bare ca-etcd<br><img src="https://oscimg.oschina.net/oscnet/b5af566d555c23adff00539276d0364021a.jpg" alt=""></p><p>创建etcd证书签名请求, vi etcd-csr.json  如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;etcd&quot;,</span><br><span class="line">  &quot;hosts&quot;: [</span><br><span class="line">    &quot;127.0.0.1&quot;,</span><br><span class="line">    &quot;192.168.100.111&quot;,</span><br><span class="line">    &quot;192.168.100.112&quot;,</span><br><span class="line">    &quot;192.168.100.113&quot;,</span><br><span class="line">    &quot;kube-cluster-master01&quot;,</span><br><span class="line">    &quot;kube-cluster-master02&quot;,</span><br><span class="line">    &quot;kube-cluster-master03&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;SH&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;BS&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;etcd&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;System&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>生成etcd证书<br>cfssl gencert -ca=/work/cert/ca-etcd.pem \<br>-ca-key=/work/cert/ca-etcd-key.pem \<br>-config=/work/cert/ca-etcd-config.json \<br>-profile=etcd etcd-csr.json | cfssljson -bare etcd<br>生成的如下文件：etcd.csr   etcd-key.pem    etcd.pem 将三个证书拷贝到其他两个节点上<br><img src="https://oscimg.oschina.net/oscnet/38ea93385af6779effc5d7eaecf3342ae42.jpg" alt=""></p><h3 id="编写Etcd服务配置文件"><a href="#编写Etcd服务配置文件" class="headerlink" title="编写Etcd服务配置文件"></a>编写Etcd服务配置文件</h3><p>节点1配置文件：vi /work/etcd/cfg/etcd.yml</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">name: kube-etcd-node01</span><br><span class="line">wal-dir: /work/etcd/wal</span><br><span class="line">data-dir: /work/etcd/dat/default.etcd</span><br><span class="line">listen-peer-urls: https://192.168.100.111:2380</span><br><span class="line">listen-client-urls: https://192.168.100.111:2379,https://127.0.0.1:2379</span><br><span class="line"></span><br><span class="line">advertise-client-urls: https://192.168.100.111:2379</span><br><span class="line">initial-advertise-peer-urls: https://192.168.100.111:2380</span><br><span class="line">initial-cluster: kube-etcd-node01=https://192.168.100.111:2380,kube-etcd-node02=https://192.168.100.112:2380,kube-etcd-node03=https://192.168.100.113:2380</span><br><span class="line">initial-cluster-token: kube-etcd-cluster</span><br><span class="line">initial-cluster-state: new</span><br><span class="line"></span><br><span class="line">client-transport-security:</span><br><span class="line">  cert-file: /work/cert/etcd.pem</span><br><span class="line">  key-file: /work/cert/etcd-key.pem</span><br><span class="line">  client-cert-auth: false</span><br><span class="line">  trusted-ca-file: /work/cert/ca-etcd.pem</span><br><span class="line">  auto-tls: false</span><br><span class="line"></span><br><span class="line">peer-transport-security:</span><br><span class="line">  cert-file: /work/cert/etcd.pem</span><br><span class="line">  key-file: /work/cert/etcd-key.pem</span><br><span class="line">  client-cert-auth: false</span><br><span class="line">  trusted-ca-file: /work/cert/ca-etcd.pem</span><br><span class="line">  auto-tls: false</span><br><span class="line"></span><br><span class="line">debug: false</span><br><span class="line">logger: zap</span><br><span class="line">log-outputs: [stderr]</span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/b14b7a3f9f9a7b2c87770c26e11256d1df9.jpg" alt=""></p><p>节点2配置文件：vim /work/etcd/cfg/etcd.yml</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">name: kube-etcd-node02</span><br><span class="line">wal-dir: /work/etcd/wal</span><br><span class="line">data-dir: /work/etcd/dat/default.etcd</span><br><span class="line">listen-peer-urls: https://192.168.100.112:2380</span><br><span class="line">listen-client-urls: https://192.168.100.112:2379,https://127.0.0.1:2379</span><br><span class="line"></span><br><span class="line">advertise-client-urls: https://192.168.100.112:2379</span><br><span class="line">initial-advertise-peer-urls: https://192.168.100.112:2380</span><br><span class="line">initial-cluster: kube-etcd-node01=https://192.168.100.111:2380,kube-etcd-node02=https://192.168.100.112:2380,kube-etcd-node03=https://192.168.100.113:2380</span><br><span class="line">initial-cluster-token: kube-etcd-cluster</span><br><span class="line">initial-cluster-state: new</span><br><span class="line"></span><br><span class="line">client-transport-security:</span><br><span class="line">  cert-file: /work/cert/etcd.pem</span><br><span class="line">  key-file: /work/cert/etcd-key.pem</span><br><span class="line">  client-cert-auth: false</span><br><span class="line">  trusted-ca-file: /work/cert/ca-etcd.pem</span><br><span class="line">  auto-tls: false</span><br><span class="line"></span><br><span class="line">peer-transport-security:</span><br><span class="line">  cert-file: /work/cert/etcd.pem</span><br><span class="line">  key-file: /work/cert/etcd-key.pem</span><br><span class="line">  client-cert-auth: false</span><br><span class="line">  trusted-ca-file: /work/cert/ca-etcd.pem</span><br><span class="line">  auto-tls: false</span><br><span class="line"></span><br><span class="line">debug: false</span><br><span class="line">logger: zap</span><br><span class="line">log-outputs: [stderr]</span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/3bfffdceaa5bb59bebff0c21e6bf277c4a5.jpg" alt=""></p><p>节点3配置文件：vi /work/etcd/cfg/etcd.conf</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">name: kube-etcd-node03</span><br><span class="line">wal-dir: /work/etcd/wal</span><br><span class="line">data-dir: /work/etcd/dat/default.etcd</span><br><span class="line">listen-peer-urls: https://192.168.100.113:2380</span><br><span class="line">listen-client-urls: https://192.168.100.113:2379,https://127.0.0.1:2379</span><br><span class="line"></span><br><span class="line">advertise-client-urls: https://192.168.100.113:2379</span><br><span class="line">initial-advertise-peer-urls: https://192.168.100.113:2380</span><br><span class="line">initial-cluster: kube-etcd-node01=https://192.168.100.111:2380,kube-etcd-node02=https://192.168.100.112:2380,kube-etcd-node03=https://192.168.100.113:2380</span><br><span class="line">initial-cluster-token: kube-etcd-cluster</span><br><span class="line">initial-cluster-state: new</span><br><span class="line"></span><br><span class="line">client-transport-security:</span><br><span class="line">  cert-file: /work/cert/etcd.pem</span><br><span class="line">  key-file: /work/cert/etcd-key.pem</span><br><span class="line">  client-cert-auth: false</span><br><span class="line">  trusted-ca-file: /work/cert/ca-etcd.pem</span><br><span class="line">  auto-tls: false</span><br><span class="line"></span><br><span class="line">peer-transport-security:</span><br><span class="line">  cert-file: /work/cert/etcd.pem</span><br><span class="line">  key-file: /work/cert/etcd-key.pem</span><br><span class="line">  client-cert-auth: false</span><br><span class="line">  trusted-ca-file: /work/cert/ca-etcd.pem</span><br><span class="line">  auto-tls: false</span><br><span class="line"></span><br><span class="line">debug: false</span><br><span class="line">logger: zap</span><br><span class="line">log-outputs: [stderr]</span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/4946d5e28089425670ac5bb06a6c1e9280f.jpg" alt=""></p><h3 id="启动ETCD服务"><a href="#启动ETCD服务" class="headerlink" title="启动ETCD服务"></a>启动ETCD服务</h3><p>以上步骤在三个节点上都操作完成后，分别在三个节点上执行以下操作：<br>systemctl daemon-reload<br>systemctl enable etcd<br>systemctl start etcd<br><img src="https://oscimg.oschina.net/oscnet/776dc2102b9d40543e710c15672a2c8f42f.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/76104916badd5634169b73a750cba5d4a41.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/4a4b5a7ec6c1b476ab2e8da1210cd6594f5.jpg" alt=""></p><h3 id="验证ETCD服务"><a href="#验证ETCD服务" class="headerlink" title="验证ETCD服务"></a>验证ETCD服务</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">etcdctl --cacert=/work/cert/ca-etcd.pem \</span><br><span class="line"> --cert=/work/cert/etcd.pem \</span><br><span class="line"> --key=/work/cert/etcd-key.pem \</span><br><span class="line"> --endpoints=https://192.168.100.111:2379,https://192.168.100.112:2379,https://192.168.100.113:2379 endpoint health</span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/b59f25fde169b28a953d3d1b7d6d5c0ffe5.jpg" alt=""></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">etcdctl --write-out=table \</span><br><span class="line"> --cacert=/work/cert/ca-etcd.pem \</span><br><span class="line"> --cert=/work/cert/etcd.pem \</span><br><span class="line"> --key=/work/cert/etcd-key.pem \</span><br><span class="line"> --endpoints=https://192.168.100.111:2379,https://192.168.100.112:2379,https://192.168.100.113:2379 endpoint status</span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/b70b14f70a02f817ba9f23075588881ee79.jpg" alt=""></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">etcdctl --write-out=table \</span><br><span class="line"> --cacert=/work/cert/ca-etcd.pem \</span><br><span class="line"> --cert=/work/cert/etcd.pem \</span><br><span class="line"> --key=/work/cert/etcd-key.pem \</span><br><span class="line"> --endpoints=https://192.168.100.111:2379,https://192.168.100.112:2379,https://192.168.100.113:2379 member list</span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/628e26988085001164dd51dce5d0edde660.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      K8S(04)模拟生产环境搭建高可用集群之Etcd集群部署
    
    </summary>
    
    
      <category term="开发运维" scheme="https://www.maxbill.cn/kinds/%E5%BC%80%E5%8F%91%E8%BF%90%E7%BB%B4/"/>
    
    
      <category term="K8S" scheme="https://www.maxbill.cn/marks/K8S/"/>
    
      <category term="Kubernetes" scheme="https://www.maxbill.cn/marks/Kubernetes/"/>
    
      <category term="容器化" scheme="https://www.maxbill.cn/marks/%E5%AE%B9%E5%99%A8%E5%8C%96/"/>
    
      <category term="Etcd" scheme="https://www.maxbill.cn/marks/Etcd/"/>
    
  </entry>
  
  <entry>
    <title>K8S(03)模拟生产环境搭建高可用集群之Master节点高可用方案</title>
    <link href="https://www.maxbill.cn/2830891998.html"/>
    <id>https://www.maxbill.cn/2830891998.html</id>
    <published>2019-10-29T05:35:03.000Z</published>
    <updated>2020-03-07T08:02:32.372Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>注意：本高可用方案不仅适用于本文的K8S主控节点的高可用，还适用于任何需要高可用的业务场景，haproxy可改用nginx或其他负载均衡器实现<br>大家都知道在生产环境部署服务一定要坚持一条：不允许出现单点故障。我们在测试环境部署k8s的架构一般是单主控Master节点多个工作Node节点，生产上部署K8S集群要避免主控节点宕机，我们需要对主控节点进行高可用部署。<br>生产环境对主控节点的高可用的解决方案：对主控节点部署多台（3台以上），然后多部署多台（一般2台以上）负载均衡器（一般选用Nginx或者Haproxy）来对主控节点的api-server服务进行负载以防止单点故障。本文将详细说明怎么对主控节点的api-server服务高可用，主要讲负载均衡器配置值部署这一块，集群的详细搭建在后面的文章中。</p><p><img src="https://oscimg.oschina.net/oscnet/6887ab8539a10f71a7108e6f6b029bb80a5.jpg" alt=""><br>主工作节点：192.168.100.107<br>从工作节点：192.168.100.108<br>虚拟IP       ：192.168.100.110</p><h2 id="环境说明"><a href="#环境说明" class="headerlink" title="环境说明"></a><strong>环境说明</strong></h2><p>系统环境：CentOS7.7<br>Keepalived版本：2.0.19<br>Haproxy版本：2.0.8</p><h2 id="安装配置Keepalived服务"><a href="#安装配置Keepalived服务" class="headerlink" title="安装配置Keepalived服务"></a><strong>安装配置Keepalived服务</strong></h2><h3 id="下载Keepalived源码包"><a href="#下载Keepalived源码包" class="headerlink" title="下载Keepalived源码包"></a>下载Keepalived源码包</h3><p>官网地址：<a href="https://www.keepalived.org/">https://www.keepalived.org/</a><br>下载地址：<a href="https://www.keepalived.org/software/keepalived-2.0.19.tar.gz">https://www.keepalived.org/software/keepalived-2.0.19.tar.gz</a></p><h3 id="上传并解压Keepalived源码包"><a href="#上传并解压Keepalived源码包" class="headerlink" title="上传并解压Keepalived源码包"></a>上传并解压Keepalived源码包</h3><p>tar -zxvf keepalived-2.0.19.tar.gz</p><h3 id="编译Keepalived准备"><a href="#编译Keepalived准备" class="headerlink" title="编译Keepalived准备"></a>编译Keepalived准备</h3><p>进入解压目录：cd keepalived-2.0.19<br>执行编译准备：./configure –prefix=/work/keepalived<br>注意：一定要有gcc和openssl编译相关的依赖</p><h3 id="编译安装Keepalived"><a href="#编译安装Keepalived" class="headerlink" title="编译安装Keepalived"></a>编译安装Keepalived</h3><p>make &amp;&amp; make install</p><h3 id="安装配置Keepalived"><a href="#安装配置Keepalived" class="headerlink" title="安装配置Keepalived"></a>安装配置Keepalived</h3><p>keepalived启动时会从/etc/keepalived/中相关的目录下查找keepalived.conf配置文件，因此将keepalived安装目录/usr/local/keepalived/etc/keepalived.conf 拷贝到/etc/keepalived/中。<br>mkdir /etc/keepalived/<br>cp /work/keepalived/etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf<br>cp /work/keepalived/etc/sysconfig/keepalived /etc/sysconfig/keepalived</p><h3 id="设置Keepalived开机启动项"><a href="#设置Keepalived开机启动项" class="headerlink" title="设置Keepalived开机启动项"></a>设置Keepalived开机启动项</h3><p>systemctl enable keepalived<br>然后就能使用systemctl start/stop/status keepalived管理keepalived了</p><h3 id="配置Keepalived服务"><a href="#配置Keepalived服务" class="headerlink" title="配置Keepalived服务"></a>配置Keepalived服务</h3><p>107机器的配置信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">vrrp_script check_haproxy &#123;</span><br><span class="line">       interval 3</span><br><span class="line">       script &quot;/work/script/check_haproxy.sh&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance kube_master&#123;</span><br><span class="line">       state master</span><br><span class="line">       interface ens33</span><br><span class="line">       virtual_router_id 110</span><br><span class="line">       priority 100</span><br><span class="line">       advert_int 3</span><br><span class="line">       authentication &#123;</span><br><span class="line">            auth_type PASS</span><br><span class="line">            auth_pass kube_master_password</span><br><span class="line">       &#125;</span><br><span class="line">       virtual_ipaddress &#123;</span><br><span class="line">            192.168.100.110</span><br><span class="line">       &#125;</span><br><span class="line">       track_script &#123;</span><br><span class="line">            check_haproxy</span><br><span class="line">       &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>108机器的配置信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">vrrp_script check_haproxy &#123;</span><br><span class="line">       interval 3</span><br><span class="line">       script &quot;/work/script/check_haproxy.sh&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance kube_master&#123;</span><br><span class="line">       state backup</span><br><span class="line">       interface ens33</span><br><span class="line">       virtual_router_id 110</span><br><span class="line">       priority 90</span><br><span class="line">       advert_int 3</span><br><span class="line">       authentication &#123;</span><br><span class="line">            auth_type PASS</span><br><span class="line">            auth_pass kube_master_password</span><br><span class="line">       &#125;</span><br><span class="line">       virtual_ipaddress &#123;</span><br><span class="line">            192.168.100.110</span><br><span class="line">       &#125;</span><br><span class="line">       track_script &#123;</span><br><span class="line">            check_haproxy</span><br><span class="line">       &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="编写haproxy服务检测脚本"><a href="#编写haproxy服务检测脚本" class="headerlink" title="编写haproxy服务检测脚本"></a>编写haproxy服务检测脚本</h3><p>vi /work/script/check_haproxy.sh   </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">active_status=`netstat -lntp|grep haproxy|wc -l`</span><br><span class="line">if [ $active_status -gt 0 ]; then</span><br><span class="line">    exit 0</span><br><span class="line">else</span><br><span class="line">    exit 1</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p>然后给脚本赋予执行权限：chmod +x /work/script/check_haproxy.sh</p><h2 id="Haproxy安装部署"><a href="#Haproxy安装部署" class="headerlink" title="Haproxy安装部署"></a><strong>Haproxy安装部署</strong></h2><h3 id="下载Haproxy源码包"><a href="#下载Haproxy源码包" class="headerlink" title="下载Haproxy源码包"></a>下载Haproxy源码包</h3><p>官网地址：<a href="https://www.haproxy.org/">https://www.haproxy.org/</a><br>下载地址：<a href="https://www.haproxy.org/download/2.0/src/haproxy-2.0.8.tar.gz">https://www.haproxy.org/download/2.0/src/haproxy-2.0.8.tar.gz</a></p><h3 id="上传并解压Haproxy源码包"><a href="#上传并解压Haproxy源码包" class="headerlink" title="上传并解压Haproxy源码包"></a>上传并解压Haproxy源码包</h3><p>tar -zxvf haproxy-2.0.8.tar.gz</p><h3 id="编译Haproxy"><a href="#编译Haproxy" class="headerlink" title="编译Haproxy"></a>编译Haproxy</h3><p>需要的依赖库：openssl openssl-devel systemd-deve pcre zlib<br>make TARGET=linux-glibc USE_OPENSSL=1 USE_SYSTEMD=1 USE_PCRE=1 USE_ZLIB=1 USE_CRYPT_H=1 USE_LIBCRYPT=1<br>开启https模式：USE_OPENSSL=1<br>指定systemd模式：USE_SYSTEMD=1<br>支持pcre库：USE_PCRE=1<br>支持zlib库：USE_ZLIB=1<br>支持crypt_h库：USE_CRYPT_H=1<br>支持libcrypt库：USE_LIBCRYPT=1</p><h3 id="安装haproxy"><a href="#安装haproxy" class="headerlink" title="安装haproxy"></a>安装haproxy</h3><p>make install PREFIX=/work/haproxy<br>指定安装目录：PREFIX=/work/haproxy</p><h3 id="注册到系统服务"><a href="#注册到系统服务" class="headerlink" title="注册到系统服务"></a>注册到系统服务</h3><p>vi /usr/lib/systemd/system/haproxy.service</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=HAProxy Load Balancer</span><br><span class="line">After=syslog.target network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStartPre=/work/haproxy/sbin/haproxy -f /etc/haproxy/haproxy.cfg   -c -q</span><br><span class="line">ExecStart=/work/haproxy/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg  -p /var/run/haproxy.pid</span><br><span class="line">ExecReload=/bin/kill -USR2 $MAINPID</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><h3 id="编写Haproxy配置文件"><a href="#编写Haproxy配置文件" class="headerlink" title="编写Haproxy配置文件"></a>编写Haproxy配置文件</h3><p>vi /etc/haproxy/haproxy.cfg</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">global</span><br><span class="line">    log            127.0.0.1 local0</span><br><span class="line">    chroot         /var/lib/haproxy</span><br><span class="line">    pidfile        /var/run/haproxy.pid</span><br><span class="line">    maxconn        4000</span><br><span class="line">    user           root</span><br><span class="line">    group          root</span><br><span class="line">    stats socket   /var/lib/haproxy/stats</span><br><span class="line">    daemon</span><br><span class="line"></span><br><span class="line">listen admin_stats</span><br><span class="line">    stats   enable</span><br><span class="line">    bind    *:8080</span><br><span class="line">    mode    http</span><br><span class="line">    option  httplog</span><br><span class="line">    log     global</span><br><span class="line">    maxconn 10</span><br><span class="line">    stats   refresh 30s</span><br><span class="line">    stats   uri /admin</span><br><span class="line">    stats   realm haproxy</span><br><span class="line">    stats   auth admin:admin</span><br><span class="line">    stats   hide-version</span><br><span class="line">    stats   admin if TRUE</span><br><span class="line"> </span><br><span class="line">listen kube_cluster_api_server</span><br><span class="line">    log                        global</span><br><span class="line">    bind                       192.168.100.110:6443</span><br><span class="line">    mode                       tcp</span><br><span class="line">    option                     tcplog </span><br><span class="line">    timeout http-request       10s</span><br><span class="line">    timeout queue              1m</span><br><span class="line">    timeout connect            10s</span><br><span class="line">    timeout client             1m</span><br><span class="line">    timeout server             1m</span><br><span class="line">    timeout http-keep-alive    10s</span><br><span class="line">    timeout check              10s</span><br><span class="line">    maxconn                    3000</span><br><span class="line">    balance  roundrobin</span><br><span class="line">    server   kube_cluster_master01  192.168.100.111:6443  check  inter 5000 rise 2 fall 3</span><br><span class="line">    server   kube_cluster_master02  192.168.100.112:6443  check  inter 5000 rise 2 fall 3</span><br><span class="line">    server   kube_cluster_master03  192.168.100.113:6443  check  inter 5000 rise 2 fall 3</span><br></pre></td></tr></table></figure><h3 id="创建所需目录"><a href="#创建所需目录" class="headerlink" title="创建所需目录"></a>创建所需目录</h3><p>创建/var/lib/haproxy/stats文件<br>mkdir -p /var/lib/haproxy<br>touch /var/lib/haproxy/stats</p><h3 id="修改内核参数"><a href="#修改内核参数" class="headerlink" title="修改内核参数"></a>修改内核参数</h3><p>vi /etc/sysctl.conf<br>增加如下内容：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.ip_nonlocal_bind = 1  #启动haproxy的时候，允许忽视VIP的存在</span><br><span class="line">net.ipv4.ip_forward = 1  #允许转发</span><br></pre></td></tr></table></figure><p>执行sysctl -p 保存结果，使结果生效<br>如果没有配置以上内核参数，那么haproxy在启动的会报出cannot bind socket的错误</p><h3 id="开放监控页面端口"><a href="#开放监控页面端口" class="headerlink" title="开放监控页面端口"></a>开放监控页面端口</h3><p>iptables -I INPUT -p tcp –dport 8080 -j ACCEPT</p><h3 id="安装验证"><a href="#安装验证" class="headerlink" title="安装验证"></a><strong>安装验证</strong></h3><p>两台机器上都完成了如上的安装配置后</p><h3 id="分别启动Keepalived服务"><a href="#分别启动Keepalived服务" class="headerlink" title="分别启动Keepalived服务"></a>分别启动Keepalived服务</h3><p>systemctl start keepalived </p><h3 id="分别启动Haproxy服务"><a href="#分别启动Haproxy服务" class="headerlink" title="分别启动Haproxy服务"></a>分别启动Haproxy服务</h3><p>systemctl start haproxy<br>分别登陆两台机器查看haproxy服务监控页面：<br><img src="https://oscimg.oschina.net/oscnet/460e6fa0851d1321e48a9ca1586fe4f5568.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/8e9e7e824ef46623dc02f4d441332512053.jpg" alt=""><br>分别查看两台机器的keepalived服务是否正常<br><img src="https://oscimg.oschina.net/oscnet/67fda154626f4c43acfa519c68e0c1642db.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/decd8975c1060bb3b406cc67ca3a3c31366.jpg" alt=""><br>分别停止两台机器keepalived服务查看VIP分配的情况：<br><img src="https://oscimg.oschina.net/oscnet/157602697458db641b811533ff8e1e2a216.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/f79d146070e1b329355dcdf49f647a257f6.jpg" alt=""></p><h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a><strong>常见问题</strong></h2><p>1.configure: error: no acceptable C compiler found in $PATH   See `config.log’ for more details.<br>解决方法：安装gcc库<br>2.!!! OpenSSL is not properly installed on your system. !!!   !!! Can not include OpenSSL headers files.<br>解决方法：安装openssl openssl-devel<br>3.*** WARNING - this build will not support IPVS with IPv6. Please install libnl/libnl-3 dev libraries to support IPv6 with IPVS.<br>解决方法：安装libnl libnl-devel</p>]]></content>
    
    <summary type="html">
    
      K8S(03)模拟生产环境搭建高可用集群之Master节点高可用方案
    
    </summary>
    
    
      <category term="开发运维" scheme="https://www.maxbill.cn/kinds/%E5%BC%80%E5%8F%91%E8%BF%90%E7%BB%B4/"/>
    
    
      <category term="高可用" scheme="https://www.maxbill.cn/marks/%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
    
      <category term="K8S" scheme="https://www.maxbill.cn/marks/K8S/"/>
    
      <category term="Kubernetes" scheme="https://www.maxbill.cn/marks/Kubernetes/"/>
    
      <category term="容器化" scheme="https://www.maxbill.cn/marks/%E5%AE%B9%E5%99%A8%E5%8C%96/"/>
    
      <category term="Haproxy" scheme="https://www.maxbill.cn/marks/Haproxy/"/>
    
      <category term="Keepalived" scheme="https://www.maxbill.cn/marks/Keepalived/"/>
    
  </entry>
  
  <entry>
    <title>K8S(02)模拟生产环境搭建高可用集群之Docker私服</title>
    <link href="https://www.maxbill.cn/1990740722.html"/>
    <id>https://www.maxbill.cn/1990740722.html</id>
    <published>2019-10-27T11:44:03.000Z</published>
    <updated>2020-03-07T08:02:22.816Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>由于kubernetes是对docker容器的编排，kubernetes搭建过程中需要从docker仓库中去拉取所需要的镜像。生产的k8s集群一般是搭建在内网中，因此需要在内网搭建一个Docker仓库私服。</p><h2 id="安装docker服务"><a href="#安装docker服务" class="headerlink" title="安装docker服务"></a><strong>安装docker服务</strong></h2><h3 id="下载docker二进制安装包："><a href="#下载docker二进制安装包：" class="headerlink" title="下载docker二进制安装包："></a>下载docker二进制安装包：</h3><p><a href="https://download.docker.com/linux/static/stable/x86_64/docker-19.03.4.tgz">https://download.docker.com/linux/static/stable/x86_64/docker-19.03.4.tgz</a></p><h3 id="解压docker二进制包"><a href="#解压docker二进制包" class="headerlink" title="解压docker二进制包"></a>解压docker二进制包</h3><p>将下载的docker二进制包上传到服务器上，然后解压：<br>tar -zxvf docker-19.03.4.tgz<br><img src="https://oscimg.oschina.net/oscnet/d759a4c8df94ccea1baed1ebaa13e76b5e7.jpg" alt=""></p><h3 id="移动到系统bin目录"><a href="#移动到系统bin目录" class="headerlink" title="移动到系统bin目录"></a>移动到系统bin目录</h3><p>在解压目录执行：sudo cp docker/* /usr/bin/</p><h3 id="开启-docker-守护进程"><a href="#开启-docker-守护进程" class="headerlink" title="开启 docker 守护进程"></a>开启 docker 守护进程</h3><p>sudo dockerd &amp;<br><img src="https://oscimg.oschina.net/oscnet/ec1a2638e2e57cb50c12aed7b8cecb00dd6.jpg" alt=""><br>此时docker info 可以看到docker服务的信息<br><img src="https://oscimg.oschina.net/oscnet/6e36e9f227e712063e522270f3962fe244f.jpg" alt=""></p><h3 id="增加docker启动参数文件"><a href="#增加docker启动参数文件" class="headerlink" title="增加docker启动参数文件"></a>增加docker启动参数文件</h3><p>sudo cat  &gt; /etc/docker/daemon.json  &lt;&lt;EOF<br>{<br>    “insecure-registries”:[“192.168.100.101”]<br>}<br>EOF</p><h3 id="注册docker为系统服务"><a href="#注册docker为系统服务" class="headerlink" title="注册docker为系统服务"></a>注册docker为系统服务</h3><p>sudo vi /usr/lib/systemd/system/docker.service<br>文件内容如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=Docker Application Container Engine</span><br><span class="line">Documentation=https://docs.docker.com</span><br><span class="line">After=network-online.target firewalld.service</span><br><span class="line">Wants=network-online.target</span><br><span class="line"> </span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line"># the default is not to use systemd for cgroups because the delegate issues still</span><br><span class="line"># exists and systemd currently does not support the cgroup feature set required</span><br><span class="line"># for containers run by docker</span><br><span class="line">ExecStartPost=/sbin/iptables -I FORWARD -s 0.0.0.0/0 -j ACCEPT</span><br><span class="line">ExecStart=/usr/bin/dockerd</span><br><span class="line">ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock </span><br><span class="line">ExecReload=/bin/kill -s HUP $MAINPID</span><br><span class="line"> </span><br><span class="line"># Having non-zero Limit*s causes performance problems due to accounting overhead</span><br><span class="line"># in the kernel. We recommend using cgroups to do container-local accounting.</span><br><span class="line">LimitNOFILE=infinity</span><br><span class="line">LimitNPROC=infinity</span><br><span class="line">LimitCORE=infinity</span><br><span class="line"> </span><br><span class="line"># Uncomment TasksMax if your systemd version supports it.</span><br><span class="line"># Only systemd 226 and above support this version.</span><br><span class="line"># TasksMax=infinity</span><br><span class="line">TimeoutStartSec=0</span><br><span class="line"> </span><br><span class="line"># set delegate yes so that systemd does not reset the cgroups of docker containers</span><br><span class="line">Delegate=yes</span><br><span class="line"> </span><br><span class="line"># kill only the docker process, not all processes in the cgroup</span><br><span class="line">KillMode=process</span><br><span class="line"> </span><br><span class="line"># restart the docker process if it exits prematurely</span><br><span class="line">Restart=on-failure</span><br><span class="line">StartLimitBurst=3</span><br><span class="line">StartLimitInterval=60s</span><br><span class="line"> </span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><p>然后就可使用service docker restart/stop/status 或者systemctl start/stop/status docker 等来操作docker服务<br><img src="https://oscimg.oschina.net/oscnet/fb473408b184be900af5a1d9533eb82e1d3.jpg" alt=""></p><h3 id="添加docker开机自启动"><a href="#添加docker开机自启动" class="headerlink" title="添加docker开机自启动"></a>添加docker开机自启动</h3><p>sudo systemctl enable docker</p><h2 id="安装docker-compose服务"><a href="#安装docker-compose服务" class="headerlink" title="安装docker-compose服务"></a><strong>安装docker-compose服务</strong></h2><h3 id="下载docker-compose二进制包"><a href="#下载docker-compose二进制包" class="headerlink" title="下载docker-compose二进制包"></a>下载docker-compose二进制包</h3><p><a href="https://github.com/docker/compose/releases">https://github.com/docker/compose/releases</a></p><h3 id="上传docker-compose二进制包"><a href="#上传docker-compose二进制包" class="headerlink" title="上传docker-compose二进制包"></a>上传docker-compose二进制包</h3><p>将下载的docker-compose-Linux-x86_64二进制包上传到服务器上</p><h3 id="移动到系统bin目录-1"><a href="#移动到系统bin目录-1" class="headerlink" title="移动到系统bin目录"></a>移动到系统bin目录</h3><p>在上传目录执行：sudo cp docker-compose-Linux-x86_64 /usr/bin/docker-compose<br>给docker-compose添加可执行权限：sudo chmod +x /usr/bin/docker-compose<br>然后docker-compose -v验证下：<br><img src="https://oscimg.oschina.net/oscnet/be83a60cb7e79a48c3762936df7141f342b.jpg" alt=""></p><h2 id="安装harbor服务"><a href="#安装harbor服务" class="headerlink" title="安装harbor服务"></a><strong>安装harbor服务</strong></h2><h3 id="下载harbor离线镜像包"><a href="#下载harbor离线镜像包" class="headerlink" title="下载harbor离线镜像包"></a>下载harbor离线镜像包</h3><p><a href="https://github.com/vmware/harbor/releases或https://github.com/goharbor/harbor/releases">https://github.com/vmware/harbor/releases或https://github.com/goharbor/harbor/releases</a><br><a href="https://storage.googleapis.com/harbor-releases/release-1.9.0/harbor-offline-installer-v1.9.1.tgz">https://storage.googleapis.com/harbor-releases/release-1.9.0/harbor-offline-installer-v1.9.1.tgz</a><br>注：离线安装包中是docker镜像，大概500多MB</p><h3 id="解压harbor离线安装包"><a href="#解压harbor离线安装包" class="headerlink" title="解压harbor离线安装包"></a>解压harbor离线安装包</h3><p>将下载的harbor-offline-installer-v1.9.1.tgz离线安装包上传到服务器上<br>然后解压：tar -zxvf harbor-offline-installer-v1.9.1.tgz<br><img src="https://oscimg.oschina.net/oscnet/3d687f4f896629fd9c9095885e738e0a74c.jpg" alt=""></p><h3 id="创建https证书"><a href="#创建https证书" class="headerlink" title="创建https证书"></a>创建https证书</h3><p>mkdir cert &amp;&amp; cd cert<br>创建https证书，根据官方文档：<a href="https://github.com/goharbor/harbor/blob/master/docs/configure_https.md">https://github.com/goharbor/harbor/blob/master/docs/configure_https.md</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl genrsa -out ca.key 4096</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">openssl req -x509 -new -nodes -sha512 -days 3650 \</span><br><span class="line"> -subj &quot;/C=CN/ST=SH/L=BS/O=GR/OU=MaxBill/CN=registry.maxbill.com&quot; \</span><br><span class="line"> -key ca.key \</span><br><span class="line"> -out ca.crt</span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/c475b29e085512cd55ef76a083e3343fb03.jpg" alt=""><br>openssl genrsa -out registry.maxbill.com.key 4096</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">openssl genrsa -out registry.maxbill.com.key 4096</span><br><span class="line"></span><br><span class="line">openssl req -sha512 -new \</span><br><span class="line"> -subj &quot;/C=CN/ST=SH/L=BS/O=GR/OU=MaxBill/CN=registry.maxbill.com&quot; \</span><br><span class="line"> -key registry.maxbill.com.key \</span><br><span class="line"> -out registry.maxbill.com.csr</span><br><span class="line"></span><br><span class="line">cat &gt; v3.ext &lt;&lt;-EOF</span><br><span class="line">authorityKeyIdentifier=keyid,issuer</span><br><span class="line">basicConstraints=CA:FALSE</span><br><span class="line">keyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment</span><br><span class="line">extendedKeyUsage = serverAuth</span><br><span class="line">subjectAltName = @alt_names</span><br><span class="line"></span><br><span class="line">[alt_names]</span><br><span class="line">DNS.1=registry.maxbill.com</span><br><span class="line">DNS.2=192.168.100.101</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">openssl x509 -req -sha512 -days 3650 \</span><br><span class="line"> -extfile v3.ext \</span><br><span class="line"> -CA ca.crt -CAkey ca.key -CAcreateserial \</span><br><span class="line"> -in registry.maxbill.com.csr \</span><br><span class="line"> -out registry.maxbill.com.crt</span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/4df70d896867ae41f2d8ae7bbd8d42d8980.jpg" alt=""></p><h3 id="修改harbor配置文件"><a href="#修改harbor配置文件" class="headerlink" title="修改harbor配置文件"></a>修改harbor配置文件</h3><p>vi harbor.yml 具体配置如下：<br>修改hostname:  registry.maxbill.com<br>放开https配置：<br>https:<br>   port: 443<br>   certificate: /work/harbor/cert/registry.maxbill.com.crt<br>   private_key: /work/harbor/cert/registry.maxbill.com.key<br>修改harbor_admin_password管理密码：MaxBill2019<br><img src="https://oscimg.oschina.net/oscnet/3ad21e64f0f7d7b0791abc2a186848230a4.jpg" alt=""></p><h3 id="执行安装准备"><a href="#执行安装准备" class="headerlink" title="执行安装准备"></a>执行安装准备</h3><p>在harbor目录下执行  ./prepare<br><img src="https://oscimg.oschina.net/oscnet/e0161a53fa72198c0c46a1fd50232c9a92d.jpg" alt=""></p><h3 id="开始安装操作"><a href="#开始安装操作" class="headerlink" title="开始安装操作"></a>开始安装操作</h3><p>在harbor 目录执行 ./install.sh<br><img src="https://oscimg.oschina.net/oscnet/a1a40b3204c2b10c6d722f863c6d235d579.jpg" alt=""><br>等待安装程序打印如下日志，说明安装完成：<br><img src="https://oscimg.oschina.net/oscnet/8f16486438fa1976f719d922bef849b5614.jpg" alt=""></p><h2 id="安装验证"><a href="#安装验证" class="headerlink" title="安装验证"></a><strong>安装验证</strong></h2><p>在docker中看下启动的容器：<br>docker ps<br><img src="https://oscimg.oschina.net/oscnet/e5c075cc3ec9b645cfba11173c380fd93f1.jpg" alt=""><br>在浏览器中<a href="https://192.168.100.101或者https://registry.maxbill.com访问：">https://192.168.100.101或者https://registry.maxbill.com访问：</a><br><img src="https://oscimg.oschina.net/oscnet/912129c4bfce37a9235241d9066d5c6c87a.jpg" alt=""><br>使用上面配置的账户登录：admin/MaxBill2019<br><img src="https://oscimg.oschina.net/oscnet/7daa22ce1ca5f84c62ff3e026133cd0b0bd.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      K8S(02)模拟生产环境搭建高可用集群之Docker私服
    
    </summary>
    
    
      <category term="开发运维" scheme="https://www.maxbill.cn/kinds/%E5%BC%80%E5%8F%91%E8%BF%90%E7%BB%B4/"/>
    
    
      <category term="K8S" scheme="https://www.maxbill.cn/marks/K8S/"/>
    
      <category term="Kubernetes" scheme="https://www.maxbill.cn/marks/Kubernetes/"/>
    
      <category term="Docker" scheme="https://www.maxbill.cn/marks/Docker/"/>
    
      <category term="容器化" scheme="https://www.maxbill.cn/marks/%E5%AE%B9%E5%99%A8%E5%8C%96/"/>
    
      <category term="Harbor" scheme="https://www.maxbill.cn/marks/Harbor/"/>
    
      <category term="容器编排" scheme="https://www.maxbill.cn/marks/%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92/"/>
    
  </entry>
  
  <entry>
    <title>K8S(01)模拟生产环境搭建高可用集群之环境规划和基础准备</title>
    <link href="https://www.maxbill.cn/1686052618.html"/>
    <id>https://www.maxbill.cn/1686052618.html</id>
    <published>2019-10-27T06:42:03.000Z</published>
    <updated>2020-03-07T08:02:15.229Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在微服务盛行的今天，大大小小的公司都在实践自己的微服务架构。并且近年来又兴起了以istio为代表的Service Mesh技术体系，专注为服务之间的网络调用、限流、熔断和监控等，解耦了微服务业务。随着微服务业务增加，那么使用传统的管理和部署方式显然成本很高，而且对于开发人员的专业素质有很高要。于是后面出现了容器化技术，将微服务结合自动化发布技术部署在docker容器中。但是随着业务不断增长，越来越多的容器很难管理，于是出现了容器编排技术，目前占据份额最多的当属google开源的kubernetes项目。从本文开始将会从0开始模拟搭建一个高可用的kubernetes集群，由于生产环境机器一般不允许访问外部网络，因此我们这个系列的实践都是在断网下使用二进制部署。</p><h2 id="模拟环境机器规划"><a href="#模拟环境机器规划" class="headerlink" title="模拟环境机器规划"></a><strong>模拟环境机器规划</strong></h2><p><img src="https://oscimg.oschina.net/oscnet/7c4df5a8f7b585c3e72ea218732388809b6.jpg" alt=""></p><h2 id="集群环境说明"><a href="#集群环境说明" class="headerlink" title="集群环境说明"></a><strong>集群环境说明</strong></h2><p>操作系统：CentOS7.7<br>Kubernetes版本：1.16.2<br>Docker版本：19.03</p><h2 id="集群主控和工作节点基础准备"><a href="#集群主控和工作节点基础准备" class="headerlink" title="集群主控和工作节点基础准备"></a><strong>集群主控和工作节点基础准备</strong></h2><h3 id="配置hosts文件"><a href="#配置hosts文件" class="headerlink" title="配置hosts文件"></a>配置hosts文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sudo cat &gt;&gt; /etc/hosts&lt;&lt;<span class="string">EOF  </span></span><br><span class="line"><span class="string">   192.168.100.111  kube_cluster_master01  </span></span><br><span class="line"><span class="string">   192.168.100.112  kube_cluster_master02  </span></span><br><span class="line"><span class="string">   192.168.100.113  kube_cluster_master03  </span></span><br><span class="line"><span class="string">   192.168.100.114  kube_cluster_minion01  </span></span><br><span class="line"><span class="string">   192.168.100.115  kube_cluster_minion02  </span></span><br><span class="line"><span class="string">   192.168.100.116  kube_cluster_minion03  </span></span><br><span class="line"><span class="string">   192.168.100.117  kube_cluster_minion04  </span></span><br><span class="line"><span class="string">   192.168.100.118  kube_cluster_minion05  </span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/d7ba831bd3139007e63490aa7a1592ce2cd.jpg" alt=""></p><h3 id="修改hostname文件"><a href="#修改hostname文件" class="headerlink" title="修改hostname文件"></a>修改hostname文件</h3><p>sudo hostnamectl set-hostname <newhostname><br><img src="https://oscimg.oschina.net/oscnet/a0a34fd97eaed7c42b1ef5433a9f77ed925.jpg" alt=""><br>修改完成logout或者重启启动就可看到修改结果</p><h3 id="关闭系统防火墙"><a href="#关闭系统防火墙" class="headerlink" title="关闭系统防火墙"></a>关闭系统防火墙</h3><p>sudo systemctl stop firewalld &amp;&amp; systemctl disable firewalld<br><img src="https://oscimg.oschina.net/oscnet/6d66838d89bd0bd8ba170d01be7ec41bea7.jpg" alt=""></p><h3 id="禁用swap内存交换"><a href="#禁用swap内存交换" class="headerlink" title="禁用swap内存交换"></a>禁用swap内存交换</h3><p>sudo swapoff -a &amp;&amp; sudo echo “swapoff -a” &gt;&gt;/etc/rc.d/rc.local &amp;&amp; sudo chmod +x /etc/rc.d/rc.local<br><img src="https://oscimg.oschina.net/oscnet/3ae23d7eccce6bb0db3bffbef87436daa68.jpg" alt=""></p><h3 id="关闭系统selinux"><a href="#关闭系统selinux" class="headerlink" title="关闭系统selinux"></a>关闭系统selinux</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo setenforce 0</span><br><span class="line">sudo sed -i <span class="string">&#x27;s/SELINUX=enforcing/SELINUX=disabled/g&#x27;</span> /etc/sysconfig/selinux</span><br><span class="line">sudo sed -i <span class="string">&#x27;s/SELINUX=enforcing/SELINUX=disabled/g&#x27;</span> /etc/selinux/config</span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/eea01fb3c11d0cf96caaa70632394b0725d.jpg" alt=""></p><h3 id="修改系统内核参数"><a href="#修改系统内核参数" class="headerlink" title="修改系统内核参数"></a>修改系统内核参数</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sudo cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt;<span class="string">EOF  </span></span><br><span class="line"><span class="string">   net.bridge.bridge-nf-call-ip6tables = 1  </span></span><br><span class="line"><span class="string">   net.bridge.bridge-nf-call-iptables = 1  </span></span><br><span class="line"><span class="string">   net.ipv4.ip_forward = 1  </span></span><br><span class="line"><span class="string">   net.ipv4.ip\_local\_port_range = 10000 65000  </span></span><br><span class="line"><span class="string">   fs.file-max = 2000000  </span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line">sudo sysctl --system</span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/0120b8356b4dbfee2dd6709ffda2fb0769d.jpg" alt=""></p><h3 id="校对系统时间"><a href="#校对系统时间" class="headerlink" title="校对系统时间"></a>校对系统时间</h3><p>搭建内网时间校正服务器，本文将时间服务器部署于192.168.100.101上，搭建服务步骤：<br>下载ntp-dev-4.3.99.tar.gz二进制包，解压：tar -zxvf ntp-dev-4.3.99.tar.gz<br>进入解压目录执行 ./configure<br>然后执行编译安装 make &amp;&amp; make install<br>sudo vi /etc/ntp.conf 修改配置文件，如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># For more information about this file, see the man pages</span><br><span class="line"># ntp.conf(5), ntp_acc(5), ntp_auth(5), ntp_clock(5), ntp_misc(5), ntp_mon(5).</span><br><span class="line"></span><br><span class="line">driftfile /var/lib/ntp/drift</span><br><span class="line">restrict default nomodify</span><br><span class="line"></span><br><span class="line">restrict 127.0.0.1</span><br><span class="line">restrict ::1</span><br><span class="line">restrict 192.168.100.0 mask 255.255.254.0 nomodify</span><br><span class="line"></span><br><span class="line">server ntp1.aliyun.com</span><br><span class="line">server ntp2.aliyun.com</span><br><span class="line">server ntp3.aliyun.com</span><br><span class="line">server 127.127.1.0</span><br><span class="line">fudge 127.127.1.0 stratum 8</span><br><span class="line"></span><br><span class="line">logfile /var/lib/ntp/ntp.log</span><br><span class="line">disable monitor</span><br></pre></td></tr></table></figure><p>mkdir /var/lib/ntp<br>touch /var/lib/ntp/ntp.log<br>sudo vi /usr/lib/systemd/system/ntpd.service    如下：编写ntp服务配置文件，如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=ntpd</span><br><span class="line">After=syslog.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=forking</span><br><span class="line">ExecStart=/usr/local/bin/ntpd -c /etc/ntpd.conf -p /var/run/ntpd.pid -g</span><br><span class="line">PrivateTmp=true</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><p>使用iptables -F暂停防火墙，然后启动ntp服务systemctl enable ntpd &amp;&amp; systemctl start ntpd<br>集群中的机器将101服务器上的/usr/local/bin/ntpdate文件拷贝到自己对应的目录下<br>集群中的机器都使用ntpdate -d 192.168.100.101同步时间，然后将同步的系统时间写入biso，如下：<br><img src="https://oscimg.oschina.net/oscnet/07526226156ae0df25f521f093bd08bef94.jpg" alt=""><br>其他方案：使用终端同时给个机器设置时间：date -s “2019-11-03 22:18:00”  （修改成当期时间），使用clock -w把系统时间写入CMOS，使用hwclock -w将系统时间写入BISO</p><h2 id="集群搭建所需安装包"><a href="#集群搭建所需安装包" class="headerlink" title="集群搭建所需安装包"></a><strong>集群搭建所需安装包</strong></h2><p>ntp：<a href="http://www.ntp.org/downloads.html">http://www.ntp.org/downloads.html</a><br>kubernetes：<a href="https://github.com/kubernetes/kubernetes/releases">https://github.com/kubernetes/kubernetes/releases</a><br>docker：<a href="https://download.docker.com">https://download.docker.com</a><br>docker-compose：<a href="https://github.com/docker/compose/releases">https://github.com/docker/compose/releases</a></p>]]></content>
    
    <summary type="html">
    
      K8S(01)模拟生产环境搭建高可用集群之环境规划和基础准备
    
    </summary>
    
    
      <category term="开发运维" scheme="https://www.maxbill.cn/kinds/%E5%BC%80%E5%8F%91%E8%BF%90%E7%BB%B4/"/>
    
    
      <category term="高可用" scheme="https://www.maxbill.cn/marks/%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
    
      <category term="K8S" scheme="https://www.maxbill.cn/marks/K8S/"/>
    
      <category term="Kubernetes" scheme="https://www.maxbill.cn/marks/Kubernetes/"/>
    
      <category term="Docker" scheme="https://www.maxbill.cn/marks/Docker/"/>
    
      <category term="Docker-Compose" scheme="https://www.maxbill.cn/marks/Docker-Compose/"/>
    
      <category term="NTP" scheme="https://www.maxbill.cn/marks/NTP/"/>
    
      <category term="容器化" scheme="https://www.maxbill.cn/marks/%E5%AE%B9%E5%99%A8%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>使用Kubeadm部署Kubernetes集群V1.15.3</title>
    <link href="https://www.maxbill.cn/2789679519.html"/>
    <id>https://www.maxbill.cn/2789679519.html</id>
    <published>2019-10-10T02:54:11.000Z</published>
    <updated>2020-03-07T08:01:59.102Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>上文我们使用最新的kubernetes v1.16.0搭建了集群，但是由于版本导致了遇到问题，首先是dashboard不兼容1.16.0的Api，其次是flannel-cni的问题，本文重新用稳定版v1.15.3部署。</p><h2 id="基础环境配置"><a href="#基础环境配置" class="headerlink" title="基础环境配置"></a><strong>基础环境配置</strong></h2><h3 id="准备三台虚拟机"><a href="#准备三台虚拟机" class="headerlink" title="准备三台虚拟机"></a><strong>准备三台虚拟机</strong></h3><p>docker   192.168.100.10<br>node01  192.168.100.11   kube-node01    master<br>node01  192.168.100.12   kube-node02   minion<br>node01  192.168.100.13   kube-node03   minion</p><h3 id="配置hosts文件"><a href="#配置hosts文件" class="headerlink" title="配置hosts文件"></a><strong>配置hosts文件</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;&gt; /etc/hosts&lt;&lt;<span class="string">EOF  </span></span><br><span class="line"><span class="string">192.168.100.11  kube-node01  </span></span><br><span class="line"><span class="string">192.168.100.12  kube-node02  </span></span><br><span class="line"><span class="string">192.168.100.13  kube-node03  </span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/0319b6e16b50117879988c119c156d8f8a9.jpg" alt=""></p><h3 id="修改hostname文件"><a href="#修改hostname文件" class="headerlink" title="修改hostname文件"></a><strong>修改hostname文件</strong></h3><p>sudo hostnamectl set-hostname <newhostname><br><img src="https://oscimg.oschina.net/oscnet/da6551d5e38dd9d724694d4cad5d108cd66.jpg" alt=""></p><h3 id="关闭系统防火墙"><a href="#关闭系统防火墙" class="headerlink" title="关闭系统防火墙"></a><strong>关闭系统防火墙</strong></h3><p>systemctl stop firewalld &amp;&amp; systemctl disable firewalld<br><img src="https://oscimg.oschina.net/oscnet/c305c5f5eabf010c7c5c4bcd22eb8d83770.jpg" alt=""></p><h3 id="禁用swap内存交换"><a href="#禁用swap内存交换" class="headerlink" title="禁用swap内存交换"></a><strong>禁用swap内存交换</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">swapoff -a</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;swapoff -a&quot;</span> &gt;&gt;/etc/rc.d/rc.local</span><br><span class="line">chmod +x /etc/rc.d/rc.local</span><br></pre></td></tr></table></figure><p>注意：或开机禁用swap: 编辑/etc/fstab –&gt; 注释掉swap 分区<br><img src="https://oscimg.oschina.net/oscnet/1797225f8eeaca27851a1caeec06057e61f.jpg" alt=""></p><h3 id="关闭selinux服务"><a href="#关闭selinux服务" class="headerlink" title="关闭selinux服务"></a><strong>关闭selinux服务</strong></h3><p>临时关闭：setenforce 0    永久关闭：vi /etc/selinux/config<br>将SELINUX=enforcing改为SELINUX=disabled 设置后需要重启才能生效，命令如下：<br>sed -i ‘s/SELINUX=enforcing/SELINUX=disabled/g’ /etc/sysconfig/selinux<br><img src="https://oscimg.oschina.net/oscnet/6995fb480ed1a583e8cfef2023e5ce0906e.jpg" alt=""></p><h3 id="配置iptable管理ipv4-6请求"><a href="#配置iptable管理ipv4-6请求" class="headerlink" title="配置iptable管理ipv4/6请求"></a><strong>配置iptable管理ipv4/6请求</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo <span class="built_in">echo</span> <span class="string">&quot;1&quot;</span> &gt; /proc/sys/net/ipv4/ip_forward</span><br><span class="line">cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">net.bridge.bridge-nf-call-ip6tables = 1</span></span><br><span class="line"><span class="string">net.bridge.bridge-nf-call-iptables = 1</span></span><br><span class="line"><span class="string">net.ipv4.ip_forward = 1</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p>执行 sysctl –system 使配置生效<br><img src="https://oscimg.oschina.net/oscnet/9a1907f3bf66bead36b3893e22826d0cd18.jpg" alt=""></p><h3 id="校对系统时间"><a href="#校对系统时间" class="headerlink" title="校对系统时间"></a><strong>校对系统时间</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum -y install ntp</span><br><span class="line">systemctl start ntpd &amp;&amp; systemctl <span class="built_in">enable</span> ntpd</span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/c10f937aab86084671593b89e2ba6000275.jpg" alt=""></p><h2 id="集群环境配置"><a href="#集群环境配置" class="headerlink" title="集群环境配置"></a><strong>集群环境配置</strong></h2><h3 id="安装docker服务"><a href="#安装docker服务" class="headerlink" title="安装docker服务"></a><strong>安装docker服务</strong></h3><p>配置源wget <a href="https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo">https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</a> -O /etc/yum.repos.d/docker-ce.repo<br><img src="https://oscimg.oschina.net/oscnet/026e85ed00c313a2d1908b4f7c2087c22e9.jpg" alt=""><br>安装docker-ce容器服务：yum -y install docker-ce<br>查看docker版本号：docker –version和详细信息：docker info<br><img src="https://oscimg.oschina.net/oscnet/0c3b645ebb3076d0dae95ccfbe2766161b7.jpg" alt=""><br>添加开机自启动和启动服务：systemctl enable docker &amp;&amp; systemctl start docker<br>修改docker启动参数：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cat  &gt; /etc/docker/daemon.json  &lt;&lt;<span class="string">EOF  </span></span><br><span class="line"><span class="string">&#123;  </span></span><br><span class="line"><span class="string">     &quot;registry-mirrors&quot;: [&quot;http://192.168.100.10&quot;],  </span></span><br><span class="line"><span class="string">     &quot;insecure-registries&quot;:\[&quot;192.168.100.10&quot;\],  </span></span><br><span class="line"><span class="string">     &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;]  </span></span><br><span class="line"><span class="string">&#125;  </span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/dcf287e79f8234e078ee661b8f49916375c.jpg" alt=""><br>修改docker的启动服务脚本docker.service：<br>在[Service]节点下增加：ExecStartPost=/sbin/iptables -I FORWARD -s 0.0.0.0/0 -j ACCEPT<br>修改完成使用：systemctl daemon-reload &amp;&amp; systemctl restart docker重启服务<br><img src="https://oscimg.oschina.net/oscnet/d0201c00597072c73e807235c03819663aa.jpg" alt=""></p><h3 id="安装Kubernetes组件"><a href="#安装Kubernetes组件" class="headerlink" title="安装Kubernetes组件"></a><strong>安装Kubernetes组件</strong></h3><p>配置源：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">[kubernetes]</span></span><br><span class="line"><span class="string">name=Kubernetes</span></span><br><span class="line"><span class="string">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64</span></span><br><span class="line"><span class="string">enabled=1</span></span><br><span class="line"><span class="string">gpgcheck=0</span></span><br><span class="line"><span class="string">repo_gpgcheck=0</span></span><br><span class="line"><span class="string">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p>安装组件：yum install -y kubelet-1.15.3 kubeadm-1.15.3 kubectl-1.15.3</p><h3 id="配置启动kubelet-组件"><a href="#配置启动kubelet-组件" class="headerlink" title="配置启动kubelet 组件"></a><strong>配置启动kubelet 组件</strong></h3><p>配置kubelet使用国内pause镜像和配置kubelet的cgroups：<br>cgroups要和docker的配置一样，使用dokcer info可查看<br>vi /var/lib/kubelet/kubeadm-flags.env<br><img src="https://oscimg.oschina.net/oscnet/3544ec249616a95184b088ced53a0ec7267.jpg" alt=""><br>vi /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf<br>添加环境变量：<br>Environment=”KUBELET_CGROUP_ARGS=–runtime-cgroups=/systemd/system.slice –kubelet-cgroups=/systemd/system.slice”<br>并将环境变量KUBELET_CGROUP_ARGS写入启动参数<br><img src="https://oscimg.oschina.net/oscnet/5999cf65c487f78e164c2a0e80f8958cfe8.jpg" alt=""><br>如果上面/var/lib/kubelet/kubeadm-flags.env没有cgroup-driver和pod-infra-container-image的信息，则写入/etc/sysconfig/kubelet的KUBELET_EXTRA_ARGS启动参数中加载</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;/etc/sysconfig/kubelet&lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">KUBELET_EXTRA_ARGS=--cgroup-driver=systemd --pod-infra-container-image=192.168.100.10/kubernetes/pause:3.1 </span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p>使配置生效：systemctl daemon-reload<br>添加自启动：systemctl enable kubelet</p><h3 id="配置Master节点"><a href="#配置Master节点" class="headerlink" title="配置Master节点"></a><strong>配置Master节点</strong></h3><p>在master节点上创建初始化脚本：vi /etc/kubernetes/conf/kubeadm-init.sh</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init \</span><br><span class="line">--kubernetes-version=v1.16.0 \</span><br><span class="line">--pod-network-cidr=10.244.0.0/16 \</span><br><span class="line">--apiserver-advertise-address=192.168.100.11 \</span><br><span class="line">--image-repository=192.168.100.10/kubernetes</span><br></pre></td></tr></table></figure><p>修改脚本权限：chmod +x /etc/kubernetes/conf/kubeadm-init.sh<br><img src="https://oscimg.oschina.net/oscnet/affc17b9a78236b9f9585c363c7006fe1e8.jpg" alt=""><br>由于初始化时,默认会从k8s.gcr.io拉取镜像，该镜像被墙，这里从私有docker镜像库拉取，由–image-repository=192.168.100.10/kubernetes指定<br>私有docker镜像库搭建请参照我的另一篇博文：《Docker搭建私有镜像仓库》</p><h3 id="5-初始化Master节点"><a href="#5-初始化Master节点" class="headerlink" title="5.初始化Master节点"></a><strong>5.初始化Master节点</strong></h3><p>初始化时及搭建集群过程中所需要的所有镜像我们都已托管到我们私有镜像仓库中：<br><img src="https://oscimg.oschina.net/oscnet/faaf9dd1033c7d2b464f0846f11ac83b849.jpg" alt=""><br>执行/etc/kubernetes/conf/kubeadm-init.sh此时会初始化<br>注意：如果初始化过程出现问题，使用如下命令重置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubeadm reset</span><br><span class="line">rm -rf /var/lib/cni/ <span class="variable">$HOME</span>/.kube/config</span><br></pre></td></tr></table></figure><p>初始化成功如下图：<br><img src="https://oscimg.oschina.net/oscnet/fdd1fa22677601d240a0a67718999807e2a.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/e0992fa8a61bc4e64be6ea2ba6601bbc302.jpg" alt=""></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join 192.168.100.11:6443</span><br><span class="line">--token qjqxwd.2k79lzjvxc3t6hsj</span><br><span class="line">--discovery-token-ca-cert-hash sha256:091e12d369cd83fda3187b5eddb1d07db074b220ff32cb0f21d8b82fc19d4ccb</span><br></pre></td></tr></table></figure><p>上面这一句是给其他节点加入集群用的，要保存下来，后面要用。<br>配置master上通过 kubectl 管理集群，执行下面的命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rm -rf <span class="variable">$HOME</span>/.kube</span><br><span class="line">mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/3f68065602893b60818cf6bb1b4d26b09be.jpg" alt=""><br>使用kubectl get nodes -owide查看刚初始化的主节点信息：<br><img src="https://oscimg.oschina.net/oscnet/5f73462ff88f08d9126a5f5cc4b4b330267.jpg" alt=""><br>我们看到master节点的状态时未就绪状态，需要配置使用网络flannel插件:<br>下载flannel配置文件：<br>wget -P /etc/kubernetes/conf<br><a href="https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml">https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</a><br>修改下载的flannel.yml文件，删除多余部分，并指定网卡信息:<br><img src="https://oscimg.oschina.net/oscnet/c3d4567475b24d242a3c4e465b54111ae4a.jpg" alt=""><br>启动flannel组件：kubectl apply -f /etc/kubernetes/conf/kube-flannel.yml<br><img src="https://oscimg.oschina.net/oscnet/e921c6ee6949be29786f7053f57444a8f2d.jpg" alt=""></p><h3 id="加入各Node节"><a href="#加入各Node节" class="headerlink" title="加入各Node节"></a><strong>加入各Node节</strong></h3><p>在每个节点的机器上执行下面的加入集群的命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join 192.168.100.11:6443</span><br><span class="line">--token qjqxwd.2k79lzjvxc3t6hsj</span><br><span class="line">--discovery-token-ca-cert-hash sha256:091e12d369cd83fda3187b5eddb1d07db074b220ff32cb0f21d8b82fc19d4ccb</span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/0636c3b5a2fdc4acb4148a73e9141b58147.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/1b4ae74e81ba8940199a1eb60f9c820ea53.jpg" alt=""></p><h3 id="部署Kubernetes-Web"><a href="#部署Kubernetes-Web" class="headerlink" title="部署Kubernetes Web"></a><strong>部署Kubernetes Web</strong></h3><p>从kubernetes官方github下载配置文件：<br>wget /etc/kubernetes/conf <a href="https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml">https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml</a><br><img src="https://oscimg.oschina.net/oscnet/56dd471194751085a76e0b47901e3169323.jpg" alt=""><br>修改配置文件访问类型为：NodePort<br><img src="https://oscimg.oschina.net/oscnet/7c63aa1e6c0ab449eb224199d0676fdb50c.jpg" alt=""><br>启动webui组件：kubectl apply -f /etc/kubernetes/conf/kubernetes-dashboard.yaml<br><img src="https://oscimg.oschina.net/oscnet/625ebeeca873be3eed8caad001a40c81bc0.jpg" alt=""><br>查看dashboard pod的状态：kubectl get pods -n kube-system -owide<br><img src="https://oscimg.oschina.net/oscnet/e297230b7630659e0776f6046afe001b2b4.jpg" alt=""><br>然后通过：<a href="https://192.168.100.11:31080/访问">https://192.168.100.11:31080/访问</a><br><img src="https://oscimg.oschina.net/oscnet/38990c2aa29501a0993d4a892fe6c032c68.jpg" alt=""><br>我们看到有两种访问方式，下面我们配置这两种访问方式：<br>我们创建dashboard用户yaml文件：<br>vi  /etc/kubernetes/conf/kubernetes-dashboard-admin.yaml </p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># Create Dashboard Service Account</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: dashboard-admin-user</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line"># Create ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: dashboard-admin-user</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: dashboard-admin-user</span><br><span class="line">  namespace: kube-system</span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/5993823158679643266f60d639fb664420a.jpg" alt=""><br>然后kubectl apply -f /etc/kubernetes/conf/kubernetes-dashboard-user.yaml<br>完成后执行kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep dashboard-admin-user | awk ‘{print $1}’)  查看token<br><img src="https://oscimg.oschina.net/oscnet/1c1aff3b1ec24d1517a0a26dbb2d839f0d0.jpg" alt=""><br>获取的token即可用来在页面上输入登录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkYXNoYm9hcmQtYWRtaW4tdXNlci10b2tlbi13NGg1biIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJkYXNoYm9hcmQtYWRtaW4tdXNlciIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6ImNjNzE5NTMwLWY0NDAtNGNmYi1hNDkwLTZiZjkzNWNkMDYxOCIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlLXN5c3RlbTpkYXNoYm9hcmQtYWRtaW4tdXNlciJ9.No8ic7iNedWgX9iX1cIPHrK81vDTApsayPHm2U5No65yndQX7l_GgE8Ze-oTqx1JQVN85EWdJGM4T_LdbxflkIiBElmKRST7m3VpAeLgNl1f56NyyUwf0GEVzsdZdhb0E-i1DJO0ofXkqQiHwtcpWMmq4wqlYymu_fDxblJl4LzTpPUV89emPSQhSA3ZopbNBKJr6u5kRYgsTiz8EGAhRRqWGzCyEkyp8Y_SJlYsnXXx-F8gmneBiyaqeCrNiO71eczz6sQDsEI37fhxs41xeLJNF7sA2LihAE9KD3YBBgRjxxMmfmsGb-IkTn68bhhsHiCN0AMW5xJFSXNiLyWGMQ</span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/48b61cf8af7ce5faf7fe48b82fbfa242b22.jpg" alt=""><br>此时的dashboard没有展示cpu、内存等图标可视化信息，我们需要安装heapster服务（因为dashboard要显示图表数据需要依赖heapster服务）<br>下载 heapster 相关 yaml 文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget /etc/kubernetes/heapster https://raw.githubusercontent.com/kubernetes-retired/heapster/master/deploy/kube-config/influxdb/grafana.yaml</span><br><span class="line">wget /etc/kubernetes/heapster https://raw.githubusercontent.com/kubernetes-retired/heapster/master/deploy/kube-config/influxdb/heapster.yaml</span><br><span class="line">wget /etc/kubernetes/heapster https://raw.githubusercontent.com/kubernetes-retired/heapster/master/deploy/kube-config/influxdb/influxdb.yaml</span><br><span class="line">wget /etc/kubernetes/heapster https://raw.githubusercontent.com/kubernetes-retired/heapster/master/deploy/kube-config/rbac/heapster-rbac.yaml</span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/9c16e69481289641e3d8f24efba2f719d0d.jpg" alt=""><br>查看需要部署的镜像：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cat grafana.yaml | grep image</span><br><span class="line">cat heapster.yaml | grep image</span><br><span class="line">cat influxdb.yaml | grep image</span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/ea358a345d37b00d13d28997965ab159e82.jpg" alt=""><br>修改yaml文件：<br>因为k8s高版本的api版本进行了变化，将上面四个yaml文件中的apiVersion: extensions/v1beta1 改为apiVersion: apps/v1<br>因为kubelet 只在 10250 监听 https 请求，将heapster.yaml中的- –source=kubernetes:<a href="https://kubernetes.default">https://kubernetes.default</a>  修改为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">- --<span class="built_in">source</span>=kubernetes:https://kubernetes.default?kubeletHttps=<span class="literal">true</span>&amp;kubeletPort=10250&amp;insecure=<span class="literal">true</span></span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/93e4a3e82c2fc5a31c53892a7be7c0f6f7f.jpg" alt=""><br>修改上面四个yaml文件中的spec节点，增加selector，如下图：<br><img src="https://oscimg.oschina.net/oscnet/492ead32405f234b56cff60ff5fe54db76f.jpg" alt=""><br>然后在heapster配置文件的当前目录下执行部署：kubectl apply -f .<br>注意：如果部署发生错误，我们执行kubectl delete -f . 进行回退<br>Heapster各个组件部署成功如下：<br><img src="https://oscimg.oschina.net/oscnet/82d20a52939c36e5bd7520deffb0f081107.jpg" alt=""><br>然后我们生成使用config登录的文件：<br>##将secret中的token使用base64方式进行解码，然后使用变量引用<br>DASH_TOCKEN=$(kubectl get secret -n kube-system dashboard-admin-token-q6pz8 -o jsonpath={.data.token}|base64 -d)<br>##创建一个集群<br>kubectl config set-cluster cluster-admin –server=192.168.100.11:6443 –kubeconfig=/etc/kubernetes/conf/dashbord-admin.conf<br>##创建一个集群用户，并引用sa的token<br>kubectl config set-credentials dashboard-admin-user –token=$DASH_TOCKEN –kubeconfig=/etc/kubernetes/conf/dashbord-admin.conf<br> ##创建一个上下文，指定集群名、集群用户名<br>kubectl config set-context dashboard-admin-user@cluster-admin –cluster=cluster-admin –user=dashboard-admin-user<br>–kubeconfig=/etc/kubernetes/conf/dashbord-admin.conf<br>##设置集群中当前使用的用户<br>kubectl config use-context dashboard-admin-user@cluster-admin –kubeconfig=/etc/kubernetes/conf/dashbord-admin.conf<br>然后使用token或生成的文件登录成功如下：<br><img src="https://oscimg.oschina.net/oscnet/486d238d714622e84cc5532e72b39f7ece2.jpg" alt=""></p><h3 id="验证集群状态"><a href="#验证集群状态" class="headerlink" title="验证集群状态"></a><strong>验证集群状态</strong></h3><p>使用kubectl get nodes -n kube-system -owide 查看节点列表<br><img src="https://oscimg.oschina.net/oscnet/ef623959b9b69b4e700ce0a8ff2c7b44485.jpg" alt=""><br>使用kubectl get pods -n kube-system -owide查看pod列表<br><img src="https://oscimg.oschina.net/oscnet/630cc3ccd4fe301b8d1dbaab3dd803dcb11.jpg" alt=""><br>使用kubectl get svc -n kube-system -owide 查看服务列表<br><img src="https://oscimg.oschina.net/oscnet/cf083a56faec4befe828aeccf448392f2d9.jpg" alt=""></p><h2 id="集群问题解决"><a href="#集群问题解决" class="headerlink" title="集群问题解决"></a><strong>集群问题解决</strong></h2><h3 id="初始化集群异常"><a href="#初始化集群异常" class="headerlink" title="初始化集群异常"></a>初始化集群异常</h3><p>问题描述：执行kubeadm init时报出/proc/sys/net/ipv4/ip_forward contents are not set to 1的错误<br>解决方案：sudo echo “1” &gt; /proc/sys/net/ipv4/ip_forward</p><h3 id="部署heapster提示版本问题"><a href="#部署heapster提示版本问题" class="headerlink" title="部署heapster提示版本问题"></a>部署heapster提示版本问题</h3><p>问题描述：部署heapster 组件提示no matches for king “Deployment” in version “extensions/v1beta1”<br><img src="https://oscimg.oschina.net/oscnet/9a00ca3e6bd3de71d55b81a9fe78df30fea.jpg" alt=""><br>解决方案：是因为k8s高版本的api版本进行了变化，将对应的yaml文件中的extensions/v1beta1 改为apiVersion: apps/v1</p><h3 id="部署heapster提示selector错误"><a href="#部署heapster提示selector错误" class="headerlink" title="部署heapster提示selector错误"></a>部署heapster提示selector错误</h3><p>问题描述：部署heapster 组件提示missing required field “selector” in io.k8s.api.apps.v1.DeploymentSpec的错误<br><img src="https://oscimg.oschina.net/oscnet/cdc2377691d33cb655ea8062c1635fb22cb.jpg" alt=""><br>解决方案：修改heapster上面四个yaml文件中的spec节点，增加selector，如下图：<br><img src="https://oscimg.oschina.net/oscnet/6ad2d45b203c8522bb259fec4043f635f4f.jpg" alt=""></p><h3 id="部署heapster后不显示图表信息"><a href="#部署heapster后不显示图表信息" class="headerlink" title="部署heapster后不显示图表信息"></a>部署heapster后不显示图表信息</h3><p>问题描述：heapster正常部署后，pods状态都正常，但是dashboard不显示图表信息<br>查看pods的日志，发现一直提示“403 Forbidden”, response: “Forbidden (user=system:serviceaccount:kube-system:heapster, verb=create, resource=nodes, subresource=stats)”<br>解决方案：<br>查看ClusterRole: system:heapster的权限，发现的确没有针对Resource: nodes/stats 的create权限<br>kubectl describe clusterrole system:heapster<br>添加Resource: nodes/stats的create权限，vi /etc/kubernetes/conf/heapster/heapster-role.yaml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: system:heapster</span><br><span class="line">rules:</span><br><span class="line">- apiGroups:</span><br><span class="line">  - &quot;&quot;</span><br><span class="line">  resources:</span><br><span class="line">  - events</span><br><span class="line">  - namespaces</span><br><span class="line">  - nodes</span><br><span class="line">  - pods</span><br><span class="line">  - nodes/stats</span><br><span class="line">  verbs:</span><br><span class="line">  - create</span><br><span class="line">  - get</span><br><span class="line">  - list</span><br><span class="line">  - watch</span><br><span class="line">- apiGroups:</span><br><span class="line">  - extensions</span><br><span class="line">  resources:</span><br><span class="line">  - deployments</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line">  - list</span><br><span class="line">  - watch</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /etc/kubernetes/conf/heapster</span><br><span class="line">kubectl delete -f .</span><br><span class="line">kubectl apply -f .</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      使用Kubeadm部署Kubernetes集群V1.15.3
    
    </summary>
    
    
      <category term="开发运维" scheme="https://www.maxbill.cn/kinds/%E5%BC%80%E5%8F%91%E8%BF%90%E7%BB%B4/"/>
    
    
      <category term="K8S" scheme="https://www.maxbill.cn/marks/K8S/"/>
    
      <category term="Kubernetes" scheme="https://www.maxbill.cn/marks/Kubernetes/"/>
    
      <category term="容器化" scheme="https://www.maxbill.cn/marks/%E5%AE%B9%E5%99%A8%E5%8C%96/"/>
    
      <category term="容器编排" scheme="https://www.maxbill.cn/marks/%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92/"/>
    
      <category term="Kubeadm" scheme="https://www.maxbill.cn/marks/Kubeadm/"/>
    
  </entry>
  
  <entry>
    <title>搭建Docker私有镜像仓库</title>
    <link href="https://www.maxbill.cn/3671626427.html"/>
    <id>https://www.maxbill.cn/3671626427.html</id>
    <published>2019-10-08T07:05:09.000Z</published>
    <updated>2020-07-04T12:39:17.783Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>docker仓库的工作原理和maven的类似，他们都提供了提供了一个中央仓库，允许用户科技直接从中央仓库下载，同时我们也可以搭建自己的本地私有仓库。下面我们将完整的说明使用docker registry 搭建docker私有镜像仓库和管理工具harbor的过程。<br>docker本地私有镜像仓库的优点：</p><ol><li>从私有仓库中下载节省网络带宽；</li><li>从私有仓库中下载速度快，一般都是局域网络内部署；</li><li>托管不对外的内部镜像；</li></ol><h2 id="安装dokcer服务"><a href="#安装dokcer服务" class="headerlink" title="安装dokcer服务"></a><strong>安装dokcer服务</strong></h2><p>配置源wget <a href="https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo">https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</a> -O /etc/yum.repos.d/docker-ce.repo<br><img src="https://oscimg.oschina.net/oscnet/ef067515476744e4ac811c1866a8fd086e9.jpg" alt=""><br>安装docker-ce容器服务: yum -y install docker-ce<br>添加docker服务开机自启动: systemctl enable docker &amp;&amp;  systemctl start docker<br>修改docker启动参数:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">cat  &gt; /etc/docker/daemon.json  &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">   &quot;registry-mirrors&quot;: [</span></span><br><span class="line"><span class="string">      &quot;https://registry.docker-cn.com&quot;,</span></span><br><span class="line"><span class="string">      &quot;http://hub-mirror.c.163.com&quot;,</span></span><br><span class="line"><span class="string">      &quot;https://registry.docker-cn.com&quot;</span></span><br><span class="line"><span class="string">   ],</span></span><br><span class="line"><span class="string">   &quot;insecure-registries&quot;: [&quot;192.168.100.10&quot;],</span></span><br><span class="line"><span class="string">   &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p>注意：客户机的该文件也需要加如下配置:  “insecure-registries”: [“192.168.100.10”]<br><img src="https://oscimg.oschina.net/oscnet/24d895e56c2cf11007d61fe5906657d0313.jpg" alt=""><br>修改docker的启动服务脚本docker.service：<br>在[Service]节点下增加<br>ExecStartPost=/sbin/iptables -I FORWARD -s 0.0.0.0/0 -j ACCEPT<br>修改完成使用systemctl daemon-reload &amp;&amp; systemctl restart docker重启服务<br><img src="https://oscimg.oschina.net/oscnet/c074afa9c694f5bb3175f3f60e04ae05ba4.jpg" alt=""><br>启动docker服务: systemctl start docker<br>查看docker版本号: docker –version<br><img src="https://oscimg.oschina.net/oscnet/afbda4fdcd5512d52e6890da46c35427750.jpg" alt=""><br>查看docker详细信息: docker info<br><img src="https://oscimg.oschina.net/oscnet/b1cb7633f23173fc8294d33b28e49919f56.jpg" alt=""></p><h2 id="拉取registry镜像"><a href="#拉取registry镜像" class="headerlink" title="拉取registry镜像"></a><strong>拉取registry镜像</strong></h2><p>执行拉取镜像命令：docker pull registry<br><img src="https://oscimg.oschina.net/oscnet/f88893a6004ca94ed1580feef782bf3eb44.jpg" alt=""><br>执行查看镜像命令：docker images<br><img src="https://oscimg.oschina.net/oscnet/d7c2a53416db19cec19f2d620103ce81577.jpg" alt=""></p><h2 id="挂载镜像存储目录"><a href="#挂载镜像存储目录" class="headerlink" title="挂载镜像存储目录"></a><strong>挂载镜像存储目录</strong></h2><p>将容器内的数据映射挂载在自己指定的目录上，以/work/docker-repo为镜像存储的目录<br><img src="https://oscimg.oschina.net/oscnet/9d99fd7777dbfe02910348321ef690285bd.jpg" alt=""><br>执行如下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 5000:5000 --privileged=<span class="literal">true</span> -v /work/docker-repo:/var/lib/registry --name docker-registry registry</span><br></pre></td></tr></table></figure><p>-d : 让容器可以后台运行<br>-p ：指定映射端口（前者是宿主机的端口号，后者是容器的端口号）<br>-v ：数据挂载（前者是宿主机的目录，后者是容器的目录）<br>–name : 为运行的容器命名<br><img src="https://oscimg.oschina.net/oscnet/19b92dc91ed1f1570eb60f8f4b0720bdb2a.jpg" alt=""></p><h2 id="重启容器并开启registry服务"><a href="#重启容器并开启registry服务" class="headerlink" title="重启容器并开启registry服务"></a><strong>重启容器并开启registry服务</strong></h2><p>重启docker服务：systemctl restart docker<br>开启registry服务：docker start docker-registry<br><img src="https://oscimg.oschina.net/oscnet/807703bdd237b819ed8d7a3aded9fe58131.jpg" alt=""></p><h2 id="安装epel"><a href="#安装epel" class="headerlink" title="安装epel"></a><strong>安装epel</strong></h2><p>执行安装命令：yum install -y epel-release<br><img src="https://oscimg.oschina.net/oscnet/435e035fd7ea0076cfb7360b9529801eb10.jpg" alt=""></p><h2 id="安装pip"><a href="#安装pip" class="headerlink" title="安装pip"></a><strong>安装pip</strong></h2><p>执行安装命令：yum install -y python-pip<br><img src="https://oscimg.oschina.net/oscnet/a4e0bdd5414d406cdb559a7a684ec2582cf.jpg" alt=""></p><h2 id="升级pip"><a href="#升级pip" class="headerlink" title="升级pip"></a><strong>升级pip</strong></h2><p>执行升级命令：pip install –upgrade pip<br><img src="https://oscimg.oschina.net/oscnet/44808ff105aa7ddb8b21d2a6c72c4000313.jpg" alt=""></p><h2 id="安装docker-compose"><a href="#安装docker-compose" class="headerlink" title="安装docker-compose"></a><strong>安装docker-compose</strong></h2><p>执行安装命令：pip install docker-compose<br><img src="https://oscimg.oschina.net/oscnet/81eac2cf02c700a174055ddc507fb247321.jpg" alt=""></p><h2 id="安装Harbor"><a href="#安装Harbor" class="headerlink" title="安装Harbor"></a><strong>安装Harbor</strong></h2><p>官网地址：<a href="https://github.com/goharbor/harbor/releases">https://github.com/goharbor/harbor/releases</a><br>最新地址：<a href="https://storage.googleapis.com/harbor-releases/release-1.9.0/harbor-offline-installer-v1.9.0.tgz">https://storage.googleapis.com/harbor-releases/release-1.9.0/harbor-offline-installer-v1.9.0.tgz</a><br>下载安装包：wget <a href="https://storage.googleapis.com/harbor-releases/release-1.9.0/harbor-offline-installer-v1.9.0.tgz">https://storage.googleapis.com/harbor-releases/release-1.9.0/harbor-offline-installer-v1.9.0.tgz</a><br><img src="https://oscimg.oschina.net/oscnet/9ce95fbca21a4b86fa65f38b6e422338a38.jpg" alt=""><br>解压安装包：tar xvf harbor-offline-installer-v1.9.0.tgz<br><img src="https://oscimg.oschina.net/oscnet/ef11579555fdfa476509eaf062d3e7cf780.jpg" alt=""></p><h2 id="修改harbor-yml配置"><a href="#修改harbor-yml配置" class="headerlink" title="修改harbor.yml配置"></a><strong>修改harbor.yml配置</strong></h2><p>执行修改命令：vi /work/harbor/harbor.yml<br>将hostname改为本机机器ip，登录密码改为123456（实际环境请改为复杂密码）<br><img src="https://oscimg.oschina.net/oscnet/b314a2080be75fb1af6264e002098e0c1d8.jpg" alt=""></p><h2 id="安装启动harbor"><a href="#安装启动harbor" class="headerlink" title="安装启动harbor"></a><strong>安装启动harbor</strong></h2><p>执行 ./install.sh<br><img src="https://oscimg.oschina.net/oscnet/a915c20a19b6ed0ce730767d23f3fca66ee.jpg" alt=""><br>看到如下日志，即为安装启动成功：<br><img src="https://oscimg.oschina.net/oscnet/555d0a04d4f6330ba6fc40cebeedd9a2cd0.jpg" alt=""><br>我们在工作机器访问：<a href="http://192.168.100.10">http://192.168.100.10</a><br>用户：admin   密码：123456<br><img src="https://oscimg.oschina.net/oscnet/74c57c3d29107880f94d6f95e7b5271f079.jpg" alt=""><br>登录成功如下：<br><img src="https://oscimg.oschina.net/oscnet/a6607cfecc079e64048907fd8cc512de97b.jpg" alt=""></p><h2 id="harbor简单使用"><a href="#harbor简单使用" class="headerlink" title="harbor简单使用"></a><strong>harbor简单使用</strong></h2><p>首选创建一个kubernets的项目<br><img src="https://oscimg.oschina.net/oscnet/7f86c4462f90d8d16734cd0fbe5cbbd5eaa.jpg" alt=""><br>然后在/work/docker-pull目录下创建拉取k8s v1.15.3所需的镜像脚本<br><img src="https://oscimg.oschina.net/oscnet/8dc21a0911d7a47ba1c6f37cab0ce592e7b.jpg" alt=""><br>k8s-v1.15.3-pull.sh内容如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.15.3</span><br><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.15.3</span><br><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.15.3</span><br><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.15.3</span><br><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1</span><br><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.3.10</span><br><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.3.1</span><br><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/google-containers/flannel:v0.9.0-amd64</span><br><span class="line"></span><br><span class="line">docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.15.3 192.168.100.10/kubernetes/kube-apiserver:v1.15.3</span><br><span class="line">docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.15.3 192.168.100.10/kubernetes/kube-controller-manager:v1.15.3</span><br><span class="line">docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.15.3 192.168.100.10/kubernetes/kube-scheduler:v1.15.3</span><br><span class="line">docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.15.3 192.168.100.10/kubernetes/kube-proxy:v1.15.3</span><br><span class="line">docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 192.168.100.10/kubernetes/pause:3.1</span><br><span class="line">docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.3.10 192.168.100.10/kubernetes/etcd:3.3.10</span><br><span class="line">docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.3.1 192.168.100.10/kubernetes/coredns:1.3.1</span><br><span class="line">docker tag registry.cn-hangzhou.aliyuncs.com/google-containers/flannel:v0.9.0-amd64 192.168.100.10/kubernetes/flannel:v0.9.0-amd64</span><br><span class="line"></span><br><span class="line">docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.15.3</span><br><span class="line">docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.15.3</span><br><span class="line">docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.15.3</span><br><span class="line">docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.15.3</span><br><span class="line">docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1</span><br><span class="line">docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.3.10</span><br><span class="line">docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.3.1</span><br><span class="line">docker rmi registry.cn-hangzhou.aliyuncs.com/google-containers/flannel:v0.9.0-amd64</span><br><span class="line"></span><br><span class="line">docker push 192.168.100.10/kubernetes/kube-apiserver:v1.15.3</span><br><span class="line">docker push 192.168.100.10/kubernetes/kube-controller-manager:v1.15.3</span><br><span class="line">docker push 192.168.100.10/kubernetes/kube-scheduler:v1.15.3</span><br><span class="line">docker push 192.168.100.10/kubernetes/kube-proxy:v1.15.3</span><br><span class="line">docker push 192.168.100.10/kubernetes/pause:3.1</span><br><span class="line">docker push 192.168.100.10/kubernetes/etcd:3.3.10</span><br><span class="line">docker push 192.168.100.10/kubernetes/coredns:1.3.1</span><br><span class="line">docker push 192.168.100.10/kubernetes/flannel:v0.9.0-amd64</span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/43754d6e9defb0613fb644b2b94cf7e82c7.jpg" alt=""><br>完成后执行chmod +x k8s-v1.15.3-pull.sh<br><img src="https://oscimg.oschina.net/oscnet/8617ebc4d307e1545b5be7ec77be4811b91.jpg" alt=""><br>执行./k8s-v1.15.3-pull.sh<br><img src="https://oscimg.oschina.net/oscnet/4dbad7bb981660bb71bdb4fdea279ba7648.jpg" alt=""><br>在push过程中发生错误：<br><img src="https://oscimg.oschina.net/oscnet/42426595bb3ee4c5dcf6bf04d54c9b19979.jpg" alt=""><br>虽然是公开仓库，是允许公开pull，但是push是需要登录的，我们这里登录harbor的管理员账号：<br><img src="https://oscimg.oschina.net/oscnet/8a38fc6b32e1cfbdf39662e94b46377a902.jpg" alt=""><br>再次执行基本，可以看到正常push了<br><img src="https://oscimg.oschina.net/oscnet/9114aa3b2493859222307d66a0dd585db03.jpg" alt=""><br>镜像操作完成docker images查看<br><img src="https://oscimg.oschina.net/oscnet/96e53eedeaab2fa02f065b94dfa28436e03.jpg" alt=""><br>查看镜像存储目录，发现私有库中已存在镜像<br><img src="https://oscimg.oschina.net/oscnet/b17ce39d299d0df2d7967490850bdc699c9.jpg" alt=""><br>登录harbor中查看，也已经存在镜像<br><img src="https://oscimg.oschina.net/oscnet/155add6d3e1456c08ea361268a1559c4ee3.jpg" alt=""><br>至此docker 私有镜像仓库以及管理服务Harbor搭建完成。</p>]]></content>
    
    <summary type="html">
    
      搭建Docker私有镜像仓库
    
    </summary>
    
    
      <category term="开发运维" scheme="https://www.maxbill.cn/kinds/%E5%BC%80%E5%8F%91%E8%BF%90%E7%BB%B4/"/>
    
    
      <category term="Docker" scheme="https://www.maxbill.cn/marks/Docker/"/>
    
      <category term="Docker-Compose" scheme="https://www.maxbill.cn/marks/Docker-Compose/"/>
    
      <category term="容器化" scheme="https://www.maxbill.cn/marks/%E5%AE%B9%E5%99%A8%E5%8C%96/"/>
    
      <category term="Harbor" scheme="https://www.maxbill.cn/marks/Harbor/"/>
    
      <category term="Docker-Registry" scheme="https://www.maxbill.cn/marks/Docker-Registry/"/>
    
  </entry>
  
  <entry>
    <title>使用Kubeadm部署Kubernetes集群V1.16.0</title>
    <link href="https://www.maxbill.cn/9146406960.html"/>
    <id>https://www.maxbill.cn/9146406960.html</id>
    <published>2019-09-26T08:03:21.000Z</published>
    <updated>2020-03-07T08:02:06.444Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>一般kubernetes集群搭建的方式有kubeadm（官方推荐），二进制搭建，minikube等方式，本文使用官方推荐的kubeadm搭建。</p><h2 id="基础环境配置"><a href="#基础环境配置" class="headerlink" title="基础环境配置"></a><strong>基础环境配置</strong></h2><h3 id="准备四台虚拟机"><a href="#准备四台虚拟机" class="headerlink" title="准备四台虚拟机"></a><strong>准备四台虚拟机</strong></h3><p>Kubernetes Master01  192.168.100.11   kube-master-01   master<br>Kubernetes Minion01  192.168.100.12   kube-minion-01   minion<br>Kubernetes Minion02  192.168.100.13   kube-minion-02   minion<br>Kubernetes Minion03  192.168.100.14   kube-minion-03   minion</p><h3 id="配置hosts文件"><a href="#配置hosts文件" class="headerlink" title="配置hosts文件"></a><strong>配置hosts文件</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;&gt; /etc/hosts&lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">192.168.100.11  kube-master-01</span></span><br><span class="line"><span class="string">192.168.100.12  kube-minion-01</span></span><br><span class="line"><span class="string">192.168.100.13  kube-minion-02</span></span><br><span class="line"><span class="string">192.168.100.14  kube-minion-03</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/82c17d06dab15407e608490372e15afd018.jpg" alt=""></p><h3 id="修改hostname文件"><a href="#修改hostname文件" class="headerlink" title="修改hostname文件"></a><strong>修改hostname文件</strong></h3><p>sudo hostnamectl set-hostname <newhostname><br><img src="https://oscimg.oschina.net/oscnet/d6017d914c73a0e028e588006b34050e044.jpg" alt=""></p><h3 id="关闭系统防火墙"><a href="#关闭系统防火墙" class="headerlink" title="关闭系统防火墙"></a><strong>关闭系统防火墙</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld</span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/816f69cf9b328e39abf6bcd64c6e8459bba.jpg" alt=""></p><h3 id="禁用swap内存交换"><a href="#禁用swap内存交换" class="headerlink" title="禁用swap内存交换"></a><strong>禁用swap内存交换</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">swapoff -a</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;swapoff -a&quot;</span> &gt;&gt;/etc/rc.d/rc.local</span><br><span class="line">chmod +x /etc/rc.d/rc.local</span><br></pre></td></tr></table></figure><p>注意：或开机禁用swap: 编辑/etc/fstab –&gt; 注释掉swap 分区</p><h3 id="关闭selinux服务"><a href="#关闭selinux服务" class="headerlink" title="关闭selinux服务"></a><strong>关闭selinux服务</strong></h3><p>临时关闭：setenforce 0    永久关闭：vi /etc/selinux/config<br>将SELINUX=enforcing改为SELINUX=disabled 设置后需要重启才能生效，命令如下：<br>sed -i ‘s/SELINUX=enforcing/SELINUX=disabled/g’ /etc/sysconfig/selinux<br><img src="https://oscimg.oschina.net/oscnet/000176aef68467e7a5b7ecf9f80d0782990.jpg" alt=""></p><h3 id="配置iptable管理ipv4-6请求"><a href="#配置iptable管理ipv4-6请求" class="headerlink" title="配置iptable管理ipv4/6请求"></a><strong>配置iptable管理ipv4/6请求</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo <span class="built_in">echo</span> <span class="string">&quot;1&quot;</span> &gt; /proc/sys/net/ipv4/ip_forward</span><br><span class="line">cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">net.bridge.bridge-nf-call-ip6tables = 1</span></span><br><span class="line"><span class="string">net.bridge.bridge-nf-call-iptables = 1</span></span><br><span class="line"><span class="string">net.ipv4.ip_forward = 1</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p>执行 sysctl –system    使配置生效<br><img src="https://oscimg.oschina.net/oscnet/64affcbfdbf46bcc039b755a496bf38442d.jpg" alt=""></p><h3 id="校对系统时间"><a href="#校对系统时间" class="headerlink" title="校对系统时间"></a><strong>校对系统时间</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum -y install ntp</span><br><span class="line">systemctl start ntpd</span><br><span class="line">systemctl <span class="built_in">enable</span> ntpd</span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/436ea2aa88ebe84f4aa1bc1f279de9a0ef5.jpg" alt=""></p><h2 id="集群环境配置"><a href="#集群环境配置" class="headerlink" title="集群环境配置"></a><strong>集群环境配置</strong></h2><h3 id="安装docker服务"><a href="#安装docker服务" class="headerlink" title="安装docker服务"></a><strong>安装docker服务</strong></h3><p>配置源wget <a href="https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo">https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</a> -O /etc/yum.repos.d/docker-ce.repo<br><img src="https://oscimg.oschina.net/oscnet/026e85ed00c313a2d1908b4f7c2087c22e9.jpg" alt=""><br>安装docker-ce容器服务：yum -y install docker-ce-18.06.1.ce-3.el7<br>查看docker版本号：docker –version和详细信息：docker info<br><img src="https://oscimg.oschina.net/oscnet/0c3b645ebb3076d0dae95ccfbe2766161b7.jpg" alt=""><br>添加开机自启动和启动服务：systemctl enable docker &amp;&amp; systemctl start docker<br>修改docker启动参数：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cat  &gt; /etc/docker/daemon.json  &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">     &quot;registry-mirrors&quot;: [&quot;https://yywkvob3.mirror.aliyuncs.com&quot;],</span></span><br><span class="line"><span class="string">     &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/4e3cc1089ee215c7dca62455db9d0947f6d.jpg" alt=""><br>修改docker的启动服务脚本docker.service：<br>在[Service]节点下增加：ExecStartPost=/sbin/iptables -I FORWARD -s 0.0.0.0/0 -j ACCEPT<br>修改完成使用：systemctl daemon-reload &amp;&amp; systemctl restart docker重启服务<br><img src="https://oscimg.oschina.net/oscnet/d0201c00597072c73e807235c03819663aa.jpg" alt=""></p><h3 id="安装Kubernetes组件"><a href="#安装Kubernetes组件" class="headerlink" title="安装Kubernetes组件"></a><strong>安装Kubernetes组件</strong></h3><p>配置源：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">[kubernetes]</span></span><br><span class="line"><span class="string">name=Kubernetes</span></span><br><span class="line"><span class="string">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64</span></span><br><span class="line"><span class="string">enabled=1</span></span><br><span class="line"><span class="string">gpgcheck=0</span></span><br><span class="line"><span class="string">repo_gpgcheck=0</span></span><br><span class="line"><span class="string">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p>安装组件：yum install -y kubelet kubeadm kubectl</p><h3 id="配置启动kubelet-组件"><a href="#配置启动kubelet-组件" class="headerlink" title="配置启动kubelet 组件"></a><strong>配置启动kubelet 组件</strong></h3><p>配置kubelet使用国内pause镜像和配置kubelet的cgroups：<br>cgroups要和docker的配置一样，使用：dokcer info可查看</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;/etc/sysconfig/kubelet&lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">KUBELET_EXTRA_ARGS=--cgroup-driver=systemd</span></span><br><span class="line"><span class="string">--pod-infra-container-image=k8s.gcr.io/pause:3.1 </span></span><br><span class="line"><span class="string">--runtime-cgroups=/systemd/system.slice</span></span><br><span class="line"><span class="string">--kubelet-cgroups=/systemd/system.slice</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p>使配置生效：systemctl daemon-reload<br>添加自启动：systemctl enable kubelet</p><h3 id="配置Master节点"><a href="#配置Master节点" class="headerlink" title="配置Master节点"></a><strong>配置Master节点</strong></h3><p>在master节点上创建初始化脚本：vi /etc/kubernetes/kubeadm-init.sh</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init \</span><br><span class="line">--kubernetes-version=v1.16.0 \</span><br><span class="line">--pod-network-cidr=10.244.0.0/16 \</span><br><span class="line">--apiserver-advertise-address=192.168.100.11</span><br></pre></td></tr></table></figure><p>修改脚本权限：chmod +x /etc/kubernetes/kubeadm-init.sh<br><img src="https://oscimg.oschina.net/oscnet/493cd8c78f1b1fc71f63c659631870f0d75.jpg" alt=""></p><h3 id="初始化Master节点"><a href="#初始化Master节点" class="headerlink" title="初始化Master节点"></a><strong>初始化Master节点</strong></h3><p>由于初始化时会从k8s.gcr.io拉取镜像，该镜像被墙，我们手动从国内镜像源拉取<br>首选我们：kubeadm config images list查看需要手动拉取镜像资源<br><img src="https://oscimg.oschina.net/oscnet/3153dbef283a5b1ec123cf9272430eaccdc.jpg" alt=""><br>在master节点上创建拉取镜像脚本：vi /etc/kubernetes/kubeadm-pull.sh</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.16.0</span><br><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.16.0</span><br><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.16.0</span><br><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.16.0</span><br><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1</span><br><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.3.15-0</span><br><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.6.2</span><br><span class="line">docker pull quay.io/coreos/flannel:v0.11.0-amd64</span><br></pre></td></tr></table></figure><p>修改脚本权限：chmod +x /etc/kubernetes/kubeadm-pull.sh<br>执行拉取镜像脚本：/etc/kubernetes/kubeadm-pull.s<br><img src="https://oscimg.oschina.net/oscnet/a19209417417e9926837fc45a05c877f4a2.jpg" alt=""><br>然后镜像拉取完成后我们需要打tag为k8s.gcr.io，让初始化时不在拉不到镜像<br>在master节点上创建打标镜像脚本：vi /etc/kubernetes/kubeadm-tags.sh</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.16.0 k8s.gcr.io/kube-apiserver:v1.16.0</span><br><span class="line">docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.16.0 k8s.gcr.io/kube-controller-manager:v1.16.0</span><br><span class="line">docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.16.0 k8s.gcr.io/kube-scheduler:v1.16.0</span><br><span class="line">docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.16.0 k8s.gcr.io/kube-proxy:v1.16.0</span><br><span class="line">docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 k8s.gcr.io/pause:3.1</span><br><span class="line">docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.3.15-0 k8s.gcr.io/etcd:3.3.15-0</span><br><span class="line">docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.6.2 k8s.gcr.io/coredns:1.6.2</span><br><span class="line">docker tag quay.io/coreos/flannel:v0.11.0-amd64 k8s.gcr.io/flannel:v0.11.0</span><br><span class="line"></span><br><span class="line">docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.16.0</span><br><span class="line">docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.16.0</span><br><span class="line">docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.16.0</span><br><span class="line">docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.16.0</span><br><span class="line">docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1</span><br><span class="line">docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.3.15-0</span><br><span class="line">docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.6.2</span><br><span class="line">docker rmi quay.io/coreos/flannel:v0.11.0-amd64</span><br></pre></td></tr></table></figure><p>修改脚本权限：chmod +x /etc/kubernetes/kubeadm-tags.sh<br>执行打标镜像脚本：/etc/kubernetes/kubeadm-tags.sh<br><img src="https://oscimg.oschina.net/oscnet/09365a768e9b62c7281ba6f45fd4a5ad71f.jpg" alt=""><br>执行/etc/kubernetes/kubeadm-init.sh此时会初始化<br>注意：如果初始化过程出现问题，使用如下命令重置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubeadm reset</span><br><span class="line">rm -rf /var/lib/cni/ <span class="variable">$HOME</span>/.kube/config</span><br></pre></td></tr></table></figure><p>初始化成功如下图：<br><img src="https://oscimg.oschina.net/oscnet/4e257d6badec5f35399f3f60a8d44cce063.jpg" alt=""></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join 192.168.100.11:6443 --token orpb71.4ntdi3oq3ct9fmap --discovery-token-ca-cert-hash</span><br><span class="line">sha256:c392f20abfc6f58da1140a7112a68bf29e68322bb96397c2ffdb7589079bc512</span><br></pre></td></tr></table></figure><p>上面这一句是给其他节点加入集群用的，要保存下来，后面要用。<br>配置master上通过 kubectl 管理集群，执行下面的命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rm -rf <span class="variable">$HOME</span>/.kube</span><br><span class="line">mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br></pre></td></tr></table></figure><p>使用kubectl get nodes查看刚初始化的主节点信息：<br><img src="https://oscimg.oschina.net/oscnet/d032be52225db75a3bbc14bbd1f0f898b8b.jpg" alt=""><br>我们看到master节点的状态时未就绪状态，需要配置使用网络flannel插件:<br>下载flannel配置文件：<br>wget -P /etc/kubernetes/conf<br><a href="https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml">https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</a><br>修改下载的flannel.yml文件，删除多余部分，并指定网卡信息:<br><img src="https://oscimg.oschina.net/oscnet/b63b175d71fc232eda0f842d92575707890.jpg" alt=""><br>启动flannel组件：kubectl apply -f /etc/kubernetes/conf/kube-flannel.yml<br><img src="https://oscimg.oschina.net/oscnet/e921c6ee6949be29786f7053f57444a8f2d.jpg" alt=""><br>使用kubeadm初始化的集群，出于安全考虑Pod不会被调度到Master Node上，可使用如下命令使Master节点参与工作负载：<br>kubectl taint nodes –all node-role.kubernetes.io/master-</p><h3 id="加入各Node节点"><a href="#加入各Node节点" class="headerlink" title="加入各Node节点"></a><strong>加入各Node节点</strong></h3><p>首先要给节点拉取镜像：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.16.0</span><br><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1</span><br><span class="line">docker pull quay.io/coreos/flannel:v0.11.0-amd64</span><br><span class="line"></span><br><span class="line">docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.16.0 k8s.gcr.io/kube-proxy:v1.16.0</span><br><span class="line">docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1 k8s.gcr.io/pause:3.1</span><br><span class="line">docker tag quay.io/coreos/flannel:v0.11.0-amd64 k8s.gcr.io/flannel:v0.11.0</span><br><span class="line"></span><br><span class="line">docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.16.0</span><br><span class="line">docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1</span><br><span class="line">docker rmi quay.io/coreos/flannel:v0.11.0-amd64</span><br></pre></td></tr></table></figure><p>等每个节点机器上都拉取完镜像后，执行下面的加入集群的命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join 192.168.100.11:6443 --token orpb71.4ntdi3oq3ct9fmap --discovery-token-ca-cert-hash</span><br><span class="line">sha256:c392f20abfc6f58da1140a7112a68bf29e68322bb96397c2ffdb7589079bc512</span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/ae252cd6bb91f391db28980da25c405503b.jpg" alt=""></p><h3 id="部署Kubernetes-Web"><a href="#部署Kubernetes-Web" class="headerlink" title="部署Kubernetes Web"></a><strong>部署Kubernetes Web</strong></h3><p>从kubernetes官方github下载配置文件：<br>wget <a href="https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml">https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml</a><br><img src="https://oscimg.oschina.net/oscnet/d04af9f3ed8a2a423eb711726e9ac3fa231.jpg" alt=""><br>手动从阿里仓库拉取镜像到各个节点上：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kubernetes-dashboard-amd64:v1.10.1</span><br><span class="line">docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kubernetes-dashboard-amd64:v1.10.1 k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1</span><br><span class="line">docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/kubernetes-dashboard-amd64:v1.10.1</span><br></pre></td></tr></table></figure><p>修改配置文件访问类型为：NodePort<br><img src="https://oscimg.oschina.net/oscnet/7c63aa1e6c0ab449eb224199d0676fdb50c.jpg" alt=""><br>启动webui组件：kubectl apply -f /etc/kubernetes/conf/kubernetes-dashboard.yaml<br><img src="https://oscimg.oschina.net/oscnet/625ebeeca873be3eed8caad001a40c81bc0.jpg" alt=""><br>查看dashboard pod的状态：kubectl get pods -n kube-system<br><img src="https://oscimg.oschina.net/oscnet/c1278924b22e85d1777f307d364e24da0f2.jpg" alt=""><br>查看端口映射：kubectl get svc -n kube-system<br><img src="https://oscimg.oschina.net/oscnet/767320f18d803144dc9486cafa63ffb6bcf.jpg" alt=""><br>然后通过：<a href="https://192.168.100.11:31080/访问">https://192.168.100.11:31080/访问</a><br><img src="https://oscimg.oschina.net/oscnet/38990c2aa29501a0993d4a892fe6c032c68.jpg" alt=""><br>我们看到有两种访问方式，下面我们配置这两种访问方式：<br>我们创建dashboard用户yaml文件：<br>vi  /etc/kubernetes/conf/kubernetes-dashboard-user.yaml </p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># Create Dashboard Service Account</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: dashboard-admin-user</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line"># Create ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: dashboard-admin-user</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: dashboard-admin-user</span><br><span class="line">  namespace: kube-system</span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/5993823158679643266f60d639fb664420a.jpg" alt=""><br>然后kubectl apply -f /etc/kubernetes/conf/kubernetes-dashboard-user.yaml<br>完成后执行kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep dashboard-admin-user | awk ‘{print $1}’)  查看token<br><img src="https://oscimg.oschina.net/oscnet/6784d4802b7518c33d856953a7aa17f7306.jpg" alt=""><br>获取的token即可用来在页面上输入登录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">eyJhbGciOiJSUzI1NiIsImtpZCI6IkF3QmIxYmVOYUcweXIxODVTdXhxYmZaZG5aQ2FFTzVod2V3bDlzUS1XeFkifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkYXNoYm9hcmQtYWRtaW4tdG9rZW4tcTZwejgiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGFzaGJvYXJkLWFkbWluIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiZmM4MGU3MTYtODc3Ny00MmZjLTk2MjQtYmU0NWY5YTI5MjZmIiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRhc2hib2FyZC1hZG1pbiJ9.NZ7zswny6DO1VkUbXB54b2CFZyNz-IB0nVX9yGOgJP8scAcFU5f6Mvg6AeFnT5Tmw6vdm_B6aXuJouAQEhDwVsYqpa3sI0zzyAfequYs5utWwz_R96gWCLBsrktKNxBpQG2r6JawzWOC3P-vdt1YYgN9jpU5gLo3uyyg0wKYM7KemSPmevqAncXUrm73N-L-4ubKRnYHjuJey1EVnzlSBe0_brV_KRrF5jFiy7Te3ziTmQUa4Z_wgK_yQ_eUoOEMIyu2qNlNfTEr6qdqqczCQo879EXGW4boTHopGQsjlSoI-GUbmrhA9H3H597qKbhmz7cgfA_6lgHpsOeSrBWi0g</span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/48b61cf8af7ce5faf7fe48b82fbfa242b22.jpg" alt=""><br>此时登录我们发现会出现：the server could not find the requested resource错误<br><img src="https://oscimg.oschina.net/oscnet/b3b9893f4e9e9096fb9964e965e01cf4eff.jpg" alt=""><br>我们查看pod的日志：kubectl logs kubernetes-dashboard-7c54d59f66-lcz2g -n kube-system<br><img src="https://oscimg.oschina.net/oscnet/3f40c380f3f13783e556a90240e34416177.jpg" alt=""><br>通过上面的日志，我们发现有查找heapster服务失败，因为dashboard要显示图表数据需要依赖heapster服务，于是我们部署heapster服务：<br>下载 heapster 相关 yaml 文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget /etc/kubernetes/heapster https://raw.githubusercontent.com/kubernetes-retired/heapster/master/deploy/kube-config/influxdb/grafana.yaml</span><br><span class="line">wget /etc/kubernetes/heapster https://raw.githubusercontent.com/kubernetes-retired/heapster/master/deploy/kube-config/influxdb/heapster.yaml</span><br><span class="line">wget /etc/kubernetes/heapster https://raw.githubusercontent.com/kubernetes-retired/heapster/master/deploy/kube-config/influxdb/influxdb.yaml</span><br><span class="line">wget /etc/kubernetes/heapster https://raw.githubusercontent.com/kubernetes-retired/heapster/master/deploy/kube-config/rbac/heapster-rbac.yaml</span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/9c16e69481289641e3d8f24efba2f719d0d.jpg" alt=""><br>查看需要部署的镜像：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cat grafana.yaml | grep image</span><br><span class="line">cat heapster.yaml | grep image</span><br><span class="line">cat influxdb.yaml | grep image</span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/ea358a345d37b00d13d28997965ab159e82.jpg" alt=""><br>手动部署heapster相关的镜像：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/heapster-amd64:v1.5.4</span><br><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/heapster-influxdb-amd64:v1.5.2</span><br><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/heapster-grafana-amd64:v5.0.4</span><br><span class="line"></span><br><span class="line">docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/heapster-amd64:v1.5.4 k8s.gcr.io/heapster-amd64:v1.5.4</span><br><span class="line">docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/heapster-influxdb-amd64:v1.5.2 k8s.gcr.io/heapster-influxdb-amd64:v1.5.2</span><br><span class="line">docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/heapster-grafana-amd64:v5.0.4 k8s.gcr.io/heapster-grafana-amd64:v5.0.4</span><br><span class="line"></span><br><span class="line">docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/heapster-amd64:v1.5.4</span><br><span class="line">docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/heapster-influxdb-amd64:v1.5.2</span><br><span class="line">docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/heapster-grafana-amd64:v5.0.4</span><br></pre></td></tr></table></figure><p>修改yaml文件：<br>因为k8s高版本的api版本进行了变化，将上面四个yaml文件中的apiVersion: extensions/v1beta1 改为apiVersion: apps/v1<br>因为kubelet 只在 10250 监听 https 请求，将heapster.yaml中的- –source=kubernetes:<a href="https://kubernetes.default">https://kubernetes.default</a>  修改为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">- --<span class="built_in">source</span>=kubernetes:https://kubernetes.default?kubeletHttps=<span class="literal">true</span>&amp;kubeletPort=10250&amp;insecure=<span class="literal">true</span></span><br></pre></td></tr></table></figure><p><img src="https://oscimg.oschina.net/oscnet/93e4a3e82c2fc5a31c53892a7be7c0f6f7f.jpg" alt=""><br>修改上面四个yaml文件中的spec节点，增加selector，如下图：<br><img src="https://oscimg.oschina.net/oscnet/492ead32405f234b56cff60ff5fe54db76f.jpg" alt=""><br>然后在heapster配置文件的当前目录下执行部署：kubectl apply -f .<br>注意：如果部署发生错误，我们执行kubectl delete -f . 进行回退<br>Heapster各个组件部署成功如下：<br><img src="https://oscimg.oschina.net/oscnet/28e692f45287b76be9c8b8f542662c64ba1.jpg" alt=""><br>然后我们生成使用config登录的文件：<br>##将secret中的token使用base64方式进行解码，然后使用变量引用<br>DASH_TOCKEN=$(kubectl get secret -n kube-system dashboard-admin-token-q6pz8 -o jsonpath={.data.token}|base64 -d)<br>##创建一个集群<br>kubectl config set-cluster cluster-admin –server=192.168.100.11:6443 –kubeconfig=/etc/kubernetes/conf/dashbord-admin.conf<br>##创建一个集群用户，并引用sa的token<br>kubectl config set-credentials dashboard-admin-user –token=$DASH_TOCKEN –kubeconfig=/etc/kubernetes/conf/dashbord-admin.conf<br> ##创建一个上下文，指定集群名、集群用户名</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl config set-context dashboard-admin-user@cluster-admin --cluster=cluster-admin --user=dashboard-admin-user</span><br><span class="line">--kubeconfig=/etc/kubernetes/conf/dashbord-admin.conf</span><br></pre></td></tr></table></figure><p>##设置集群中当前使用的用户<br>kubectl config use-context dashboard-admin-user@cluster-admin –kubeconfig=/etc/kubernetes/conf/dashbord-admin.conf<br>然后使用token或生成的文件登录成功如下：<br><img src="https://oscimg.oschina.net/oscnet/396f8f7379a90af7a7d0c8d60efbdae4478.jpg" alt=""></p><h3 id="验证集群状态"><a href="#验证集群状态" class="headerlink" title="验证集群状态"></a><strong>验证集群状态</strong></h3><p>使用kubectl get nodes -n kube-system -owide 查看节点列表<br><img src="https://oscimg.oschina.net/oscnet/8fadde7f97595cafa9a57c9a23394107bd4.jpg" alt=""><br>使用kubectl get pods -n kube-system -owide查看pod列表<br><img src="https://oscimg.oschina.net/oscnet/742c0865aa6724199ee46197ce5dbf1319f.jpg" alt=""><br>使用kubectl get svc -n kube-system -owide 查看服务列表<br><img src="https://oscimg.oschina.net/oscnet/687ce1e0dfd08c8db0c75af33316ce85833.jpg" alt=""></p><h2 id="集群问题解决"><a href="#集群问题解决" class="headerlink" title="集群问题解决"></a><strong>集群问题解决</strong></h2><h3 id="初始化集群时异常"><a href="#初始化集群时异常" class="headerlink" title="初始化集群时异常"></a>初始化集群时异常</h3><p>问题描述：执行kubeadm init时报出/proc/sys/net/ipv4/ip_forward contents are not set to 1的错误<br>解决方案：sudo echo “1” &gt; /proc/sys/net/ipv4/ip_forward</p><h3 id="安装好网络插件后组件还是NotReady状态"><a href="#安装好网络插件后组件还是NotReady状态" class="headerlink" title="安装好网络插件后组件还是NotReady状态"></a>安装好网络插件后组件还是NotReady状态</h3><p>问题描述：安装好网络插件flannel后，node还是NotReady状态，coredns 是padding状态，通过systemctl status kubelet 能看到是cni-flannel版本问题<br>解决方案：vi /etc/cni/net.d/10-flannel.conflist  ,增加”cniVersion”:”0.2.0”,<br><img src="https://oscimg.oschina.net/oscnet/e08d81374662226e247cd2460486d5c9514.jpg" alt=""></p><h3 id="部署heapster提示版本问题"><a href="#部署heapster提示版本问题" class="headerlink" title="部署heapster提示版本问题"></a>部署heapster提示版本问题</h3><p>问题描述：部署heapster 组件提示no matches for king “Deployment” in version “extensions/v1beta1”<br>![](<a href="https://oscimg.oschina.net/oscnet/9a00ca3e6bd3de71d55b81a9fe78df30fea.jpg">https://oscimg.oschina.net/oscnet/9a00ca3e6bd3de71d55b81a9fe78df30fea.jpg</a><br>解决方案：是因为k8s高版本的api版本进行了变化，将对应的yaml文件中的extensions/v1beta1 改为apiVersion: apps/v1</p><h3 id="部署heapster提示selector错误"><a href="#部署heapster提示selector错误" class="headerlink" title="部署heapster提示selector错误"></a>部署heapster提示selector错误</h3><p>问题描述：部署heapster 组件提示missing required field “selector” in io.k8s.api.apps.v1.DeploymentSpec的错误<br><img src="https://oscimg.oschina.net/oscnet/cdc2377691d33cb655ea8062c1635fb22cb.jpg" alt=""><br>解决方案：修改heapster上面四个yaml文件中的spec节点，增加selector，如下图：<br><img src="https://oscimg.oschina.net/oscnet/6ad2d45b203c8522bb259fec4043f635f4f.jpg" alt=""></p><h3 id="Dashboard访问异常"><a href="#Dashboard访问异常" class="headerlink" title="Dashboard访问异常"></a>Dashboard访问异常</h3><p>问题描述：部署完dashboard访问提示the server could not find the requested resource :404<br>解决方案：这是由于安装的最新的k8s 1.16.0的api不支持dashboard，等待dashboard更新支持，即可，或者先降级到1.15.x版本</p>]]></content>
    
    <summary type="html">
    
      使用Kubeadm部署Kubernetes集群V1.16.0
    
    </summary>
    
    
      <category term="开发运维" scheme="https://www.maxbill.cn/kinds/%E5%BC%80%E5%8F%91%E8%BF%90%E7%BB%B4/"/>
    
    
      <category term="K8S" scheme="https://www.maxbill.cn/marks/K8S/"/>
    
      <category term="Kubernetes" scheme="https://www.maxbill.cn/marks/Kubernetes/"/>
    
      <category term="容器化" scheme="https://www.maxbill.cn/marks/%E5%AE%B9%E5%99%A8%E5%8C%96/"/>
    
      <category term="容器编排" scheme="https://www.maxbill.cn/marks/%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92/"/>
    
      <category term="Kubeadm" scheme="https://www.maxbill.cn/marks/Kubeadm/"/>
    
  </entry>
  
  <entry>
    <title>Linux系统开发环境搭建之Redis安装配置.</title>
    <link href="https://www.maxbill.cn/1682194463.html"/>
    <id>https://www.maxbill.cn/1682194463.html</id>
    <published>2018-09-10T02:05:04.000Z</published>
    <updated>2020-07-06T14:21:11.866Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在windows下使用redis只要下载解压后启动就可以了，但是在linux下和windows下还是有些区别的，下面我们详细看看linux下redis的安装、配置、使用过程。</p><h3 id="一、环境说明"><a href="#一、环境说明" class="headerlink" title="一、环境说明"></a>一、环境说明</h3><p>1.Linux 操作系统<br>本文使用deepin 15.7发行版，下载地址：<a href="https://www.deepin.org/">https://www.deepin.org/</a></p><p>2.redis安装包<br>本文使用redis3.0.0，下载地址：<a href="http://download.redis.io/releases/">http://download.redis.io/releases/</a></p><p>3.redis客户端<br>本文使用开源软件RedisPlus，下载地址：<a href="https://gitee.com/MaxBill/RedisPlus">https://gitee.com/MaxBill/RedisPlus</a></p><h3 id="二、安装过程"><a href="#二、安装过程" class="headerlink" title="二、安装过程"></a>二、安装过程</h3><p><strong>1.下载redis源码包</strong><br>我们使用wget 下载或者直接去<a href="http://download.redis.io/releases/下载源码包">http://download.redis.io/releases/下载源码包</a></p><p><strong>2.解压redis源码包</strong><br>使用解压工具或者使用tar -zxvf命令解压<br><img src="https://oscimg.oschina.net/oscnet/edda7fbb8ad78320336c6d5b5fdf0bfe075.jpg" alt=""></p><p><strong>3.编译redis程序</strong><br>我们刚下载的是redis的源码，需要我们进行编译才能使用，进入刚解压的redis安装包目录，使用make命令进行编译<br><img src="https://oscimg.oschina.net/oscnet/d7d3d94aae0442e073ce6612e905751fb84.jpg" alt=""></p><p>等待编译过程一会，看到如下说明编译完成<br><img src="https://oscimg.oschina.net/oscnet/fd8d2e16b9b53d02f453799baf749836554.jpg" alt=""></p><p><strong>4.安装redis程序</strong><br>进行完编译过程，会在src目录下生成可执行的redis程序了，接下来就能安装使用了，安装目录大家可自己定义，这里我安装到/opt/redis/下<br><img src="https://oscimg.oschina.net/oscnet/6fac5882f1417999783f257588159761ec8.jpg" alt=""><br>可以看到这是安装成功了，但是第一次失败了，是因为opt目录需要管理员权限，我们使用了sudo提权后在此安装成功</p><p><strong>5.配置redis服务</strong><br>首选需要将源码包中的redis.conf配置文件拷贝到安装目录/etc/下<br><img src="https://oscimg.oschina.net/oscnet/3f917883c3f4c90ccfd70bd3ff2f78a92fe.jpg" alt=""><br>首选修改redis密码，修改/opt/redis/redis.conf中的requirepass项，默认是注释的，也就是空，我这里我们修改成123456<br><img src="https://oscimg.oschina.net/oscnet/21983acc472c7d4487594d9749fe59076b4.jpg" alt=""><br>然后修改ip访问，默认是本地访问，允许其他主机访问我们修改bind为0.0.0.0<br><img src="https://oscimg.oschina.net/oscnet/0624dcb575450ff0fa85c6e276c4a4eea4c.jpg" alt=""><br>配置redis为后台服务启动，修改daemonize项，默认是no，这里改成yes是后台启动模式<br><img src="https://oscimg.oschina.net/oscnet/2ead8aadc2d61307e8137b4c831a70c53e8.jpg" alt=""></p><p><strong>6.启动redis服务</strong><br>在终端执行/opt/redis/bin/redis-server /opt/redis/etc/redis.conf ，为了方便我们可以写个sh脚本，执行后我们telnet 6379，发现已经启动了<br><img src="https://oscimg.oschina.net/oscnet/118f796866970817a14eb69ccbec9dd0fd7.jpg" alt=""><br>使用ps -ef |grep redis查看redis是否启动<br><img src="https://oscimg.oschina.net/oscnet/24f91c0c09d1f376ad198c74b507689cc96.jpg" alt=""><br>使用netstat -lntp | grep 6379查看redis是否启动，如果是LISTEN 说明启动正常，6379端口处于监听状态<br><img src="https://oscimg.oschina.net/oscnet/4ac1d4ed0374d27d3a8a9b4241f0adf0f00.jpg" alt=""></p><p><strong>7.使用RedisPlus客户端连接redis</strong><br>下载安装RedisPlus客户端程序，点击打开添加连接信息：<br><img src="https://oscimg.oschina.net/oscnet/93f9251fc9048d6a6f1e35968d29f2a2abc.jpg" alt=""><br>然后双击连接，我们看到成功连接到：<br><img src="https://oscimg.oschina.net/oscnet/41219221da4a92843f858930568bdfe6633.jpg" alt=""><br>查看redis数据、信息、配置等，RedisPlus的具体使用见<a href="https://gitee.com/MaxBill/RedisPlus">https://gitee.com/MaxBill/RedisPlus</a><br><img src="https://oscimg.oschina.net/oscnet/814ee8215db23e90eb1be478acb2eb93dbc.jpg" alt=""></p><p><strong>8.卸载redis程序</strong><br>先使用kill杀死redis进程，然后rm -rf  /opt/redis/即可</p>]]></content>
    
    <summary type="html">
    
      Linux系统开发环境搭建之Redis安装配置.
    
    </summary>
    
    
      <category term="开发运维" scheme="https://www.maxbill.cn/kinds/%E5%BC%80%E5%8F%91%E8%BF%90%E7%BB%B4/"/>
    
    
      <category term="Deepin" scheme="https://www.maxbill.cn/marks/Deepin/"/>
    
      <category term="Redis" scheme="https://www.maxbill.cn/marks/Redis/"/>
    
      <category term="RedisPlus" scheme="https://www.maxbill.cn/marks/RedisPlus/"/>
    
      <category term="Linux" scheme="https://www.maxbill.cn/marks/Linux/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot(13)集成使用Lombok简化JavaBean代码</title>
    <link href="https://www.maxbill.cn/4021358283.html"/>
    <id>https://www.maxbill.cn/4021358283.html</id>
    <published>2018-08-21T08:53:22.000Z</published>
    <updated>2020-07-04T12:58:29.656Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>SpringBoot采用约定大于配置的方式，极大的减少了配置文件的使用，简化了开发过程中的配置难度，使得项目开发更加高效。当然初次之外我们还可以采用其他手段来简化代码，使得代码没那么臃肿。开发JavaWeb的同学都知道，一个标准的JavaBean组件由属性、方法、构造函数三部分组成，其中JavaBean需要提供可读写的属性，也就是属性的setter和getter方法，而这些使得代码看起来很臃肿，但却是必不可少的。 同样在Springboot项目中JavaBean组件也是无处不在，我们今天主要说说SpringBoot项目中使用Lombok插件简化JavaBean的代码，以及开发ide安装Lombok插件等。</p><h2 id="项目中引入Lombok开发包"><a href="#项目中引入Lombok开发包" class="headerlink" title="项目中引入Lombok开发包"></a><strong>项目中引入Lombok开发包</strong></h2><p>我们使用maven构建的springboot项目，引入Lombok只需要在pom文件中加入以下依赖：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--lombok插件--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.projectlombok<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lombok<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">optional</span>&gt;</span>true<span class="tag">&lt;/<span class="name">optional</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>此时我们编写一个javabean加上lombok的注解看看：<br><img src="https://oscimg.oschina.net/oscnet/402c71aab950ad861fcecfaafa33dc3391e.jpg" alt=""><br>虽然引入了lombok开发包，但是idea开发工具依然不认识（Private field ‘xxx’ is never used），这是因为我们还需要给ide安装lombok的编译插件</p><h2 id="Idea安装Lombok插件"><a href="#Idea安装Lombok插件" class="headerlink" title="Idea安装Lombok插件"></a><strong>Idea安装Lombok插件</strong></h2><p>我们本文使用的是IDEA开发工具，我们先File-&gt;Settings-&gt;Plugins<br><img src="https://oscimg.oschina.net/oscnet/2e84d5bfed7bf0e4494e5e12ab9567a353a.jpg" alt=""><br>然后我们点击下面 的Browser repositories按钮，在搜索框输入lombok关键字搜索如下：<br><img src="https://oscimg.oschina.net/oscnet/0b4da5601438aca0b121467ee8dd0f984ce.jpg" alt=""><br>我们点击倒数第二个 Lombok Plugin项，然后点击右面的安装即可<br><img src="https://oscimg.oschina.net/oscnet/8c8edd2b2699d5f210f2b929c9e829c4240.jpg" alt=""><br>安装完成后会提示重启idea<br><img src="https://oscimg.oschina.net/oscnet/c6cd97026cfd3dc42bc504f556be58612bc.jpg" alt=""><br>我们重启完idea，然后再看上面写的那个javabean，此时已经能识别lombok的注解了<br><img src="https://oscimg.oschina.net/oscnet/688997395b64825c1832446c3175d457921.jpg" alt=""><br>我们对比之前的javabean代码，是不是简化了很多，当然这是lombok最基本的用法，跟多的关于方法复写之类打击可以去官方看看文档。<br>lombok官网：<a href="https://www.projectlombok.org/">https://www.projectlombok.org/</a><br>lombok文档：<a href="https://projectlombok.org/features/all">https://projectlombok.org/features/all</a></p><h2 id="Lombok插件使用的注意地方"><a href="#Lombok插件使用的注意地方" class="headerlink" title="Lombok插件使用的注意地方"></a><strong>Lombok插件使用的注意地方</strong></h2><p>1.关于属性是is什么的，要主要生成的setter和getter方法<br>比如isParent该属性，生成的其实是setParent和isParent方法<br><img src="https://oscimg.oschina.net/oscnet/5e7740d749305227aa81f278a3308503e6d.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/dddb33a47c93b838a60b70209243957537c.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      SpringBoot(13)集成使用Lombok简化JavaBean代码
    
    </summary>
    
    
      <category term="学微服务" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="Java" scheme="https://www.maxbill.cn/marks/Java/"/>
    
      <category term="SpringBoot" scheme="https://www.maxbill.cn/marks/SpringBoot/"/>
    
      <category term="微服务" scheme="https://www.maxbill.cn/marks/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="Lombok" scheme="https://www.maxbill.cn/marks/Lombok/"/>
    
      <category term="JavaBean" scheme="https://www.maxbill.cn/marks/JavaBean/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot(12)使用Idea开发配置热加载</title>
    <link href="https://www.maxbill.cn/1399388179.html"/>
    <id>https://www.maxbill.cn/1399388179.html</id>
    <published>2018-08-15T07:09:18.000Z</published>
    <updated>2020-07-04T12:58:29.656Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>java开发的ide用最多的无非就是eclipse和idea，在eclipse中开发springboot，要使项目热加载资源只需要在pom文件中引入springboot的开发工devtools即可。但是该工具在使用idea开发springboot时单纯的引入并不起作用，还需要一些代码支持和idea设置才能生效。下面我们就在idea中使用maven构建的springboot项目进行热部署配置。</p><h2 id="使用maven构建一个springboot项目"><a href="#使用maven构建一个springboot项目" class="headerlink" title="使用maven构建一个springboot项目"></a>使用maven构建一个springboot项目</h2><p><img src="https://oscimg.oschina.net/oscnet/8f7cc2bc308f7824c40976e3be0df44d015.jpg" alt=""></p><h2 id="引入springboot开发工具包"><a href="#引入springboot开发工具包" class="headerlink" title="引入springboot开发工具包"></a>引入springboot开发工具包</h2><p>打开项目中的pom.xml文件，加入以下依赖：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--开发工具依赖--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-devtools<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">scope</span>&gt;</span>runtime<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>注意：也可以在构建的时候勾选上devtools工具包</p><h2 id="配置参数是devtools生效"><a href="#配置参数是devtools生效" class="headerlink" title="配置参数是devtools生效"></a>配置参数是devtools生效</h2><p>单纯的引入上面的devtools工具包是不起作用的，我们还需要在maven编译插件处配置一个参数：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--编译插件配置--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="comment">&lt;!--没有该项配置，devtools不会起作用--&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">fork</span>&gt;</span>true<span class="tag">&lt;/<span class="name">fork</span>&gt;</span><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="设置idea的自动编译项目"><a href="#设置idea的自动编译项目" class="headerlink" title="设置idea的自动编译项目"></a>设置idea的自动编译项目</h2><p>打开idea的设置，找到编译，勾选自动编译项（File—&gt;Settings—&gt;Bulid—&gt;Compiler ）<br><img src="https://oscimg.oschina.net/oscnet/4ed886e57d0f5b0a3bcd45221f637fe4ada.jpg" alt=""></p><h2 id="在idea中注册maven自动编译项"><a href="#在idea中注册maven自动编译项" class="headerlink" title="在idea中注册maven自动编译项"></a>在idea中注册maven自动编译项</h2><p>首先使用快捷键ctrl + Shift + Alt + / 打开Maintenance插件注册界面<br><img src="https://oscimg.oschina.net/oscnet/ff92a31e18c160dc4c0a6fdcdcb6e4a715f.jpg" alt=""><br>然后点击注册进入idea的插件注册界面<br><img src="https://oscimg.oschina.net/oscnet/10a112fd86349d7702bc425c81020cc756a.jpg" alt=""><br>最后找到compiler.automake.allow.when.app.running这一项勾选，使maven的自动编译插件注册到idea中。<br>亲测有效！我的idea版本：<br><img src="https://oscimg.oschina.net/oscnet/1b0572874e713b16cd3e25d66b76cef46a1.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      SpringBoot(12)使用Idea开发配置热加载
    
    </summary>
    
    
      <category term="学微服务" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="Java" scheme="https://www.maxbill.cn/marks/Java/"/>
    
      <category term="SpringBoot" scheme="https://www.maxbill.cn/marks/SpringBoot/"/>
    
      <category term="Idea" scheme="https://www.maxbill.cn/marks/Idea/"/>
    
      <category term="微服务" scheme="https://www.maxbill.cn/marks/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="devtools" scheme="https://www.maxbill.cn/marks/devtools/"/>
    
      <category term="热加载" scheme="https://www.maxbill.cn/marks/%E7%83%AD%E5%8A%A0%E8%BD%BD/"/>
    
  </entry>
  
  <entry>
    <title>Java深究之Vector、ArrayList、LinkedList的区别</title>
    <link href="https://www.maxbill.cn/3953404786.html"/>
    <id>https://www.maxbill.cn/3953404786.html</id>
    <published>2018-07-03T07:37:18.000Z</published>
    <updated>2020-07-07T13:37:06.687Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在java开发中除了上文经常用的对字符串的操作外，还有使用居多的当属集合了。在基础的java学习时，相信很多同学都学习了List、Set、Map这些，他们之间的区别和基本的使用方法也是很了解了，本文是详细的去分析List中Vector、ArrayList、LinkedList之间的区别和底层实现原理以及使用场景。</p><p>首先说下这三者的区别：<br><strong>1.基本区别：</strong>三个类都实现了List接口，都是有序集合，数据是允许重复的；ArrayList 和Vector都是基于数组实现存储的，集合中的元素的位置都是有顺序即连续的；LinkedList是基于双向链表实现存储的<strong>，</strong>集合中的元素的位置是不连续的。<br><strong>2.性能区别：</strong>Vector和ArrayList底层实现原理一致，但是Vector是线程安全的，因此性能比ArrayList差很多；LinkedList相比于集合Vector和ArrayList在插入,修改，删除等操作上速度较快，但是随机访问的性能较差。<br><strong>3.安全区别：</strong>Vector是使用了synchronized同步锁是线程安全的，ArrayList和LinkedList都是线程不安全的。<br><strong>4.原理区别：</strong>ArrayList与Vector都有初始的容量大小，当存储的元素的个数超过了容量时，就需要增加存储空间，Vector默认增长为原来两倍，而ArrayList的增长为原来的1.5倍；ArrayList与Vector都可以设置初始空间大小，Vector还可以设置增长的空间大小，而ArrayList没有提供设置增长空间的方法。</p><p>然后详细分析每一个的原理：</p><p><strong>1.Vector</strong><br><img src="https://oscimg.oschina.net/oscnet/b205a631d7581de379853c361ea68722266.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/44b6026f9612455ec507803dd4325a5e63e.jpg" alt=""><br>从源码可以看出Vector的初始默认空间大小为10，底层使用protected Object[] elementData;存储数据，使用protected int elementCount;存储元素数量，Vector的方法都被synchronized关键字修饰，因此是线程安全的。<br>接下来我们从源码上看下Vector的添加元素时以及初始容量不足时的扩容机制：<br><img src="https://oscimg.oschina.net/oscnet/b3213733195ed4bdbaa41c38201b75f59c2.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/576ad4e25f0907e7d48df1ca3232f2da5d5.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/3e71b5831668ee458cf65fe39d60295e7d6.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/85d957d260531c5875ca63e4a567a98f0ea.jpg" alt=""><br>当创建一个Vector容器，向其中添加一个元素是，首先会调用ensureCapacityHelper函数判断容器存储容量，如果容量不足则会调用grow函数扩容，上面我们说的扩展为原来的两倍，其实不是非常准确，因为当设置了扩容参数值，则就不是扩展为两倍了，而是原来的长度加上扩容参数值，默认情况下还是扩展为原来的两倍。</p><p><strong>2.ArrayList</strong><br><img src="https://oscimg.oschina.net/oscnet/2f264dfddf928f1edeb0d47a0b24b70e339.jpg" alt=""><br>ArrayList的初始容量大小也是10，和Vector的原理是完全一样的，只是不是线程安全的，我们这里主要看下ArrayList的扩容原理：<br><img src="https://oscimg.oschina.net/oscnet/37cc95a9d19fc2af1b91451bbd37304ad49.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/fdafff46f017ae55c7375832c43d1dea90f.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/8c7c5c256d1bf27a06a855d0aa356c9405c.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/5d0f0aba7712478f5d094f66ce776c9c26e.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/f3663c53d5c86a069a936a04d236ff88051.jpg" alt=""><br>ArrayList也是会先判断容器的容量大小，如果容量不足，则调用扩容方法grow函数，将容量扩展原来加原来一半也就是1.5倍</p><p><strong>3.LinkedList</strong><br><img src="https://oscimg.oschina.net/oscnet/63b46b4da6e09bda869ab3b23f67eab4dbc.jpg" alt=""><br>LinkedList是一个继承于AbstractSequentialList的双向链表，它也可以被当作堆栈、队列或双向队列进行操作。LinkedList实现 List 接口，能对它进行队列操作。LinkedList 实现 Deque 接口，即能将LinkedList当作双端队列使用。LinkedList 是非同步的（线程不安全的）。因为是双向链表，所以它的顺序访问会非常高效，而随机访问效率比较低。<br><img src="https://oscimg.oschina.net/oscnet/d52d65a636e82213e2619217cc72f9f7a27.jpg" alt=""></p><p>下面我们先看下LinkedList的添加元素的原理：<br><img src="https://oscimg.oschina.net/oscnet/0f80bb356f615c7f47dbbb7199f9beda35a.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/e94aa06b0e246e3e896556d31cb2c0ea588.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/819735183bc5e1bb503681935b46f91fa28.jpg" alt=""></p><p>我们从源码可以看到其实add添加元素的操作就是在容器的最后新增一个数据节点，具体分析：先把当前最后一个节点存档到l数据节点中，然后新增一个数据节点，这里有一个判断，如果l为空那就是说改链表是空的，这样这个新增元素即是第一个也是最后一个节点；如果l不为空，将当前最后一个节点变成新增的前一个节点，然后last存放新增节点使其变成最后一个元素节点，这样一个新增的操作就完成了。<br><img src="https://oscimg.oschina.net/oscnet/5e3d3b0f36975c1c958e8a59d1c024a19c0.jpg" alt=""></p><p>我们再来看看向制定位置添加数据节点的原理，看下面源码：<br><img src="https://oscimg.oschina.net/oscnet/c5c9310f6e64f3871acf1b5e22fab6cdfe9.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/c002765edf33f064117494b8a4d5741af07.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/df8fbacf9cfcfcfda92138431db2db62147.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/f83865b53f90f723d1954cc957a97d9dbfe.jpg" alt=""></p><p>首先是位置是否存在，添加元素的位置必须是大于等于0小于等于链表的大小；然后判断如果要添加元素的位置等于链表的大小，则该元素插入最有一个即可，否则在指点的位置前插入节点，先将该位置前的阶段存起来到pred，然后判断如果pred为空说明该链表是空的，则将新增数据节点写入第一个节点中，如果pred不为空，将原来的前一个节点的下一个节点指向新添加的节点，将新添加节点的下一个节点指向原来位置的下一个节点即可<br><img src="https://oscimg.oschina.net/oscnet/4f7a3b8c0fe48d74b45d3c6f1c63c180eb5.jpg" alt=""></p><p>接下来我们看下删除第一个节点元素：<br><img src="https://oscimg.oschina.net/oscnet/c72e9ede7324df4e8f6c7a5778e79f95768.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/3e1bc6624df2c5d04610e7a7682b4a19707.jpg" alt=""><br>删除时是先把原来的第一个节点的下一个节点存到first中，然后将第一个节点的指向都设置为null（删除），然后将first指向next就可以了，然后判断如果next为空则last设置为空，这时候整个链表也就是空的；反之释放next内存；然后将链表大小减小一个，将此列表已被结构修改的次数减一</p><p>接下来我们看下删除最后一个节点元素：<br><img src="https://oscimg.oschina.net/oscnet/9959835f1cc2fdc496c3e528814b071ed55.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/75aba4991698e08bd02506e081818045503.jpg" alt=""><br>删除最后一个元素是相对简单一些，删除最后一个节点，然后释放该节点指向前一个节点的指针空间和释放前一个节点指向下一个节点的指针空间，然后将链表大小减小一个，将此列表已被结构修改的次数减一<br><img src="https://oscimg.oschina.net/oscnet/75f3e011051eaad9e3c1fc356234a7a6f49.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      Java深究之Vector、ArrayList、LinkedList的区别
    
    </summary>
    
    
      <category term="代码深究" scheme="https://www.maxbill.cn/kinds/%E4%BB%A3%E7%A0%81%E6%B7%B1%E7%A9%B6/"/>
    
    
      <category term="Java" scheme="https://www.maxbill.cn/marks/Java/"/>
    
      <category term="Vector" scheme="https://www.maxbill.cn/marks/Vector/"/>
    
      <category term="ArrayList" scheme="https://www.maxbill.cn/marks/ArrayList/"/>
    
      <category term="LinkedList" scheme="https://www.maxbill.cn/marks/LinkedList/"/>
    
      <category term="容器" scheme="https://www.maxbill.cn/marks/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>Java深究之String、StringBuffer、StringBuilder的区别</title>
    <link href="https://www.maxbill.cn/2840479785.html"/>
    <id>https://www.maxbill.cn/2840479785.html</id>
    <published>2018-07-02T02:12:49.000Z</published>
    <updated>2020-07-07T13:36:38.415Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在Java学习中，String、StringBuffer、StringBuilder三者是很重要的，在编写代码中经常使用到他们，那么深入的了解他们的异同是非常重要的，接下里我们详细剖析下这三个的异同之处</p><p><strong>首先总结下这三者的区别：</strong></p><p><strong>基本区别</strong><br>String的对象不可变，StringBuffer和StringBuilder的对象是可变的</p><p><strong>性能区别</strong><br>三者中StringBuilder执行速度最佳，StringBuffer次之，String的执行速度最慢（String为字符串常量，而StringBuilder和StringBuffer均为字符串变量，String对象一旦创建后该对象是不可更改的，后两者的对象是变量是可以更改的）</p><p><strong>安全区别</strong><br>String、StringBuffer是线程安全的，StringBuilder是线程不安全的（所以如果程序是单线程的使用StringBuilder效率高，如果是多线程使用StringBuffer或者String）</p><p><strong>其次总结下这三者的相同：</strong><br>1.三者在java中都是用来处理字符串的<br>2.三个类都被final修饰，因此都是不可继承的<br>3.StringBuilder与StringBuffer有公共父类AbstractStringBuilder(抽象类)</p><p><strong>接下来我们从源码和案例深入分析这三者：</strong></p><h2 id="String"><a href="#String" class="headerlink" title="String"></a><strong>String</strong></h2><p><img src="https://oscimg.oschina.net/oscnet/58422cbfc4738f98ce1c69c26c5889b7016.jpg" alt=""><br>String常用方法：<br>1.length（）           获取字符串长度<br>2.replace（）          替换字符串中某些字符<br>3.equals（）            比较两个字符对象内容是否相同<br>4.substring（）       截取一个新的字符串，它是此字符串中的子串<br>5.trim（）               将字符串开头的空白（空格）和尾部的空白去掉<br>6.indexOf（）         求某个字符在字符串中的位置<br>7.charAt（）           求一个字符串中某个位置的值<br>8.toLowerCase（） 将字符串中所有的大写改变成小写<br>9.toUpperCase（） 将字符串中所有的小写改变为大写<br><img src="https://oscimg.oschina.net/oscnet/ed47594e4e2c11e5517952bda15a13663c9.jpg" alt="">         </p><p>注意：<br>1.String是final类型，不可被继承；<br>2.String的对象不可变<br><img src="https://oscimg.oschina.net/oscnet/098a46d4ac86b016e570c1d57611c0070b2.jpg" alt=""><br>从上面这个案例我们发现a对象的内容被改变了，不是说不能改变么，这里我们不能被表面迷惑，我们再看下面的程序<br><img src="https://oscimg.oschina.net/oscnet/451a0f2e887124165318d0910715e875693.jpg" alt=""><br>我们发现字符串a被重新赋值后其实已经不是它自己了，从hashCode值可以看出。当a字符串创建赋值maxbill，然后重新赋值时又会创建一个a对象值为：maxbill1993，此时844527467是一已经在等待GC回收了，我们看到的实际上是-1438782163对象。所以我们在程序中对字符串使用+连接时，并不是把内容动态的改变进去，而是每次都会创建一个新的String对象去放新的字符内容，原来的对象会等着GC回收，所以这也是String为啥相比其他两者执行慢的原因了。</p><h2 id="StringBuffer"><a href="#StringBuffer" class="headerlink" title="StringBuffer"></a><strong>StringBuffer</strong></h2><p><img src="https://oscimg.oschina.net/oscnet/76a088b2c78b2725f249d01aaac64a3ab7e.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/348c50773408ec456af5f6d0fffd6e286e9.jpg" alt=""><br>从StringBuffer类的源码可以看出，其方法都被同步锁synchronized修饰，因此是线程安全的，因此在多线程编程中操作字符串是推荐使用为什么说StringBuffer比String的执行速度要高，前面说了String的原理，是导致其慢的原因，StringBuffer相比快是因为使用了字符串变量，是可以动态改变的，不必像String一样总是去创建对象赋值新内容，我们</p><p>看下面的案例就明白了<br><img src="https://oscimg.oschina.net/oscnet/0239d47ff547c2f24599d5f0eaf1641803c.jpg" alt=""><br>由上面的案例可以看出StringBuffer在修改字符串内容时，不会创建新的对象，因此它比String类效率更高<br>StringBuffer常用方法：<br>1.length（）             获取StringBuffer字符长度<br>2.append（）          向StringBuffer增加字符<br>3.delete（）             删除StringBuffer中的字符<br>4.replace（）           替换StringBuffer中的字符<br>5.insert（）              向StringBuffer中插入字符<br>6.toString （）         把StringBuffer转成字符串<br>StringBuffer的append方法源码解读：<br><img src="https://oscimg.oschina.net/oscnet/54c519f69db61c95b2c91f73bd06a9880f3.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/a248ac03f7a778bf2fc87cbf17d2021e58e.jpg" alt=""><br>调用了父类的append方法，我们看下父类append的源码<br><img src="https://oscimg.oschina.net/oscnet/7b91dba0e4a898112cd402ede6671ec7cd7.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/1ce1a2de74d9f9e9a0b5a57c76a4114aa1b.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/aee8353c3460f5f9b529e88d0dfb3ba8e03.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/6a6e9e77a96a39a33465c7d01135a96b56c.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/5e1065447b0410be1883b7cc6cc1b530801.jpg" alt=""><br><img src="https://oscimg.oschina.net/oscnet/613de619050047539c30999612b6e4bc08e.jpg" alt=""><br>基本原理：使用append()方法在字符串后面追加东西的时候，如果长度超过了该字符串存储空间大小了就需要进行扩容，构建新的存储空间更大的字符串，将旧的数据的复制过去<br>详细原理：char value[]用来存储数据，int count用来记录字符长度，StringBuffer初始16个字符容量 ，先记录下传进来字符串的长度，然后使用ensureCapacityInternal函数判是否需要扩容，如果容量不够则使用newCapacity进行扩容，新容量扩为原来2倍+2，存储容量够了使用getChars函数复制数据，最后将count更新。</p><h2 id="StringBuilder"><a href="#StringBuilder" class="headerlink" title="StringBuilder"></a><strong>StringBuilder</strong></h2><p><img src="https://oscimg.oschina.net/oscnet/cf4cab5758d8ef24ed2c20eff57a4cb3a95.jpg" alt=""><br>StringBuilder和StringBuffer的使用方法和原理基本一致的，唯一的区别就是StringBuilder是线程不安全的，执行效率要比StringBuffer高，因此当时单线程的时候推荐使用线程不安全的StringBuilder效率更高一些，如果是多线程推荐使用StringBuffer来保证线程安全</p>]]></content>
    
    <summary type="html">
    
      Java深究之String、StringBuffer、StringBuilder的区别
    
    </summary>
    
    
      <category term="代码深究" scheme="https://www.maxbill.cn/kinds/%E4%BB%A3%E7%A0%81%E6%B7%B1%E7%A9%B6/"/>
    
    
      <category term="Java" scheme="https://www.maxbill.cn/marks/Java/"/>
    
      <category term="String" scheme="https://www.maxbill.cn/marks/String/"/>
    
      <category term="StringBuffer" scheme="https://www.maxbill.cn/marks/StringBuffer/"/>
    
      <category term="StringBuilder" scheme="https://www.maxbill.cn/marks/StringBuilder/"/>
    
  </entry>
  
  <entry>
    <title>Java深究之final、finally、finalize三者的区别</title>
    <link href="https://www.maxbill.cn/4599877800.html"/>
    <id>https://www.maxbill.cn/4599877800.html</id>
    <published>2018-06-29T08:22:37.000Z</published>
    <updated>2020-03-07T08:01:23.682Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在java中final、finally、finalize三者在写法上很相近，但是实际含义和作用却是相差甚远。本文主要是来深层的研究下这三者的用法以及之间的区别</p><h2 id="final"><a href="#final" class="headerlink" title="final"></a><strong>final</strong></h2><p>属性：java中的关键字，修饰符<br>作用：用于修饰类、成员方法、变量（成员变量、局部变量）<br>用法：如果类被声明为final，那么该类就不能再派生出新的子类，也不能当作父类被子类继承。一个类不能同时被声明为抽象类（absrtact修饰）和final的类；如果成员方法被声明final，那么该方法只能使用，不能重载；如果变量（成员变量、局部变量）被声明为final，那么必须在声明时给定初始化的值，在后面的引用中只能读取，不可修改值。</p><p>注意：<br>1.类被声明为final，类中的所有成员方法都会被隐式地指定为final方法；<br>2.final成员变量必须在声明的时候初始化或者在构造器中初始化，否则编译时会报错；<br>3.在匿名类（内部类）中所有变量都必须是final变量；<br>4.在接口中声明的所有变量本身是final的；<br>5.如果基本数据类型的变量被声明为final，则其数值一旦在初始化之后便不能更改<br><img src="https://oscimg.oschina.net/oscnet/135f772d6d484d11d8f0da62d63ac441197.jpg" alt=""><br>如果引用类型的变量被声明为final，则在对其初始化之后便不能再让其指向另一个对象，但该对象的内容是可以改变的<br><img src="https://oscimg.oschina.net/oscnet/50b42e4445d80f1b53e7b36ec4284b48c78.jpg" alt=""><br>6.当final变量是基本数据类型以及String类型时，在编译期间是知道它的确切值，那么编译器会把它当做编译期常量，在用到该final变量的地方，相当于直接访问的这个常量<br><img src="https://oscimg.oschina.net/oscnet/099ea033fb54b237e7377305d4858932fa3.jpg" alt=""><br>只有在编译期间能确定final变量值的时候才会被当编译常量，以下是编译时不知道确定值的<br><img src="https://oscimg.oschina.net/oscnet/642942af101c9a8c8cdc9619a26edb47ca0.jpg" alt=""></p><h2 id="finally"><a href="#finally" class="headerlink" title="finally"></a><strong>finally</strong></h2><p>属性：异常处理时的finally块<br>作用:  try { 正常逻辑 } catch(Exception e) { 异常逻辑 } finally{ 一定会被执行的逻辑 }<br>用法：异常处理（try  catch）时finally块无论有没有异常发生，finally块的代码一定会被执行，所以在程序中有需要无论发生什么都必须执行的代码，就可以放在finally块中，最常见流关闭等释放资源的操作<br>注意：1.finally代码块无论有没有异常发生，finally块的代码一定会被执行； 2.即使try里包含continue、break、return语句，try块结束后，finally块也会执行； 3.finally中最好不要包含return，否则程序会提前退出，返回值不是try或catch中保存的返回值</p><h2 id="finalize"><a href="#finalize" class="headerlink" title="finalize"></a><strong>finalize</strong></h2><p>属性：方法名，Object中的方法<br>作用：finalize()方法是在垃圾收集器删除对象之前对这个对象调用<br>用法：Java中使用finalize()方法在垃圾收集器将对象从内存中清除出去之前（GC之前）做必要的清理内存的工作。这个方法是在垃圾收集器确认一个对象没有被引用时对这个对象调用的。它在Object类中定义的，所有的类都继承了它。子类覆盖finalize()方法已整理系统资源或者执行其他清理工作。finalize()方法是在垃圾收集器删除对象之前对这个对象调用的<br>注意：<br>1.垃圾回收器要回收对象的时候，首先要调用这个类的finalize方法<br><img src="https://oscimg.oschina.net/oscnet/01ba97e2a7db45797bca01967f2dc1093ac.jpg" alt=""><br>2.程序退出时为每个对象调用一次finalize方法<br>3.当某个对象被系统收集为无用信息的时候,finalize()将被自动调用,但是jvm不保证finalize()一定被调用<br>4.finalize()方法被关键字protected修饰是防止在该类之外定义的代码访问finalize()标识符<br><img src="https://oscimg.oschina.net/oscnet/8bd8c55421159839091fc1a8c23602762ea.jpg" alt=""><br>5.finalize()方法的主要用途是释放一些其他做法开辟的内存空间，以及做一些清理工作<br>6.一旦垃圾回收器GC准备好释放对象占用的存储空间，首先会去调用finalize()方法进行一些必要的清理工作。只有到下一次再进行垃圾回收动作的时候，才会真正释放这个对象所占用的内存空间<br>7.finalize()现在已经不推荐使用了，java9已经设置为deprecated了</p>]]></content>
    
    <summary type="html">
    
      Java深究之final、finally、finalize三者的区别
    
    </summary>
    
    
      <category term="代码深究" scheme="https://www.maxbill.cn/kinds/%E4%BB%A3%E7%A0%81%E6%B7%B1%E7%A9%B6/"/>
    
    
      <category term="Java" scheme="https://www.maxbill.cn/marks/Java/"/>
    
      <category term="final" scheme="https://www.maxbill.cn/marks/final/"/>
    
      <category term="finally" scheme="https://www.maxbill.cn/marks/finally/"/>
    
      <category term="finalize" scheme="https://www.maxbill.cn/marks/finalize/"/>
    
  </entry>
  
  <entry>
    <title>SonarQube之配置外部数据存储和基本使用</title>
    <link href="https://www.maxbill.cn/3926558290.html"/>
    <id>https://www.maxbill.cn/3926558290.html</id>
    <published>2018-05-24T03:54:15.000Z</published>
    <updated>2020-07-14T15:24:17.779Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在上篇文章《SonarQube之代码质量分析管理》中，我们说明了项目代码质量的重要性，以及当前代码质量分析管理的一些工具，然后详细说明了SonarQube质量分析管理工具的安装部署和代码扫描分析的过程。上文我们说到SonarQube是使用自己默认的内置的数据库，在一些功能上会受到限制，本文我们将内置存储改为外置mysql存储，然后在分析项目代码，对项目代码严重性地方进行修复工作，然后介绍SonarQube其他的一些基本的使用（设置、插件安装等）</p><h2 id="一、准备工作"><a href="#一、准备工作" class="headerlink" title="一、准备工作"></a>一、准备工作</h2><p>1.代码分析管理平台SonarQube（已部署）</p><p>2.mysql数据库服务5.6-5.7</p><h2 id="二、配置外部数据存储"><a href="#二、配置外部数据存储" class="headerlink" title="二、配置外部数据存储"></a>二、配置外部数据存储</h2><p>1.配置SonarQube数据服<br>打开我们上文安装的SonarQube的根目录，然后进入conf目录，修改sonar.properties文件<br><img src="https://static.oschina.net/uploads/space/2018/0524/095516_hKSp_2846946.png" alt=""><br>sonar.jdbc.url=jdbc:mysql://maxbill:3306/sonar?useUnicode=true&amp;characterEncoding=utf8&amp;rewriteBatchedStatements=true&amp;useConfigs=maxPerformance&amp;useSSL=false<br>sonar.jdbc.username=sonar<br>sonar.jdbc.password=sonar<br>参数说明：<br>sonar.jdbc.url  数据库连接地址<br>sonar.jdbc.username  数据库用户名<br>sonar.jdbc.password  数据库密码<br>我们在数据库中创建sonar数据库，并设置授权：<br>CREATE DATABASE sonar CHARACTER SET utf8 COLLATE utf8_general_ci;<br>CREATE USER ‘sonar’ IDENTIFIED BY ‘sonar’;<br>GRANT ALL ON sonar.* TO ‘sonar’@’%’ IDENTIFIED BY ‘sonar’;<br>GRANT ALL ON sonar.* TO ‘sonar’@’localhost’ IDENTIFIED BY ‘sonar’;<br>FLUSH PRIVILEGES;<br><img src="https://static.oschina.net/uploads/space/2018/0524/095643_8zdL_2846946.png" alt=""></p><p>2.验证配置<br>启动sonarqube服务，初始化数据库信息（使用上文我们编写的启动脚本）<br><img src="https://static.oschina.net/uploads/space/2018/0522/111619_tqEC_2846946.png" alt=""><br>此刻，SonarQube已经启动成功，我们访问 http : // localhost: 9000，发现访问不到页面<br><img src="https://static.oschina.net/uploads/space/2018/0523/110823_AzlJ_2846946.png" alt=""><br>此时我们只能去看sonar的日志，定位到sonar的log目录下，找到web.log文件<br><img src="https://static.oschina.net/uploads/space/2018/0523/111532_6veN_2846946.png" alt=""><br>从日志中我们明显的看到以下错误，该版本的必须使用mysql5.6及以上版本：<br>2018.05.23 11:10:49 ERROR web[ ][o.s.s.p.Platform] Web server startup failed: Unsupported<br>mysql version: 5.5. Minimal supported version is 5.6.</p><p>3.解决mysql版本低的问题<br>经过查询sonar的日志，我们知道使我们的mysql版本低导致的运行初始化异常，我们升级mysql到6.0(备注：我主机上刚好有6.0的包，只要升级到6.0及以上就行)，升级过程忽略，大家可自行百度，或者 重新卸载安装也是可以的<br><img src="https://static.oschina.net/uploads/space/2018/0523/114811_Ukyp_2846946.png" alt=""><br>此时我们重启sonarqube，访问 http : // localhost: 9000<br><img src="https://static.oschina.net/uploads/space/2018/0523/114933_9UZM_2846946.png" alt=""><br>结果还是报错：<br><img src="https://static.oschina.net/uploads/space/2018/0523/123156_hWUR_2846946.png" alt=""><br>报Unknown character set: ‘utf8mb4’异常，查找了许多资料，以为mysql6.0版本不支持，最后发现不是mysql的问题，而是mysql驱动引起的问题。将mysql驱动改成 mysql-connector-java-5.1.6-bin.jar<br><img src="https://static.oschina.net/uploads/space/2018/0523/122943_7KWC_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2018/0523/123604_RWc0_2846946.png" alt=""><br>本以为就完美解决了，天公不作美，又有新问题了，启动访问不到，继续看日志<br><img src="https://static.oschina.net/uploads/space/2018/0523/133836_AuWU_2846946.png" alt=""><br>查了N多的资料，没找到解决办法，看日志应该是7.1版本的BUG(最新的版本)，于是下载6.7.3版本部署后，重复上面的配置步骤，启动访问<a href="http://127.0.0.1:9000">http://127.0.0.1:9000</a> 还是访问不到，看日志如上的异常信息，于是排除sonarqube版本问题，怀疑是mysql版本导致，果断卸载mysql6.0重新安装mysql5.6版本，然后重新启动程序，访问<a href="http://127.0.0.1:9000">http://127.0.0.1:9000</a> ，我们看到程序在进行数据初始化，如下：<br><img src="https://static.oschina.net/uploads/space/2018/0524/095214_Z6MY_2846946.png" alt=""><br>我们使用客户端连接mysql数据库看看表中数据：<br><img src="https://static.oschina.net/uploads/space/2018/0524/103243_sHli_2846946.png" alt=""><br>注意：后面又切回SonarQube7.1也是正常的，所以大家注意下最好使用mysql5.6-5.7版本<br><img src="https://static.oschina.net/uploads/space/2018/0524/104836_DAs0_2846946.png" alt=""><br>此时我们可以看到使用了外置的mysql数据库后，这里的警告提示消失了</p><p>4.配置Scanner扫描工具<br>打开我们上文安装的Scanner的根目录，然后进入conf目录，修改sonar-scanner.properties文件<br><img src="https://static.oschina.net/uploads/space/2018/0524/104341_Tq6Q_2846946.png" alt=""><br>sonar.jdbc.url=jdbc:mysql://maxbill:3306/sonar?useUnicode=true&amp;characterEncoding=utf8&amp;rewriteBatchedStatements=true&amp;useConfigs=maxPerformance&amp;useSSL=false<br>sonar.jdbc.username=sonar<br>sonar.jdbc.password=sonar</p><h2 id="三、使用SonarScanner扫描分析代码"><a href="#三、使用SonarScanner扫描分析代码" class="headerlink" title="三、使用SonarScanner扫描分析代码"></a>三、使用SonarScanner扫描分析代码</h2><p>由于我们使用了外置的数据库之前扫描分析的信息就丢失了，我们使用scanner重新扫描分析项目代码进入我们要扫描的项目的更目录下面，运行终端执行sonar-scanner<br><img src="https://static.oschina.net/uploads/space/2018/0522/113507_Ylfm_2846946.png" alt=""><br>等待项目被扫描分析完成<br><img src="https://static.oschina.net/uploads/space/2018/0522/113554_Wsmd_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2018/0522/114729_uQeu_2846946.png" alt=""><br>扫描分析完成我们登陆SonarQube代码分析管理平台等待分析结果<br><img src="https://static.oschina.net/uploads/space/2018/0524/110908_sHsb_2846946.png" alt=""><br>稍等一会就分析完成了，我们可以看待项目分析的详情：<br><img src="https://static.oschina.net/uploads/space/2018/0524/111146_ttan_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2018/0524/111544_i7MB_2846946.png" alt=""></p><h2 id="四、使用SonarQube解决代码问题"><a href="#四、使用SonarQube解决代码问题" class="headerlink" title="四、使用SonarQube解决代码问题"></a>四、使用SonarQube解决代码问题</h2><p>我们在项目代码分析详情中点击问题标签，可以看到项目列出来的不同级别的问题列表<br><img src="https://static.oschina.net/uploads/space/2018/0524/111705_3I5Y_2846946.png" alt=""><br>我们点击右侧阻断性的问题（最严重，必须要改的）<br><img src="https://static.oschina.net/uploads/space/2018/0524/111850_tg1F_2846946.png" alt=""><br>我们点击一个进入，可以看到错误的代码块位置，以及系统的改错提示：<br><img src="https://static.oschina.net/uploads/space/2018/0524/112350_aJiU_2846946.png" alt=""><br>在这里可以去修复这个问题，也可以去修改这个问题的级别，可以评论，可以给该问题打上标签，可以将该问题分配给该项目其他成员。</p><h2 id="五、其他功能介绍"><a href="#五、其他功能介绍" class="headerlink" title="五、其他功能介绍"></a>五、其他功能介绍</h2><p>1.插件安装<br>系统默认是英文，可以安装中文插件（本文已安装）<br><img src="https://static.oschina.net/uploads/space/2018/0524/113250_XaxS_2846946.png" alt=""><br>插件市场中我们可以安装、卸载、更新插件，当然也可以去github下载第三方开发的插件安装</p><p>2.系统日志<br><img src="https://static.oschina.net/uploads/space/2018/0524/113602_RKy9_2846946.png" alt=""><br>在这里我们可以查看系统、web、引擎的基本信息、改动日志级别、下载系统信息、下载日志信息、在线重启SonarQube数据管理系统</p><p>3.权限控制<br><img src="https://static.oschina.net/uploads/space/2018/0524/113950_poct_2846946.png" alt=""><br>在权限控制中，可以管理系统的用户（新增、删除、禁用、修改密码、分配组、查看详情）、管理系统群组（创建、删除、更新、管理群组中人员）、给用户或者群组分配系统功能操作权限、配置权限模板等</p><p>4.代码规则<br><img src="https://static.oschina.net/uploads/space/2018/0524/114527_kYLF_2846946.png" alt=""><br>在这里可以配置各种语言的代码分析规则（可以配置自定义的规则）</p><p>5.质量配置<br><img src="https://static.oschina.net/uploads/space/2018/0524/114651_ITy1_2846946.png" alt=""><br>在质量配置中可以自定义不同语言系统分析代码质量使用的质量阀值（影响代码分析结果）</p><h2 id="六、总结"><a href="#六、总结" class="headerlink" title="六、总结"></a>六、总结</h2><p>本文中踩了不少的坑，主要还是sonar和mysql的版本兼容性问题，这里也再次提醒大家（按照sonar的配置文件提示使用mysql版本，sonar7.1使用mysql5.6-5.7），其他就是简单的使用的配置了。</p>]]></content>
    
    <summary type="html">
    
      SonarQube之配置外部数据存储和基本使用
    
    </summary>
    
    
      <category term="代码审计" scheme="https://www.maxbill.cn/kinds/%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"/>
    
    
      <category term="Sonar" scheme="https://www.maxbill.cn/marks/Sonar/"/>
    
      <category term="Scanner" scheme="https://www.maxbill.cn/marks/Scanner/"/>
    
      <category term="SonarQube" scheme="https://www.maxbill.cn/marks/SonarQube/"/>
    
      <category term="SonarScanner" scheme="https://www.maxbill.cn/marks/SonarScanner/"/>
    
  </entry>
  
  <entry>
    <title>SonarQube之代码质量分析管理</title>
    <link href="https://www.maxbill.cn/7101192600.html"/>
    <id>https://www.maxbill.cn/7101192600.html</id>
    <published>2018-05-22T04:22:20.000Z</published>
    <updated>2020-07-14T15:22:49.568Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在之前的开发中，代码的工作量化和质量化都是一个问题，随着近几年互联网行业的快速发展，代码已经可以来工作量化和质量化，今天我们来说说代码的质量化。代码的质量不是一个小问题，代码的质量问题可能会导致整个软件项目的失败，甚至更严重的问题，因此在日常的代码开发过程中加强代码审计工作（PM）是必要的，同时开发人员自己也应该注重代码质量。目前行业内对代码质量化分析工具有阿里巴巴的p3c、Sonar质量分析工具等，本文我们主要来研究下Sonar这个相比功能比较强大的质量分析工具。</p><h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><p>SonarQube 是一个代码质量管理的开放平台。通过插件机制，SonarQube 可以集成不同的测试工具，代码分析工具，以及持续集成工具。与持续集成工具（例如JenKins、Hudson等）不同，SonarQube 并不是简单地把不同的代码检查工具结果（例如 FindBugs、PMD等）直接显示在 Web 页面上，而是通过不同的插件对这些结果进行再加工处理，通过量化的方式度量代码质量的变化，从而可以方便地对不同规模和种类的工程进行代码质量管理。</p><p>在对其他工具的支持方面，SonarQube 不仅提供了对IDE的支持，可以在Eclipse和IntellijIdea 这些工具里联机查看结果；同时 SonarQube 还对大量的持续集成工具提供了接口支持，可以很方便地在持续集成中使用 SonarQube 。 此外，SonarQube 的插件还可以对Java以外的JavaScript、Xml、C#等其他编程语言提供支持，对国际化以及报告文档化也有良好的支持。</p><h2 id="二、准备工作"><a href="#二、准备工作" class="headerlink" title="二、准备工作"></a>二、准备工作</h2><p>1.代码分析管理平台SonarQube安装包（本文7.1）<br>sonarqube-7.1.zip<br>下载地址：<a href="https://www.sonarqube.org/downloads">https://www.sonarqube.org/downloads</a></p><p>2.代码分析扫描工具Scanner安装包（本文2.5）<br>sonar-scanner-2.5.zip<br>下载地址：<a href="https://sonarsource.bintray.com/Distribution/sonar-scanner-cli">https://sonarsource.bintray.com/Distribution/sonar-scanner-cli</a></p><p>3.JDK（本文1.8）<br>下载地址：<a href="https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html">https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html</a></p><p>4.mysql数据库（本文5.5.56）<br>下载地址：<a href="https://dev.mysql.com/downloads/mysql">https://dev.mysql.com/downloads/mysql</a></p><h2 id="三、部署过程"><a href="#三、部署过程" class="headerlink" title="三、部署过程"></a>三、部署过程</h2><p>1.解压代码分析管理平台SonarQube安装包sonarqube-7.1.zip<br><img src="https://static.oschina.net/uploads/space/2018/0522/105418_RMNE_2846946.png" alt=""></p><p>2.解压代码分析扫描工具Scanner安装包sonar-scanner-2.5.zip<br><img src="https://static.oschina.net/uploads/space/2018/0522/105859_ZdTr_2846946.png" alt=""></p><p>3.配置环境变量<br>终端输入vi /etc/profile编辑环境变量<br><img src="https://static.oschina.net/uploads/space/2018/0522/110133_kseE_2846946.png" alt=""><br>终端输入source /etc/profile使环境变量生效</p><p>4.编写启动脚本<br> <img src="https://static.oschina.net/uploads/space/2018/0522/111540_BXHA_2846946.png" alt=""></p><p>5.启动SonarQube<br>在终端执行我们刚编写的启动脚本<br><img src="https://static.oschina.net/uploads/space/2018/0522/111619_tqEC_2846946.png" alt=""><br>此刻，SonarQube已经启动成功，我们访问http : // localhost: 9000<br><img src="https://static.oschina.net/uploads/space/2018/0522/111809_0TCE_2846946.png" alt=""><br>然后我们登陆SonarQube代码质量分析系统，用户名/密码 , 默认admin/admin<br><img src="https://static.oschina.net/uploads/space/2018/0522/111941_xoON_2846946.png" alt=""><br>备注，里面的两个项目是我之前分析过的。</p><p>6.配置SonarScanner项目扫描工具<br>我们首先编写一个sonar-project.properties的配置文件<br> <img src="https://static.oschina.net/uploads/space/2018/0522/112352_O153_2846946.png" alt=""><br>然后将改配置文件放到被分析检查项目的目录下<br><img src="https://static.oschina.net/uploads/space/2018/0522/112528_cM0e_2846946.png" alt=""><br>注意：如果项目处于版本控制中，会连接版本控制工具去检查，如果连接不通会报错误，这里我们直接删除和svn的关联，然后进行代码检查</p><p>7.运行SonarScanner代码扫描工具<br>进入我们要扫描的项目的更目录下面，运行终端执行sonar-scanner<br><img src="https://static.oschina.net/uploads/space/2018/0522/113507_Ylfm_2846946.png" alt=""><br>等待项目被扫描分析完成:<br><img src="https://static.oschina.net/uploads/space/2018/0522/121938_9Otl_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2018/0522/113554_Wsmd_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2018/0522/114729_uQeu_2846946.png" alt=""><br>扫描分析完成我们登陆SonarQube代码分析管理平台查看被分析的项目：<br><img src="https://static.oschina.net/uploads/space/2018/0522/122048_X44q_2846946.png" alt=""><br>我们点进去看下改项目代码分析的详情<br><img src="https://static.oschina.net/uploads/space/2018/0522/122147_tFHY_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2018/0522/122221_ThXo_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2018/0522/122258_fMhi_2846946.png" alt=""></p><h2 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h2><p>本文主要说了下代码质量分析工具SonarQube，该工具可以分析出项目的代码质量，目前我们已经成功的部署了SonarQube代码分析管理平台，并且运行SonarScanner代码扫描工具扫描分析了项目的代码质量，下篇文章我们将介绍使用SonarQube代码分析管理平台怎么去监控项目代码质量、分析项目质量、解决项目中的质量问题等，本文中还有一个问题，就是SonarQube默认使用的内嵌数据库，对于测试来说是够用了，但是正式使用会有一些限制，下文中我们将介绍SonarQube如何使用外置的mysql数据库。</p>]]></content>
    
    <summary type="html">
    
      SonarQube之代码质量分析管理
    
    </summary>
    
    
      <category term="代码审计" scheme="https://www.maxbill.cn/kinds/%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"/>
    
    
      <category term="Sonar" scheme="https://www.maxbill.cn/marks/Sonar/"/>
    
      <category term="Scanner" scheme="https://www.maxbill.cn/marks/Scanner/"/>
    
      <category term="SonarQube" scheme="https://www.maxbill.cn/marks/SonarQube/"/>
    
      <category term="SonarScanner" scheme="https://www.maxbill.cn/marks/SonarScanner/"/>
    
  </entry>
  
  <entry>
    <title>LinuxDeploy上安装Docker容器</title>
    <link href="https://www.maxbill.cn/2338615630.html"/>
    <id>https://www.maxbill.cn/2338615630.html</id>
    <published>2018-05-14T07:55:31.000Z</published>
    <updated>2020-07-07T13:25:31.470Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="一、环境准备"><a href="#一、环境准备" class="headerlink" title="一、环境准备"></a>一、环境准备</h2><p>1.使用Linux Deploy安装Debian的手机<br>2.使用SSH远程连接到debian</p><h2 id="二、操作步骤"><a href="#二、操作步骤" class="headerlink" title="二、操作步骤"></a>二、操作步骤</h2><p>1.以sudo或者root权限登陆用户</p><p>2.清除旧的仓库：<br><code>$ sudo apt-get purge lxc-docker*</code><br><code>$ sudo apt-get purge docker.io*</code></p><p>3.更新软件包信息，确保APT以HTTPS方式工作，并且CA certificates已安装：<br><code>$ sudo apt-get install apt-transport-https ca-certificates</code></p><p>4.添加新的GPG密钥<br><code>$ sudo apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609</code></p><p>5.使用文件编辑器打开/etc/apt/sources.list.d/docker.list，如果该文件不存在则创建它。<br>删除所有已存在的条目，然后添加以下内容：<br><code>deb https://apt.dockerproject.org/repo debian-jessie main</code></p><p>6.更新APT软件包索引<br><code>$ sudo apt-get update</code></p><p>7.安装docker<br><code>$ sudo apt-get install docker-engine</code> </p><h2 id="三、安装验证"><a href="#三、安装验证" class="headerlink" title="三、安装验证"></a>三、安装验证</h2><p>我们通过service docker  start启动docker引擎，感觉启动异常一下就好了，都没启动小点闪烁动画，<br>我们通过service docker  status 查看docker状态<br><img src="https://static.oschina.net/uploads/space/2018/0409/130404_NnbU_2846946.png" alt=""><br>启动失败，我们查看日志，Docker 引擎日志 一般是交给了 Upstart(Ubuntu 14.04) 或者 systemd (CentOS 7, Ubuntu 16.04)。前者一般位于 /var/log/upstart/docker.log 下，后者一般通过 jounarlctl -u docker 来读取。不同系统的位置都不一样，网上有人罗列了下可以参考：<br><img src="https://oscimg.oschina.net/oscnet/30142a7fa6ba561882151f350a4be8ac0bf.jpg" alt=""><br>我们通过终端查看docker运行日志：<br><img src="https://static.oschina.net/uploads/space/2018/0409/125821_CBP3_2846946.png" alt=""><br>详细日志如下：<br><img src="https://static.oschina.net/uploads/space/2018/0409/130201_bzo9_2846946.png" alt=""><br>通过上面的日志能看到：<br>level=fatal msg=”Your Linux kernel version 3.4.0-gf4b741d-00692-gd785c3d is not supported for running docker. Please upgrade your kernel to 3.10.0 or newer.”<br>该日志提示系统的内核过低，至少需要内核版本在3.10.0或者更新的版本，然后我们升级系统的内核版本，启动docker即可。<br>docker的使用教程参考后面的docker操作文章</p>]]></content>
    
    <summary type="html">
    
      LinuxDeploy上安装Docker容器
    
    </summary>
    
    
      <category term="玩机分享" scheme="https://www.maxbill.cn/kinds/%E7%8E%A9%E6%9C%BA%E5%88%86%E4%BA%AB/"/>
    
    
      <category term="Docker" scheme="https://www.maxbill.cn/marks/Docker/"/>
    
      <category term="Linux" scheme="https://www.maxbill.cn/marks/Linux/"/>
    
      <category term="LinuxDeploy" scheme="https://www.maxbill.cn/marks/LinuxDeploy/"/>
    
      <category term="Android" scheme="https://www.maxbill.cn/marks/Android/"/>
    
  </entry>
  
  <entry>
    <title>LinuxDeploy上安装Jdk和MySQL</title>
    <link href="https://www.maxbill.cn/1652433373.html"/>
    <id>https://www.maxbill.cn/1652433373.html</id>
    <published>2018-04-06T10:52:43.000Z</published>
    <updated>2020-07-14T15:37:03.430Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>由于我们安装的Linux是基于arm的cpu架构的，因此jdk和mysql也必须安装arm版本的，之前折腾了半天就是安装错版本了，导致jdk一直不能正常使用。还有mysql的安装配置也比较奇葩，限于安卓对系统的限制，因此需要做一些特殊的配置才能跑起来。</p><h2 id="一、安装JDK"><a href="#一、安装JDK" class="headerlink" title="一、安装JDK"></a>一、安装JDK</h2><p>刚刚在摘要里说了，我的手机cpu架构是arm，所以我们下载JDK就要ARM版本的，翻了翻Oracle Jdk官网，惊喜的发现是有arm版本的，地址：<a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html">http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html</a> , 然后上传到手机的Linux容器中解压安装配置环境变量即可，可参考之前的博文：《<a href="https://my.oschina.net/zss1993/blog/1591353">Linux开发环境搭建之Java开发环境JDK安装配置</a> 》<br><img src="https://static.oschina.net/uploads/space/2018/0406/174437_G6qS_2846946.png" alt=""><br>安装成功后验证：<br><img src="https://static.oschina.net/uploads/space/2018/0406/175044_TzQO_2846946.png" alt=""></p><h2 id="二、安装MySql"><a href="#二、安装MySql" class="headerlink" title="二、安装MySql"></a>二、安装MySql</h2><p>由于mysql没有arm版本的，在官网找不到，或者需要自己手动移植编译arm版本的，我们这里直接使用install在其源中安装即可在（这里以mariadb为例，MYSQL一样）：<br>centos:    yum install mariadb-server/mysql-server<br>debian:   apt-get install mariadb-server/mysql-server</p><p>重新安装：<br>sudo apt-get remove –purge mysql-*<br>sudo apt-get install mysql-server<br><img src="https://static.oschina.net/uploads/space/2018/0406/094200_7a1Q_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2018/0406/094253_Ykby_2846946.png" alt=""><br>进过以上安装步骤，mysql就成功安装了，接下里开始设置：<br>首先使用service mysql start 启动mysql服务，然后在终端执行usermod -aG aid_inet mysql<br><img src="https://static.oschina.net/uploads/space/2018/0406/183417_8ysQ_2846946.png" alt=""><br>然后开始设置初始密码等，执行mysql_secure_installation<br><img src="https://static.oschina.net/uploads/space/2018/0406/180917_cOV4_2846946.png" alt=""><br>移除匿名用户，选择Y；不允许ROOT远程连接，选择N；到最后完成即可。<br>注意：由于安卓的限制，usermod -aG aid_inet mysql这一步特别重要<br>这时候安装完成了，但是我们使用远程工具navicat连接提示：<br>2003 - Can’t connect to MySQL server on ‘192.168.100.100’ (10038)<br>这是因为MYSQL默认绑定了 本机127.0.0.1地址，外网无法访问，于是我们更改配置文件：vi /etc/mysql/mariadb.conf.d/50-server.cnf<br><img src="https://static.oschina.net/uploads/space/2018/0406/184116_KedW_2846946.png" alt=""><br>此时我们使用navicat连接则正常：<br><img src="https://static.oschina.net/uploads/space/2018/0406/184320_4VXQ_2846946.png" alt=""></p><h2 id="三、问题记录"><a href="#三、问题记录" class="headerlink" title="三、问题记录"></a>三、问题记录</h2><p>1.启动MYSQL总是提示：<br>ERROR 1045 (28000): Access denied for user ‘root’@’localhost’ (using password: NO)<br>解决办法：<br>mysql -p    #登陆mysql<br>Enter password:<br>mysql&gt; set password for ‘root’@’localhost’ =password(‘’);<br>mysql&gt; flush privileges;<br>mysql&gt; exit;</p><p>2.提示Access denied for user ‘root’@’localhost’<br>解决办法：<br>mysql -p    #登陆mysql<br>Enter password:<br>mysql&gt; grant all privileges on <em>.</em> to ‘root’@’localhost’ identified by ‘123456’ with grant option;<br>mysql&gt; flush privileges;<br>mysql&gt; exit;</p><p>3.安全模式启动mysql<br>mysqld_safe –skip-grant-tables &amp;</p><p>4.启动服务提示密码错误<br>Access denied for user ‘root’@’localhost’ (using password: YES)<br>在mysql的配置文件/etc/mysql/debian.cnf中改动,配置password部分为自己设置的密码即可<br><img src="https://oscimg.oschina.net/oscnet/8aa4865e1e6092fa45c7c60b5d7173b99db.jpg" alt=""></p><h2 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h2><p>在deploy的Linux系统中安装jdk和mysql并不像平常在Linux系统中安装一样，因为平台架构不一样，存在许多坑，比如安卓的网络策略限制，必须usermod -aG aid_inet mysql等，不去踩坑就永远走不出坑，今天的实践就这些啦，后面会继续在Linux Deploy上搞事情。</p>]]></content>
    
    <summary type="html">
    
      LinuxDeploy上安装Jdk和MySQL
    
    </summary>
    
    
      <category term="玩机分享" scheme="https://www.maxbill.cn/kinds/%E7%8E%A9%E6%9C%BA%E5%88%86%E4%BA%AB/"/>
    
    
      <category term="MySQL" scheme="https://www.maxbill.cn/marks/MySQL/"/>
    
      <category term="Linux" scheme="https://www.maxbill.cn/marks/Linux/"/>
    
      <category term="LinuxDeploy" scheme="https://www.maxbill.cn/marks/LinuxDeploy/"/>
    
      <category term="Android" scheme="https://www.maxbill.cn/marks/Android/"/>
    
      <category term="OracleJdk" scheme="https://www.maxbill.cn/marks/OracleJdk/"/>
    
  </entry>
  
  <entry>
    <title>LinuxDeploy安装配置使用教程</title>
    <link href="https://www.maxbill.cn/2692598958.html"/>
    <id>https://www.maxbill.cn/2692598958.html</id>
    <published>2018-04-05T09:53:52.000Z</published>
    <updated>2020-07-07T13:12:43.560Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>作为一个程序猿和一个业余的玩机爱好者，自然喜欢折腾各种技术和设备，前几天无意间注意到一个可以在安卓机器上使用chroot容器技术运行arm或者x86的Linux系统（目前有些手机可能支持x64了），本文就来亲自体验下，还有后续会使用该技术搭建个人服务器、部署个人博客系统等</p><h2 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h2><p>该技术的验证是在安卓系统上进行的，因此大家先要有一台安卓手机或者安卓平板。该技术的原理就是在安卓机上搁置一个chroot容器，来运行linux系统，那为啥别的系统不行呢，因为安卓的系统内核也是Linux的。我自使用小米4（系统安卓6.0）先后试验了debian、Ubuntu、CentOS都是成功的，本文将以CentOS为例进行验证。</p><h2 id="二、准备工作"><a href="#二、准备工作" class="headerlink" title="二、准备工作"></a>二、准备工作</h2><p>1.一台安卓设备（手机过着平板）<br>设备硬件要求：建议RAM在1G及以上，手机ROM空闲容量4G左右<br>设备软件要求：建议安卓版本4.0以上，系统必须是拥有ROOT系统权限的</p><p>2.Busy Box安卓软件<br>软件简介：BusyBox 是一个集成了三百多个最常用Linux命令和工具的软件。BusyBox 包含了一些简单的工具，例如ls、cat和echo等等，还包含了一些更大、更复杂的工具，例grep、find、mount以及telnet。有些人将 BusyBox 称为 Linux 工具里的瑞士军刀。简单的说BusyBox就好像是个大工具箱，它集成压缩了 Linux 的许多工具和命令，也包含了 Android 系统的自带的shell。摘自：百度百科<br>在本实验中Busy Box作为Linux Deploy最主要的依赖软件软件地址：<a href="https://github.com/meefik/busybox/releases">https://github.com/meefik/busybox/releases</a>    （本文使用最新版）</p><p>3.Linux Deploy安卓软件<br>软件简介：安卓平台虚拟机（chroot运行linux的容器）<br>软件地址：<a href="https://github.com/meefik/linuxdeploy/releases">https://github.com/meefik/linuxdeploy/releases</a>  （本文使用最新版）</p><h2 id="三、安装工作"><a href="#三、安装工作" class="headerlink" title="三、安装工作"></a>三、安装工作</h2><p>注意：如果安卓设备没有拥有ROOT系统权限，得先ROOT设备（自行百度）</p><p>1.安装Busy Box<br>将下载的Busy Box软件安装在安卓设备上，然后打开设备点击右上角三个点然后点击Setting进行设置<br><img src="https://static.oschina.net/uploads/space/2018/0405/164020_xhgB_2846946.png" alt=""><br>这里可以设置肤色、字体大小、屏幕滚动行数等<br>注意：安装路径不要改动，后面要用的！（改了也行，不过的记住，后面找不到就尴尬了）<br><img src="https://static.oschina.net/uploads/space/2018/0405/164742_96Fw_2846946.png" alt=""><br>剩下的设置就按这样来就行，日志文件可以打开也可以关闭，建议关闭，调试模式也关闭。设置完成后返回到主界面，然后点击安装按钮，等待安装完成在界面中输出## END，然后点击右上角三个点然后点信息按钮可以看到输出的系统信息：<br><img src="https://static.oschina.net/uploads/space/2018/0405/165517_bEfX_2846946.png" alt=""></p><p>2.安装Linux Deploy<br>安装完成后打开Linux Deploy可以看到主界面如下：<br><img src="https://static.oschina.net/uploads/space/2018/0405/165810_0lzR_2846946.png" alt=""><br>然后我们点击左上角三个横杠然后点击设置：<br><img src="https://static.oschina.net/uploads/space/2018/0405/170008_Ri1c_2846946.png" alt=""><br>这里是一些显示相关的设置，前面三个中的锁定wifi一定要打钩、保持CPU唤醒也要打钩、屏幕常亮一定关闭避免耗电<br><img src="https://static.oschina.net/uploads/space/2018/0405/170240_A1ng_2846946.png" alt=""><br>下面这些看自己的需求设置、开机启动建议打开，防止手机某些问题重启后，容易没打开这样服务就断开了<br><img src="https://static.oschina.net/uploads/space/2018/0405/170434_R7aU_2846946.png" alt=""><br>这里最重要的就是PATH变量，就是前面说的不要改的，填进去就好了（改了就填写改了的路径）设置的部分就先到这，下面是最重要的部分，进行系统安装的设置工作：</p><p>&lt;1&gt;在主界面点击左上角的三个横杠然后点击点击配置文件、然后新建文件的名称，可以随意定义，本文是安装CentOS系统就用其命名了<br><img src="https://static.oschina.net/uploads/space/2018/0405/170939_azc1_2846946.png" alt=""></p><p>&lt;2&gt;点击手机右下角的设置图标，设置系统相关信息<br><img src="https://static.oschina.net/uploads/space/2018/0405/171108_l6zS_2846946.png" alt=""><br>这里的容器选择chroot（proot很不稳定）发行版本文选择CentOS，大家可以选择其他的发行版本安装架构这里一定要选对，不然安装会出错，或者安装完成后不能正常使用，这里一定要知道自己手机cpu的架构，我的小米4是晓龙801处理器，理论上是可以用x86的，但是我安装总是出错，所以选择向下兼容的armhfp，这架构大部分手机都是支持的；源地址默认或者可以切换成国内源，国内源安装的速度比较快，阿里的源地址是<a href="http://mirrors.aliyun.com/centos/">http://mirrors.aliyun.com/centos/</a> ，还有很多国内的比如网易等大家自己百度；安装类型选择镜像安装，安装地址可以默认，这里是改过的，/linux是指手机sdcard根目录的linux文件夹下的地址；<br><img src="https://static.oschina.net/uploads/space/2018/0405/172146_bsTw_2846946.png" alt=""><br>设置镜像大小2000mb往上（如果是用来做服务器，建议使用分区安装，这样可以使用整个手机所有的空间），文件系统建议选择ext4，其他的自定义信息大家自己填写，用户名和密码是待会进入系统需要的；DNS自动就好，或者改成114.114.114.114 或者8.8.8.8 或者1.1.1.1等都行；<br><img src="https://static.oschina.net/uploads/space/2018/0405/172424_EfK1_2846946.png" alt=""><br>这里的设置也很重要，一定要勾启用SSH，不然待会登陆不到系统，挂载点也勾选并设置，本文设置将sdcard整个挂载到Linux系统的/mnt/sdcard下，如下所示：<br><img src="https://static.oschina.net/uploads/space/2018/0405/173048_ghVz_2846946.png" alt=""><br>下面是一些桌面化的设置，本文是没有安装桌面的，因此没勾选某些项，大家需要桌面版可以自行勾选<br><img src="https://static.oschina.net/uploads/space/2018/0405/173225_enkQ_2846946.png" alt=""></p><p>&lt;3&gt;开始安装系统<br>设置完成返回主界面点击右上角三个点中的安装选项，开始系统的安装操作，然后等待安装，下面是系统安装的截图：<br><img src="https://static.oschina.net/uploads/space/2018/0405/173507_uB6p_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2018/0405/173521_s3rp_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2018/0405/173541_fNg4_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2018/0405/173556_CeBe_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2018/0405/173626_QUDW_2846946.png" alt=""><br>看到如下输出&lt;&lt;&lt;deploy 时说明安装完成<br><img src="https://static.oschina.net/uploads/space/2018/0405/173654_bzEb_2846946.png" alt=""></p><p>&lt;4&gt;启动linux系统<br>在启动系统之前先点击一次停止按钮：<br><img src="https://static.oschina.net/uploads/space/2018/0405/173850_bV9L_2846946.png" alt=""><br>看到如上停止信息时，再点击确定系统按钮：<br><img src="https://static.oschina.net/uploads/space/2018/0405/173946_p7FM_2846946.png" alt=""><br>看到如上启动信息，说明系统么启动成功</p><h2 id="四、安装配置验证"><a href="#四、安装配置验证" class="headerlink" title="四、安装配置验证"></a>四、安装配置验证</h2><p>在上面安装启动工作完成后，我们来验证安装是否成功，用电脑打开系统终端，开始连接测试：<br><img src="https://static.oschina.net/uploads/space/2018/0405/174325_eew7_2846946.png" alt=""><br>我们使用root用户登陆正常，和正常的Linux系统是一样的，不过因为是运行在chroot下，有些命令是不支持的，具体请百度chroot了解<br>注意：本文使用的是Linux系统，可以直接在终端使用SSH命令测试连接，大家的要是window可以使用xshell或者putty等软件连接测试，若果没有电脑可以使用手机安装程序员工具这个软件或者ConnectBox连接验证</p><h2 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h2><p>经过前面的实验，已经成功的在安卓设备上安装了Linux-CentOS发行版，而且是正常的连接使用，后面我们实验在改系统上架设tomcat等服务，并且使用花生壳或者花生棒硬件映射服务到公网作为个人云主机使用。</p>]]></content>
    
    <summary type="html">
    
      LinuxDeploy安装配置使用教程
    
    </summary>
    
    
      <category term="玩机分享" scheme="https://www.maxbill.cn/kinds/%E7%8E%A9%E6%9C%BA%E5%88%86%E4%BA%AB/"/>
    
    
      <category term="Linux" scheme="https://www.maxbill.cn/marks/Linux/"/>
    
      <category term="LinuxDeploy" scheme="https://www.maxbill.cn/marks/LinuxDeploy/"/>
    
      <category term="Android" scheme="https://www.maxbill.cn/marks/Android/"/>
    
  </entry>
  
  <entry>
    <title>Hue(05)Hue集成Mysql和Oracle关系数据库</title>
    <link href="https://www.maxbill.cn/2995392389.html"/>
    <id>https://www.maxbill.cn/2995392389.html</id>
    <published>2018-02-27T09:40:21.000Z</published>
    <updated>2020-07-14T15:37:03.430Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在前面文中在Hue中集成Hive数据仓库，替代了Hive自己的Hwi服务，可以很方便的在Hue中进行Hive的Sql查询等操作。本文将在Hue中集成Mysql和Oracle等数据库，这样就可以在Hue中对数据存储服务中的数据进行操作。</p><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>1.Hadoop集群服务<br>2.Hive-Mysql元数据库服务<br>3.Hive服务<br>4.Hue4.1服务<br>5.Mysql数据库服务<br>6.Oracle数据库服务</p><h2 id="集成准备"><a href="#集成准备" class="headerlink" title="集成准备"></a>集成准备</h2><h3 id="启动Hadoop集群"><a href="#启动Hadoop集群" class="headerlink" title="启动Hadoop集群"></a>启动Hadoop集群</h3><p>启动Hadoop三台机器，然后在主节点机器上启动Hadoop集群：start-all.sh<br><img src="https://static.oschina.net/uploads/space/2018/0104/103616_9Chc_2846946.png" alt=""></p><h3 id="启动Hiveserver服务"><a href="#启动Hiveserver服务" class="headerlink" title="启动Hiveserver服务"></a>启动Hiveserver服务</h3><p>在Hive机器上启动Hiveserver服务：hive –service hiveserver2 或者hive –service hiveserver2 &amp;</p><h3 id="启动HiveMetastore服务"><a href="#启动HiveMetastore服务" class="headerlink" title="启动HiveMetastore服务"></a>启动HiveMetastore服务</h3><p>在Hive机器上启动HiveMetastore服务：hive –service metastore或者hive –service metastore &amp;<br><img src="https://static.oschina.net/uploads/space/2018/0109/132512_UL4f_2846946.png" alt=""><br>看到如下信息，说明启动完成：<br><img src="https://static.oschina.net/uploads/space/2018/0109/132641_wcjJ_2846946.png" alt=""></p><h3 id="启动Hue服务"><a href="#启动Hue服务" class="headerlink" title="启动Hue服务"></a>启动Hue服务</h3><p>在Hue的/bulid/env/bin/目录下执行./supervisor 命令启动Hue服务<br><img src="https://static.oschina.net/uploads/space/2018/0126/102534_RXdP_2846946.png" alt=""></p><h3 id="启动数据存储服务"><a href="#启动数据存储服务" class="headerlink" title="启动数据存储服务"></a>启动数据存储服务</h3><p>分别启动需要Hue集成的Mysql和Oracle数据库服务</p><h3 id="验证启动"><a href="#验证启动" class="headerlink" title="验证启动"></a>验证启动</h3><p>在终端输入jps -ml查看：<br><img src="https://static.oschina.net/uploads/space/2018/0109/133546_Ta0S_2846946.png" alt=""><br>可以看到Hadoop集群各Hive服务启动都正常</p><h2 id="集成MySQL服务"><a href="#集成MySQL服务" class="headerlink" title="集成MySQL服务"></a>集成MySQL服务</h2><h3 id="配置过程"><a href="#配置过程" class="headerlink" title="配置过程"></a>配置过程</h3><p>打开Hue的/desktop/conf/目录下的 pseudo-distributed.ini文件<br><img src="https://static.oschina.net/uploads/space/2018/0126/093635_FEQY_2846946.png" alt=""><br>编辑pseudo-distributed.ini文件 ，找到[librdbms]这一节下的[[databases]]，然后添加关于集成Mysql<br>服务的配置信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[[[mysql]]]  </span><br><span class="line">nice_name=db_mysql  </span><br><span class="line">engine=mysql  </span><br><span class="line">host=hdpc05  </span><br><span class="line">port=3306  </span><br><span class="line">user=root  </span><br><span class="line">password=123456</span><br></pre></td></tr></table></figure><p><img src="https://static.oschina.net/uploads/space/2018/0226/162531_UX5L_2846946.png" alt=""></p><h3 id="验证过程"><a href="#验证过程" class="headerlink" title="验证过程"></a>验证过程</h3><p>如果之前Hue服务是启动的，先重启Hue服务，然后登陆Hue服务控制台页面：<br><img src="https://static.oschina.net/uploads/space/2018/0226/163217_bEyV_2846946.png" alt=""><br>点击Mysql标签，可以看到成功集成了Mysql数据库服务<br><img src="https://static.oschina.net/uploads/space/2018/0226/163415_VjEI_2846946.png" alt=""></p><h3 id="简单使用"><a href="#简单使用" class="headerlink" title="简单使用"></a>简单使用</h3><p>双击某个数据库可以看到库中的表或者右击选择Open in Browser在右边的Table Browser视图中，可以看到该数据库下的表：<br><img src="https://static.oschina.net/uploads/space/2018/0226/163933_Etah_2846946.png" alt=""><br>或<br><img src="https://static.oschina.net/uploads/space/2018/0226/165621_Smsa_2846946.png" alt=""><br>在Table Browser视图中选择表点击view可以查看表结构信息和表数据信息：<br><img src="https://static.oschina.net/uploads/space/2018/0226/165802_caqN_2846946.png" alt=""><br>可以看到表结构和部分表数据，更多的操作点击其他操作标签即可，这里不过多演示<br><img src="https://static.oschina.net/uploads/space/2018/0226/165955_0dHC_2846946.png" alt=""></p><h2 id="集成Oracle服务"><a href="#集成Oracle服务" class="headerlink" title="集成Oracle服务"></a>集成Oracle服务</h2><h3 id="配置过程-1"><a href="#配置过程-1" class="headerlink" title="配置过程"></a>配置过程</h3><p>打开Hue的/desktop/conf/目录下的 pseudo-distributed.ini文件<br><img src="https://static.oschina.net/uploads/space/2018/0126/093635_FEQY_2846946.png" alt=""><br>编辑pseudo-distributed.ini文件 ，找到[librdbms]这一节下的[[databases]]，然后添加关于集成oracle服务的配置信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[[[oracle]]]  </span><br><span class="line">nice_name=db_oracle  </span><br><span class="line">engine=oracle  </span><br><span class="line">host=192.168.1.102  </span><br><span class="line">port=1521  </span><br><span class="line">user=***  </span><br><span class="line">password=***</span><br></pre></td></tr></table></figure><p>配置完成后，重启Hue服务，我们登陆Hue控制状态点击Oracle存储查看，控制台提示如下错误：<br>Error loading cx_Oracle module: No module named cx_Oracle<br><img src="https://static.oschina.net/uploads/space/2018/0227/164146_8Lnm_2846946.png" alt=""><br>这是因为Hue是Python写的，所以使用Python连接Oracle时需要cx_Oracle这个模块，安装这个还需要配置Oracle官方的两个客户端文件，下面我们开始配置过程：<br>1&gt;.下载oracle连接需要的两个客户端文件<br>instantclient-basic-linux.x64-12.2.0.1.0.zip<br>instantclient-sdk-linux.x64-12.1.0.2.0.zip<br>下载地址：<a href="http://www.oracle.com/technetwork/topics/linuxx86-64soft-092277.html">http://www.oracle.com/technetwork/topics/linuxx86-64soft-092277.html</a><br>2&gt;.使用ftp上传到hue的oracle目录下<br><img src="https://static.oschina.net/uploads/space/2018/0227/165227_3ud0_2846946.png" alt=""><br>上传的文件如下：<br><img src="https://static.oschina.net/uploads/space/2018/0227/165346_qoIe_2846946.png" alt=""><br>解压两个文件都到instantclient12.2中：<br><img src="https://static.oschina.net/uploads/space/2018/0227/165603_cssX_2846946.png" alt=""><br>全部解压后文件如下：<br><img src="https://static.oschina.net/uploads/space/2018/0227/165935_H9YI_2846946.png" alt=""><br>3&gt;.添加环境变量<br>使用命令vi  /etc/profile 写入以下配置：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#Oracle client Profile  </span><br><span class="line">export ORACLE_HOME=/home/hue-branch-4.1/oracle/instantclient12.2/  </span><br><span class="line">export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$ORACLE_HOME</span><br></pre></td></tr></table></figure><p><img src="https://static.oschina.net/uploads/space/2018/0227/170250_jCIN_2846946.png" alt=""><br>使用source /etc/profile使配置立即生效：<br><img src="https://static.oschina.net/uploads/space/2018/0227/170623_xAPu_2846946.png" alt=""><br>4&gt;.创建软连接</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ln -s libclntsh.dylib.11.1 libclntsh.dylib</span><br><span class="line">ln -s libocci.dylib.11.1 libocci.dylib</span><br><span class="line">ln -s libclntsh.so.11.1 libclntsh.so</span><br><span class="line">![](https://static.oschina.net/uploads/space/2018/0227/170747_zplk_2846946.png)</span><br></pre></td></tr></table></figure><p>5&gt;.安装cx_Oracle某块<br>使用find / -name pip查找pip目录<br><img src="https://static.oschina.net/uploads/space/2018/0226/170937_ndLR_2846946.png" alt=""><br>cd /home/hue-branch-4.1/build/env/bin<br><img src="https://static.oschina.net/uploads/space/2018/0226/171232_dNIU_2846946.png" alt=""><br>然后执行./pip install cx_Oracle安装<br><img src="https://static.oschina.net/uploads/space/2018/0227/171146_wrNZ_2846946.png" alt=""><br>至此cx_Oracle某块就安装完成了</p><h3 id="验证过程-1"><a href="#验证过程-1" class="headerlink" title="验证过程"></a>验证过程</h3><p>配置完成后我们登陆hue控制台点击oracle标签，控制台提示‘name’的错误：<br><img src="https://static.oschina.net/uploads/space/2018/0227/171732_1yi9_2846946.png" alt=""><br>这是因为配置Oracle时少一个name的参数：<br><img src="https://static.oschina.net/uploads/space/2018/0227/173341_mQrK_2846946.png" alt=""><br>配置完成后我们重启Hue服务查看Hue控制台：<br><img src="https://static.oschina.net/uploads/space/2018/0227/173624_E1qt_2846946.png" alt=""><br>此时就完成了Hue对Oracle的集成配置，具体的使用和Mysql差不多，同上面内容</p><h2 id="最后总结"><a href="#最后总结" class="headerlink" title="最后总结"></a>最后总结</h2><p>本文是在Hue中集成Mysql和Oracle关系数据库服务，Mysql的集成相对简单，Oracle的集成复杂一点，需要注意的地方比较多，集成过程中遇到的坑都记录在文中了，希望能帮到大家。</p>]]></content>
    
    <summary type="html">
    
      Hue(05)Hue集成Mysql和Oracle关系数据库
    
    </summary>
    
    
      <category term="学大数据" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://www.maxbill.cn/marks/Hadoop/"/>
    
      <category term="大数据" scheme="https://www.maxbill.cn/marks/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Hue" scheme="https://www.maxbill.cn/marks/Hue/"/>
    
      <category term="MySQL" scheme="https://www.maxbill.cn/marks/MySQL/"/>
    
      <category term="Oracle" scheme="https://www.maxbill.cn/marks/Oracle/"/>
    
  </entry>
  
  <entry>
    <title>Hive(06)数据仓库Hive用户图形接口HWI的配置</title>
    <link href="https://www.maxbill.cn/1081867870.html"/>
    <id>https://www.maxbill.cn/1081867870.html</id>
    <published>2018-02-27T07:16:17.000Z</published>
    <updated>2020-07-25T14:16:48.645Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在之前的文中我们配置了一个Hive监控的Web界面的服务，主要用于查看当前HiveServer2服务链接的会话、服务日志、配置参数等信息，这个服务更像是一个Hive提供的监控服务,本文我们将配置HWI( Hive Web Interface)hive用户图形接口,这是Hive三种用户接口中的其中之一,可以在Web界面上对Hive服务进行操作</p><h3 id="一、环境准备"><a href="#一、环境准备" class="headerlink" title="一、环境准备"></a>一、环境准备</h3><p>1.Hadoop集群</p><p>2.Hive完整的服务（2.3.2）</p><p>3.Hive元数据存储服务(Mysql)</p><p>4.Hive源码包</p><h3 id="二、配置准备"><a href="#二、配置准备" class="headerlink" title="二、配置准备"></a>二、配置准备</h3><p>hwi服务配置的前提需要我们手动打hwi服务的war包,然后将war包部署在Hive服务下,配置完成就可使用了,首先我们要下载Hive源码包,下载地址:<a href="http://mirror.bit.edu.cn/apache/hive/">http://mirror.bit.edu.cn/apache/hive/</a><br><img src="https://static.oschina.net/uploads/space/2018/0119/102744_kYWD_2846946.png" alt=""><br>下载<a href="http://mirror.bit.edu.cn/apache/hive/hive-2.3.2/apache-hive-2.3.2-src.tar.gz">apache-hive-2.3.2-src.tar.gz</a>包到本地,我们解压源码包,在包中没有发现hwi服务的代码目录,于是使用2.2.0版本打war包:<br>jar -cvf hive-hwi.war  ./*<br><img src="https://static.oschina.net/uploads/space/2018/0119/113146_KQdc_2846946.png" alt=""><br>上传打的war包到lib下<br><img src="https://static.oschina.net/uploads/space/2018/0119/113502_rDG9_2846946.png" alt=""><br>修改hive-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--配置HWI接口--&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>    </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.hwi.war.file<span class="tag">&lt;/<span class="name">name</span>&gt;</span>    </span><br><span class="line">          <span class="tag">&lt;<span class="name">value</span>&gt;</span>lib/hive-hwi.war<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>    </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.hwi.listen.host<span class="tag">&lt;/<span class="name">name</span>&gt;</span>    </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdpc01<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>    </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.hwi.listen.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span>    </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>9999<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>启动Hadoop集群后,输入hive –service hwi启动hwi服务,提示:service hwi not found通过查询资料,我们发现2.3.2次版本已经不支持hwi服务了<br><img src="https://static.oschina.net/uploads/space/2018/0119/135134_cWZz_2846946.png" alt=""><br>注意:2.2.0及以前的版本HWI服务可以按以上办法配置,2.3.2已经取消此服务</p><h3 id="三、文末总结"><a href="#三、文末总结" class="headerlink" title="三、文末总结"></a>三、文末总结</h3><p>由于Hive在2.2.0以前的版本，官方网站是提供了hive-hwi服务的web源码包源码的，后面的版本是不提供了，而且hwi的服务也取消了，个人觉的现在公司使用Hue集成Hive使用的比较多，而且功能更加强大，因此官方取消了hwi服务。本文也是在实践配置hwi服务的时候发现的，所有在后面还有使用Hue集成Hive的文章，文中要是出现不对的地方，请大家评论或者私信指出。</p>]]></content>
    
    <summary type="html">
    
      Hive(06)数据仓库Hive用户图形接口HWI的配置
    
    </summary>
    
    
      <category term="学大数据" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://www.maxbill.cn/marks/Hadoop/"/>
    
      <category term="大数据" scheme="https://www.maxbill.cn/marks/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Hive" scheme="https://www.maxbill.cn/marks/Hive/"/>
    
      <category term="数据仓库" scheme="https://www.maxbill.cn/marks/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>Hue(04)Hue集成Hive数据仓库</title>
    <link href="https://www.maxbill.cn/2709460995.html"/>
    <id>https://www.maxbill.cn/2709460995.html</id>
    <published>2018-01-26T07:11:34.000Z</published>
    <updated>2020-07-07T12:58:48.135Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在前面文中我们在Hue中集成了Hdfs和Yarn，可以很方便的在Hue中操作Hdfs中的数据和查看MapReduce的作业执行情况。本文我们将在Hue中集成Hive数据仓库，用替代Hive自己的Hwi服务，可以很方便的在Hue中进行Hive的Sql查询等操作。</p><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>1.Hadoop集群服务<br>2.Hive-Mysql元数据库服务<br>3.Hive服务<br>4.Hue4.1服务</p><h2 id="集成配置"><a href="#集成配置" class="headerlink" title="集成配置"></a>集成配置</h2><p>打开Hue的/desktop/conf/目录下的pseudo-distributed.ini文件<br><img src="https://static.oschina.net/uploads/space/2018/0126/093635_FEQY_2846946.png" alt=""><br>编辑pseudo-distributed.ini文件 ，找到[beeswax]这一节，修改信息连接为hdpc01的机器上的Hive数据仓库服务，修改信息如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hive_server_host=hdpc01</span><br><span class="line">hive_server_port=10000</span><br><span class="line">server_conn_timeout=120</span><br><span class="line">list_partitions_limit=10000</span><br><span class="line">query_partitions_limit=10</span><br><span class="line">download_row_limit=100000</span><br><span class="line">max_number_of_sessions=10</span><br></pre></td></tr></table></figure><h2 id="集成准备"><a href="#集成准备" class="headerlink" title="集成准备"></a>集成准备</h2><h3 id="启动Hadoop集群"><a href="#启动Hadoop集群" class="headerlink" title="启动Hadoop集群"></a>启动Hadoop集群</h3><p>启动Hadoop三台机器，然后在主节点机器上启动Hadoop集群：start-all.sh<br><img src="https://static.oschina.net/uploads/space/2018/0104/103616_9Chc_2846946.png" alt=""></p><h3 id="启动Hiveserver服务"><a href="#启动Hiveserver服务" class="headerlink" title="启动Hiveserver服务"></a>启动Hiveserver服务</h3><p>在Hive机器上启动Hiveserver服务：hive –service hiveserver2 或者hive –service hiveserver2 &amp;</p><h3 id="启动HiveMetastore服务"><a href="#启动HiveMetastore服务" class="headerlink" title="启动HiveMetastore服务"></a>启动HiveMetastore服务</h3><p>在Hive机器上启动HiveMetastore服务：hive –service metastore或者hive –service metastore &amp;<br><img src="https://static.oschina.net/uploads/space/2018/0109/132512_UL4f_2846946.png" alt=""><br>看到如下信息，说明启动完成：<br><img src="https://static.oschina.net/uploads/space/2018/0109/132641_wcjJ_2846946.png" alt=""></p><h3 id="启动Hue服务"><a href="#启动Hue服务" class="headerlink" title="启动Hue服务"></a>启动Hue服务</h3><p>在Hue的/bulid/env/bin/目录下执行./supervisor 命令启动hue服务<br><img src="https://static.oschina.net/uploads/space/2018/0126/102534_RXdP_2846946.png" alt=""></p><h3 id="验证启动"><a href="#验证启动" class="headerlink" title="验证启动"></a>验证启动</h3><p>在终端输入jps -ml查看：<br><img src="https://static.oschina.net/uploads/space/2018/0109/133546_Ta0S_2846946.png" alt=""><br>可以看到Hadoop集群各Hive服务启动都正常</p><h2 id="集成验证及简单使用"><a href="#集成验证及简单使用" class="headerlink" title="集成验证及简单使用"></a>集成验证及简单使用</h2><p>登陆Hue服务，点击Hive可以看到Hive的默认default的库，和我们之前使用Hive时建的表<br><img src="https://static.oschina.net/uploads/space/2018/0126/143843_pRcy_2846946.png" alt=""><br>查看Hive表的详细信息，右击表点击Open in Browser在右边的Table Browser视图中，可以看到表的结构及字段自定义、部分数据等<br><img src="https://static.oschina.net/uploads/space/2018/0126/144012_uhST_2846946.png" alt=""><br>点击columns标签可以看到表字段的详细信息<br><img src="https://static.oschina.net/uploads/space/2018/0126/144524_MbIl_2846946.png" alt=""><br>点击sample标签可以看到该表全部的数据信息<br><img src="https://static.oschina.net/uploads/space/2018/0126/145440_EgCz_2846946.png" alt=""><br>使用Hue中的Hive查询器查询Hive表中的数据<br><img src="https://static.oschina.net/uploads/space/2018/0126/150051_LSiT_2846946.png" alt=""><br>在Hue中还有更多可以操作Hive的方式，大家可以自己尝试别的，本文先这么多基本的操作</p><h2 id="问题总结"><a href="#问题总结" class="headerlink" title="问题总结"></a>问题总结</h2><h3 id="Hue提示不能启动SASL异常"><a href="#Hue提示不能启动SASL异常" class="headerlink" title="Hue提示不能启动SASL异常"></a>Hue提示不能启动SASL异常</h3><p>问题描述：Hue提示Could not start SASL: Error in sasl_client_start (-4) SASL(-4)的异常<br><img src="https://static.oschina.net/uploads/space/2018/0126/140418_8J0o_2846946.png" alt=""><br>问题原因：因为系统缺少了相关的依赖<br>解决办法：我们在hue所在主机安装以下的依赖<br>yum install cyrus-sasl-plain cyrus-sasl-devel cyrus-sasl-gssapi<br><img src="https://static.oschina.net/uploads/space/2018/0126/142004_ED3R_2846946.png" alt=""></p><h3 id="最后总结"><a href="#最后总结" class="headerlink" title="最后总结"></a>最后总结</h3><p>本文使用Hue连接操作Hive数据仓库比较之前Hive自己的Hwi功能更强大，同时Hue支持更多的应用，集成在一起更像是一个操作、监控为一体的平台化的工具，在后面的文章我们还继续去使用Hue集成HBase、Mysql、Oracle等</p>]]></content>
    
    <summary type="html">
    
      Hue(04)Hue集成Hive数据仓库
    
    </summary>
    
    
      <category term="学大数据" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://www.maxbill.cn/marks/Hadoop/"/>
    
      <category term="大数据" scheme="https://www.maxbill.cn/marks/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Hive" scheme="https://www.maxbill.cn/marks/Hive/"/>
    
      <category term="Hue" scheme="https://www.maxbill.cn/marks/Hue/"/>
    
  </entry>
  
  <entry>
    <title>Hue(03)Hue切换MySql作为元数据库</title>
    <link href="https://www.maxbill.cn/1553974222.html"/>
    <id>https://www.maxbill.cn/1553974222.html</id>
    <published>2018-01-26T02:53:09.000Z</published>
    <updated>2020-07-14T15:37:03.430Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Hue服务默认使用的是内嵌的Sqlite数据库作为自己的源数据库，Sqlite数据库毕竟是属于一款轻型的数据库服务，在实际项目中还是建议切换MySql或者Oracle作为元数据库服务，本文将切换MySql作为Hue的元数据库。</p><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>1.MySql服务<br>2.Hue4.1服务</p><h2 id="配置工作"><a href="#配置工作" class="headerlink" title="配置工作"></a>配置工作</h2><p> 打开Hue的/desktop/conf/目录下的 pseudo-distributed.ini文件<br><img src="https://static.oschina.net/uploads/space/2018/0126/093635_FEQY_2846946.png" alt=""><br>编辑pseudo-distributed.ini文件 ，找到[[database]]这一节，修改信息为hdpc05的机器上的MySql元数<br>据库服务，修改信息如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">engine=mysql              //数据引擎类型</span><br><span class="line">host=hdpc05                //数据服务主机</span><br><span class="line">port=3306                    //端口号          </span><br><span class="line">user=root                     //用户名</span><br><span class="line">password=123456       //密码</span><br><span class="line">name=hue                   //数据库名称</span><br></pre></td></tr></table></figure><p><img src="https://static.oschina.net/uploads/space/2018/0126/094611_2tZ8_2846946.png" alt=""></p><h2 id="环境初始化"><a href="#环境初始化" class="headerlink" title="环境初始化"></a>环境初始化</h2><p>由于之前的信息都存在默认的Sqlite数据服务中，我们切换为Mysql服务，需要进行初始化的工作</p><h3 id="在MySql中新建Hue的数据库"><a href="#在MySql中新建Hue的数据库" class="headerlink" title="在MySql中新建Hue的数据库"></a>在MySql中新建Hue的数据库</h3><p><img src="https://static.oschina.net/uploads/space/2018/0126/100152_oaJU_2846946.png" alt=""></p><h3 id="初始化Hue数据库"><a href="#初始化Hue数据库" class="headerlink" title="初始化Hue数据库"></a>初始化Hue数据库</h3><p>在Hue服务所在主机，在Hue的/bulid/env/bin下执行以下初始化命令：<br>./hue syncdb<br><img src="https://static.oschina.net/uploads/space/2018/0126/101147_KR0O_2846946.png" alt=""><br>./hue migrate<br><img src="https://static.oschina.net/uploads/space/2018/0126/101531_fk9o_2846946.png" alt=""></p><h2 id="切换验证"><a href="#切换验证" class="headerlink" title="切换验证"></a>切换验证</h2><p>经过上面的配置和和初始化服务，此时Hue切换MySql作为元数据库已经完成，下面我们启动Hue服务验证我们的操作：<br>首先在Hue的/bulid/env/bin/目录下执行./supervisor 命令启动Hue服务<br><img src="https://static.oschina.net/uploads/space/2018/0126/102534_RXdP_2846946.png" alt=""><br>然后使用初始时设置的用户登陆Hue服务<br><img src="https://static.oschina.net/uploads/space/2018/0126/103934_l7O9_2846946.png" alt=""><br>最后启动Hadoop集群，看看切换后连接Hdfs等是否正常<br><img src="https://static.oschina.net/uploads/space/2018/0126/104118_6M4z_2846946.png" alt=""><br>连接Hadoop集群也正常<br><img src="https://static.oschina.net/uploads/space/2018/0126/104451_qFLm_2846946.png" alt=""></p><h2 id="问题总结"><a href="#问题总结" class="headerlink" title="问题总结"></a>问题总结</h2><h3 id="Hue提示表不存在的异常"><a href="#Hue提示表不存在的异常" class="headerlink" title="Hue提示表不存在的异常"></a>Hue提示表不存在的异常</h3><p>问题描述：Hue提示(1146, “Table ‘hue.django_session’ doesn’t exist”)的异常<br><img src="https://static.oschina.net/uploads/space/2018/0126/100625_gJQv_2846946.png" alt=""><br>问题原因：切换完Mysql数据库没有初始化数据库<br>解决方法：初始化数据库服务，见上面的初始化步骤</p><h3 id="切换后登陆提示账户名或者密码错误"><a href="#切换后登陆提示账户名或者密码错误" class="headerlink" title="切换后登陆提示账户名或者密码错误"></a>切换后登陆提示账户名或者密码错误</h3><p>问题描述：切换完成数据库后，使用原来的用户名账户登录不成功，提示账户名或者密码错误<br><img src="https://static.oschina.net/uploads/space/2018/0126/102759_5H47_2846946.png" alt=""><br>问题原因：因为我们切换了默认数据库，之前的用户信息保存在Sqllite中，所以此时使用原来的账户登陆不上去<br>解决办法：还记的我们在初始化的时候，控制台要求我们 输入的账户的密码么，那就是我们新的Hue服务的超级管理员密码<br><img src="https://static.oschina.net/uploads/space/2018/0126/111401_aOpr_2846946.png" alt=""></p><h2 id="最后总结"><a href="#最后总结" class="headerlink" title="最后总结"></a>最后总结</h2><p>本文主要是切换Hue服务的默认数据服务，将Sqllite服务切换成了Mysql服务，在我们平时使用中没有什么大问题，在线上项目中建议不要使用默认的Sqllie，因为Sqllie服务真的台轻量了，如果文中有错误，欢迎大家指出。</p>]]></content>
    
    <summary type="html">
    
      Hue(03)Hue切换MySql作为元数据库
    
    </summary>
    
    
      <category term="学大数据" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://www.maxbill.cn/marks/Hadoop/"/>
    
      <category term="大数据" scheme="https://www.maxbill.cn/marks/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Hue" scheme="https://www.maxbill.cn/marks/Hue/"/>
    
      <category term="MySQL" scheme="https://www.maxbill.cn/marks/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>Hue(02)Hue集成Hadoop集群环境</title>
    <link href="https://www.maxbill.cn/2086492639.html"/>
    <id>https://www.maxbill.cn/2086492639.html</id>
    <published>2018-01-25T06:08:23.000Z</published>
    <updated>2020-07-07T12:58:48.135Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在上文中完整的进行了Hue的源码下载编译安装,Hue的web控制台与Hdfs、Hive、Hbase等集成才能展现它的魅力，本文我们在Hue中集成Hadoop的Hdfs和Yarn服务，然后使用Hue操作和监控Hadoop集群。</p><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>1.Hadoop2.8.2集群<br>2.Hue4.1服务</p><h2 id="集成配置"><a href="#集成配置" class="headerlink" title="集成配置"></a>集成配置</h2><p>注意：以下1-4步骤同样需要在其他的Hadoop集群的节点上操作</p><h3 id="修改hdfs-site-xml配置"><a href="#修改hdfs-site-xml配置" class="headerlink" title="修改hdfs-site.xml配置"></a>修改hdfs-site.xml配置</h3><p>修改Hadoop的/etc/hadoop/目录下的hdfs-site.xml文件，在文件中加入以下配置：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.webhdfs.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p><img src="https://static.oschina.net/uploads/space/2018/0125/123910_H33p_2846946.png" alt=""></p><h3 id="修改core-site-xml配置"><a href="#修改core-site-xml配置" class="headerlink" title="修改core-site.xml配置"></a>修改core-site.xml配置</h3><p>修改Hadoop的/etc/hadoop/目录下的core-site.xml文件，在文件中加入以下配置 ：            </p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.hue.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.hue.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p><img src="https://static.oschina.net/uploads/space/2018/0125/124345_jJs4_2846946.png" alt=""> </p><h3 id="修改httpfs-site-xml配置"><a href="#修改httpfs-site-xml配置" class="headerlink" title="修改httpfs-site.xml配置"></a>修改httpfs-site.xml配置</h3><p>修改Hadoop的/etc/hadoop/目录下的httpfs-site.xml文件，在文件中加入以下配置 ： </p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>httpfs.proxyuser.hue.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>httpfs.proxyuser.hue.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p><img src="https://static.oschina.net/uploads/space/2018/0125/124705_fdZD_2846946.png" alt=""></p><h3 id="修改yarn-site-xml配置"><a href="#修改yarn-site-xml配置" class="headerlink" title="修改yarn-site.xml配置"></a>修改yarn-site.xml配置</h3><p>修改Hadoop的/etc/hadoop/目录下的yarn-site.xml文件，在文件中加入以下配置 ：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>432000<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p><img src="https://static.oschina.net/uploads/space/2018/0125/125128_JNH8_2846946.png" alt=""></p><h3 id="修改pseudo-distributed-ini配置"><a href="#修改pseudo-distributed-ini配置" class="headerlink" title="修改pseudo-distributed.ini配置"></a>修改pseudo-distributed.ini配置</h3><p>修改Hue的/desktop/conf/目录下的pseudo-distributed.ini文件集成hdfs，对Hadoop集群的hdfs配置如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fs_defaultfs=hdfs://hdpc01:9000</span><br><span class="line">webhdfs_url=http://hdpc01:50070/webhdfs/v1</span><br><span class="line">hadoop_conf_dir=/home/hadoop/hadoop-2.8.2/etc/hadoop</span><br></pre></td></tr></table></figure><p><img src="https://static.oschina.net/uploads/space/2018/0125/125604_2EcC_2846946.png" alt=""><br>修改Hue的/desktop/conf/目录下的pseudo-distributed.ini文件集成yarn，对Hadoop集群的yarn配置如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">resourcemanager_host=hdpc01</span><br><span class="line">resourcemanager_port=8032</span><br><span class="line">submit_to=True</span><br><span class="line">resourcemanager_api_url=http://hdpc01:8088</span><br><span class="line">proxy_api_url=http://hdpc01:8088</span><br><span class="line">history_server_api_url=http://hdpc01:19888  </span><br></pre></td></tr></table></figure><p><img src="https://static.oschina.net/uploads/space/2018/0125/130236_B7Vs_2846946.png" alt=""></p><h2 id="集成准备"><a href="#集成准备" class="headerlink" title="集成准备"></a>集成准备</h2><h3 id="启动Hadoop集群"><a href="#启动Hadoop集群" class="headerlink" title="启动Hadoop集群"></a>启动Hadoop集群</h3><p>在主节点上启动Hadoop集群start-all.sh<br><img src="https://static.oschina.net/uploads/space/2018/0104/103616_9Chc_2846946.png" alt=""></p><h3 id="启动Hue服务"><a href="#启动Hue服务" class="headerlink" title="启动Hue服务"></a>启动Hue服务</h3><p>在Hue的/bulid/env/bin/目录下 ./supervisor 启动hue服务<br><img src="https://static.oschina.net/uploads/space/2018/0125/131122_zPhq_2846946.png" alt=""></p><h3 id="服务启动验证"><a href="#服务启动验证" class="headerlink" title="服务启动验证"></a>服务启动验证</h3><p>验证Hadoop集群启动<br><img src="https://static.oschina.net/uploads/space/2018/0125/133655_zQ3e_2846946.png" alt=""><br>验证Hue服务启动<br><img src="https://static.oschina.net/uploads/space/2018/0125/131739_R5Hh_2846946.png" alt=""></p><h2 id="集成使用"><a href="#集成使用" class="headerlink" title="集成使用"></a>集成使用</h2><h3 id="使用Hue查看Hdfs文件"><a href="#使用Hue查看Hdfs文件" class="headerlink" title="使用Hue查看Hdfs文件"></a>使用Hue查看Hdfs文件</h3><p>点击Hdfs图标，可以Open in Browser查看详细的文件列表信息，如下图：<br><img src="https://static.oschina.net/uploads/space/2018/0125/132326_U6IK_2846946.png" alt=""></p><h3 id="查看单个文件详细的信息"><a href="#查看单个文件详细的信息" class="headerlink" title="查看单个文件详细的信息"></a>查看单个文件详细的信息</h3><p>在文件列表中点击文件可以查看这个文件详细的信息，如下图：<br><img src="https://static.oschina.net/uploads/space/2018/0125/132637_xgIh_2846946.png" alt=""></p><h3 id="使用Hue上传文件到Hdfs中"><a href="#使用Hue上传文件到Hdfs中" class="headerlink" title="使用Hue上传文件到Hdfs中"></a>使用Hue上传文件到Hdfs中</h3><p>这里上传back.txt文件到Hdfs目录下，如下步骤：<br>首先，切换到Hdfs目录下，点击upload上传文件按钮<br><img src="https://static.oschina.net/uploads/space/2018/0125/133113_bAwN_2846946.png" alt=""><br>然后，选择上传的back.txt文件到hdfs中即可看到<br><img src="https://static.oschina.net/uploads/space/2018/0125/133402_hdKh_2846946.png" alt=""></p><h3 id="使用Hue删除Hdfs的文件"><a href="#使用Hue删除Hdfs的文件" class="headerlink" title="使用Hue删除Hdfs的文件"></a>使用Hue删除Hdfs的文件</h3><p>要删除刚刚上传到Hdfs目录下的back.txt文件，先选中文件然后点击Delete forever按钮即可删除<br><img src="https://static.oschina.net/uploads/space/2018/0125/133838_uDps_2846946.png" alt=""></p><h3 id="Hue中对hdfs文件的更多操作"><a href="#Hue中对hdfs文件的更多操作" class="headerlink" title="Hue中对hdfs文件的更多操作"></a>Hue中对hdfs文件的更多操作</h3><p>选中文件点击Actions，可以看到下拉框中对文件的更多其他操作项，有下载、拷贝、移动、重命名、修改权限等等<br><img src="https://static.oschina.net/uploads/space/2018/0125/134158_9EbC_2846946.png" alt=""></p><h3 id="Hue中查看MapReduce执行的Job"><a href="#Hue中查看MapReduce执行的Job" class="headerlink" title="Hue中查看MapReduce执行的Job"></a>Hue中查看MapReduce执行的Job</h3><p>点击Jobs打开作业浏览面板，在这里可以看到执行中、执行完成、执行失败的作业信息，如下：<br><img src="https://static.oschina.net/uploads/space/2018/0125/143141_razN_2846946.png" alt=""></p><h2 id="问题总结"><a href="#问题总结" class="headerlink" title="问题总结"></a>问题总结</h2><h3 id="关于hue集成hdfs的问题"><a href="#关于hue集成hdfs的问题" class="headerlink" title="关于hue集成hdfs的问题"></a>关于hue集成hdfs的问题</h3><p>在Hue集成完成Hadoop后，使用Hue查看Hdfs的时候，Hue的控制面板总是提示如下错误：<br><img src="https://static.oschina.net/uploads/space/2018/0125/142941_7oab_2846946.png" alt=""><br>解决办法：在Hue中创建用户Hdfs，并且设置未超级用户即可解决<br><img src="https://static.oschina.net/uploads/space/2018/0125/143429_B8Wz_2846946.png" alt=""></p><h3 id="提示连接10000端口服务异常"><a href="#提示连接10000端口服务异常" class="headerlink" title="提示连接10000端口服务异常"></a>提示连接10000端口服务异常</h3><p>登录进入hue后提示连接10000端口服务异常<br><img src="https://static.oschina.net/uploads/space/2018/0125/143537_SHdX_2846946.png" alt=""><br>解决办法：该问题是我们没有连接hive服务提示的异常，解决办法就是集成hive即可，详细见下篇博文</p><h3 id="最后总结"><a href="#最后总结" class="headerlink" title="最后总结"></a>最后总结</h3><p>通过文本在Hue中集成Hadoop集群（Hdfs和Yarn），并且在集成完成后进行了简单的使用，我们以后可以有更好的方式操作Hdfs和查看作业执行情况了，后面我们还将继续集成Hive和Mysql服务，文中有不对的地方欢迎大家指出来！</p>]]></content>
    
    <summary type="html">
    
      Hue(02)Hue集成Hadoop集群环境
    
    </summary>
    
    
      <category term="学大数据" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://www.maxbill.cn/marks/Hadoop/"/>
    
      <category term="Hdfs" scheme="https://www.maxbill.cn/marks/Hdfs/"/>
    
      <category term="大数据" scheme="https://www.maxbill.cn/marks/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Yarn" scheme="https://www.maxbill.cn/marks/Yarn/"/>
    
      <category term="Hue" scheme="https://www.maxbill.cn/marks/Hue/"/>
    
  </entry>
  
  <entry>
    <title>Hue(01)Hue4.1的编译安装启动</title>
    <link href="https://www.maxbill.cn/1511704702.html"/>
    <id>https://www.maxbill.cn/1511704702.html</id>
    <published>2018-01-22T10:13:38.000Z</published>
    <updated>2020-07-07T12:58:48.135Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Hue是开源的Apache Hadoop UI系统，最早是由Cloudera Desktop演化而来，由Cloudera贡献给开源社区，它是基于Python Web框架Django实现的。通过使用Hue我们可以在浏览器端的Web控制台上与Hadoop集群进行交互来分析处理数据，例如操作HDFS上的数据，运行MapReduce Job等等。Hue所支持的功能特性集合：<br>1.认基于轻量级sqlite数据库管理会话数据，用户认证和授权，可以自定义为MySQL、Postgresql，以及Oracle等;<br>2.基于文件浏览器（File Browser）访问HDFS;<br>3.基于Hive编辑器来开发和运行Hive查询;<br>4.支持基于Solr进行搜索的应用，并提供可视化的数据视图，以及仪表板（Dashboard）;<br>5.支持基于Impala的应用进行交互式查询;<br>6.支持Spark编辑器和仪表板（Dashboard）;<br>7.支持Pig编辑器，并能够提交脚本任务;<br>8.支持Oozie编辑器，可以通过仪表板提交和监控Workflow、Coordinator和Bundle;<br>9.支持HBase浏览器，能够可视化数据、查询数据、修改HBase表;<br>10.支持Metastore浏览器，可以访问Hive的元数据，以及HCatalog;<br>11.支持Job浏览器，能够访问MapReduce Job（MR1/MR2-YARN）;<br>12.支持Job设计器，能够创建MapReduce/Streaming/Java Job;<br>13.支持Sqoop 2编辑器和仪表板（Dashboard）;<br>14.支持ZooKeeper浏览器和编辑器;<br>15.支持MySql、PostGresql、Sqlite和Oracle数据库查询编辑器</p><p>Hue的安装并不是那么简单,因为官方并没有编译好的,需要我们自己从github上下载源码、安装依赖、自己编译安装,编译的过程中最难也就是各种依赖缺失报错,本文将实际来进行下载-编译-安装-配置-运行hue的完整的操作过程。</p><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>1.CentOS7.2系统(虚拟机)<br>2.Hue4.1源码包: 下载地址:<a href="https://codeload.github.com/cloudera/hue/zip/branch-4.1">https://codeload.github.com/cloudera/hue/zip/branch-4.1</a><br>3.Maven环境</p><h2 id="编译环境"><a href="#编译环境" class="headerlink" title="编译环境"></a>编译环境</h2><p>在CentOS系统中安装编译Hue需要的依赖库:<br>yum install krb5-devel cyrus-sasl-gssapi cyrus-sasl-deve libxml2-devel libxslt-devel mysql mysql-devel openldap-devel python-devel python-simplejson sqlite-devel<br><img src="https://static.oschina.net/uploads/space/2018/0119/160316_KIGr_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2018/0119/160447_uEKn_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2018/0119/160615_6bNQ_2846946.png" alt=""><br>以上需要的依赖就安装完了,在编译过程中还有需要的依赖我们再安装。<br>编译Hue还需要Maven环境,因此在编译前需要安装Maven,可以参考之前的Linux安装Maven的内容。</p><h2 id="编译过程"><a href="#编译过程" class="headerlink" title="编译过程"></a>编译过程</h2><h3 id="上传源码"><a href="#上传源码" class="headerlink" title="上传源码"></a>上传源码</h3><p>本文是在虚拟机的CentOS环境中进行的,我们首先上传hHue源码包到虚拟机系统中<br><img src="https://static.oschina.net/uploads/space/2018/0119/164639_uo02_2846946.png" alt=""></p><h3 id="解压源码"><a href="#解压源码" class="headerlink" title="解压源码"></a>解压源码</h3><p>由于源码包是从github上下载的,下载的格式是zip,我们使用unzip命令解压<br><img src="https://static.oschina.net/uploads/space/2018/0119/165527_C0yC_2846946.png" alt=""><br>注:如果没有unzip服务,使用yum install unzip安装</p><h3 id="开始编译"><a href="#开始编译" class="headerlink" title="开始编译"></a>开始编译</h3><p>进入hue源码目录使用 make apps进行编译<br><img src="https://static.oschina.net/uploads/space/2018/0119/173134_eDW1_2846946.png" alt=""></p><h3 id="编译问题"><a href="#编译问题" class="headerlink" title="编译问题"></a>编译问题</h3><p>1&gt;.解决maven 权限问题<br>编译时提示maven的权限不够<br><img src="https://static.oschina.net/uploads/space/2018/0119/171456_xYP1_2846946.png" alt=""><br>解决办法:进入maven的bin目录将mvn权限修改 chmod 777 mvn</p><p>2&gt;.gcc命令错误<br>编译提示commod gcc命令错误<br><img src="https://static.oschina.net/uploads/space/2018/0119/173527_f0Mj_2846946.png" alt=""><br>解决办法:yum install gcc</p><p>3&gt;.ffi.h致命错误<br>编译时出现缺失ffi.h致命错误<br><img src="https://static.oschina.net/uploads/space/2018/0119/174040_fmhB_2846946.png" alt=""><br>解决办法:yum install libffi-devel openssl-devel</p><p>4&gt;.gmp.h致命错误<br>编译时出现缺失gmp.h致命错误<br><img src="https://static.oschina.net/uploads/space/2018/0119/174242_hCjs_2846946.png" alt=""><br>解决办法:yum install gmp-devel</p><p>5&gt;.缺失execvp错误<br>编译时出现缺失execvp错误<br><img src="https://static.oschina.net/uploads/space/2018/0119/174752_LRQr_2846946.png" alt="">解决办法: yum install gcc-c++</p><h3 id="编译完成"><a href="#编译完成" class="headerlink" title="编译完成"></a>编译完成</h3><p>经过上面的步骤Hue编译完成了,编译完成后Hue目录下多出一个app.reg文件和build文件夹<br><img src="https://static.oschina.net/uploads/space/2018/0122/111240_1f45_2846946.png" alt=""><br>完整的依赖:<br>yum install krb5-devel cyrus-sasl-gssapi cyrus-sasl-deve libxml2-devel libxslt-devel mysql mysql-devel openldap-devel python-devel python-simplejson sqlite-devel libffi-devel openssl-devel gmp-devel gcc gcc-c++</p><h2 id="启动验证"><a href="#启动验证" class="headerlink" title="启动验证"></a>启动验证</h2><h3 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h3><p>进入编译目录下cd build/env/bin/   然后输入启动命令:./hue runserver 0.0.0.0:8000,注意如果不加0.0.0.0:8000参数就是只有本机能访问，或者使用 ./supervisor命令启动<br><img src="https://static.oschina.net/uploads/space/2018/0122/151532_fYm1_2846946.png" alt=""><br>此时Hue服务已经启动完成</p><h3 id="访问验证"><a href="#访问验证" class="headerlink" title="访问验证"></a>访问验证</h3><p>在电脑浏览器上输入192.168.1.50:8000,如果是第一次登陆则是需要先创建一个用户<br><img src="https://static.oschina.net/uploads/space/2018/0122/152439_57VF_2846946.png" alt=""></p><h2 id="最后总结"><a href="#最后总结" class="headerlink" title="最后总结"></a>最后总结</h2><p>本文主要是实践了Hue的编译安装过程,后面的文章中我们会继续深入Hue操作和集成Hdfs、Hive、Hbase、Mysql等</p>]]></content>
    
    <summary type="html">
    
      Hue(01)Hue4.1的编译安装启动
    
    </summary>
    
    
      <category term="学大数据" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://www.maxbill.cn/marks/Hadoop/"/>
    
      <category term="大数据" scheme="https://www.maxbill.cn/marks/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Hue" scheme="https://www.maxbill.cn/marks/Hue/"/>
    
      <category term="Maven" scheme="https://www.maxbill.cn/marks/Maven/"/>
    
  </entry>
  
  <entry>
    <title>Hive(05)使用Java对数据仓库Hive进行操作</title>
    <link href="https://www.maxbill.cn/1536456043.html"/>
    <id>https://www.maxbill.cn/1536456043.html</id>
    <published>2018-01-16T07:49:13.000Z</published>
    <updated>2020-07-25T14:19:49.084Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在前文中我们实践了基于hadoop的数据仓库Hive的安装、配置、应用、扩展等，那么我们在实际中该如何通过程序调用（用户接口）开发呢，Hive提供了三种调用方式：首先是CLI就是我们前面使用过的Hive Shell命令行、然后就是通过JDBC或者ODBC的调用（通过程序可实现调用），最后就是官方提供的WebUI的方式。本文我们详细说的是使用JDBC通过Java代码去访问Hive服务，进行一些基本的操作。</p><h2 id="一、环境准备"><a href="#一、环境准备" class="headerlink" title="一、环境准备"></a>一、环境准备</h2><p>1.Hadoop集群</p><p>2.Hive元数据存储服务（mysql服务）</p><p>3.Hive数据仓库服务</p><p>4.Eclipse开发工具</p><h2 id="二、开发准备"><a href="#二、开发准备" class="headerlink" title="二、开发准备"></a>二、开发准备</h2><p>1.创建一个空的java项目<br><img src="https://static.oschina.net/uploads/space/2018/0116/101658_b3Yi_2846946.png" alt=""></p><p>2.创建如上的包<br>util包中使我们操作的jdbc或者odbc的工具类<br>main包中使我们程序运行的主类所在</p><p>3.启动Hadoop集群<br>在主节点上启动Hadoop集群start-all.sh<br><img src="https://static.oschina.net/uploads/space/2018/0104/103616_9Chc_2846946.png" alt=""></p><p>4.启动元数据库服务<br>登陆元数据库服务所在主机，启动Mysql服务service mysql start</p><p>5.启动Hiveserver2服务<br>在Hive机器上启动Hiveserver服务：hive –service hiveserver2 或者hive –service hiveserver2 &amp;<br><img src="https://static.oschina.net/uploads/space/2018/0115/111144_ZjWm_2846946.png" alt=""></p><p>6.启动Hive Metastore服务<br>在Hive机器上启动Hive Metastore服务：hive –service metastore或者hive –service metastore &amp;<br><img src="https://static.oschina.net/uploads/space/2018/0109/132512_UL4f_2846946.png" alt=""><br>看到如下信息，说明启动完成：<br><img src="https://static.oschina.net/uploads/space/2018/0109/132641_wcjJ_2846946.png" alt=""></p><p>7.验证启动<br>在终端输入jps -ml查看：<br><img src="https://static.oschina.net/uploads/space/2018/0109/133546_Ta0S_2846946.png" alt=""><br>可以看到Hadoop集群个Hive服务启动都正常</p><h2 id="三、开始编码"><a href="#三、开始编码" class="headerlink" title="三、开始编码"></a>三、开始编码</h2><p>1.编写jdbc工具类<br>编写打开Hive连接的方法<br> <img src="https://static.oschina.net/uploads/space/2018/0116/112536_RhQz_2846946.png" alt=""></p><p>代码块:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"> <span class="keyword">private</span> <span class="keyword">static</span> String driver = <span class="string">&quot;org.apache.hive.jdbc.HiveDriver&quot;</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> String url = <span class="string">&quot;jdbc:hive2://hdpc01:10000/default&quot;</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> String user = <span class="string">&quot;root&quot;</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> String pass = <span class="string">&quot;123456&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 打开连接</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Connection <span class="title">openConnection</span><span class="params">()</span> </span>&#123;</span><br><span class="line">Connection conn = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">Class.forName(driver);</span><br><span class="line">conn = DriverManager.getConnection(url, user, pass);</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> conn;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编写关闭Hive连接的方法<br><img src="https://static.oschina.net/uploads/space/2018/0116/103912_4MuE_2846946.png" alt=""></p><p>代码块：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 关闭连接</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">closeConnection</span><span class="params">(Statement stmt, Connection conn)</span> </span>&#123;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"><span class="keyword">if</span> (stmt != <span class="keyword">null</span>) &#123;</span><br><span class="line">stmt.close();</span><br><span class="line">stmt = <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (conn != <span class="keyword">null</span>) &#123;</span><br><span class="line">conn.close();</span><br><span class="line">conn = <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(<span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;:关闭连接成功...&quot;</span>);</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>测试连接<br><img src="https://static.oschina.net/uploads/space/2018/0116/105051_g9oA_2846946.png" alt=""></p><p>代码块：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.maxbill.hive.main;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.sql.Connection;</span><br><span class="line"><span class="keyword">import</span> java.sql.SQLException;</span><br><span class="line"><span class="keyword">import</span> java.sql.Statement;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.maxbill.hive.util.JdbcUtils;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@user</span> maxbill</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2018/01/16</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@func</span> hive操作测试类</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HiveTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"><span class="comment">// 1.测试连接</span></span><br><span class="line">testHiveConn();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">testHiveConn</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">Connection conn = JdbcUtils.openConnection();</span><br><span class="line">Statement stmt = conn.createStatement();</span><br><span class="line"><span class="keyword">if</span> (<span class="keyword">null</span> != stmt) &#123;</span><br><span class="line">System.out.println(<span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;:打开连接成功...&quot;</span>);</span><br><span class="line"><span class="comment">// 此处主要是测试连接是否正常，打开成功后，我们调用关闭方法释放连接</span></span><br><span class="line">JdbcUtils.closeConnection(stmt, conn);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">System.out.println(<span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;:打开连接失败...&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">catch</span> (SQLException e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行测试连接的Hive方法<br><img src="https://static.oschina.net/uploads/space/2018/0116/105705_UaPX_2846946.png" alt=""><br>发生异常，这是因为缺少hive驱动包，我们在项目中导入以下jar包即<br><img src="https://static.oschina.net/uploads/space/2018/0116/112143_VOJD_2846946.png" alt=""><br>然后继续测试，连接成功<br><img src="https://static.oschina.net/uploads/space/2018/0116/112246_SbHm_2846946.png" alt=""></p><p>2.基本查询操作<br><img src="https://static.oschina.net/uploads/space/2018/0116/131610_0tYh_2846946.png" alt=""></p><p>代码块：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">String sql = <span class="string">&quot;select *  from tb_user&quot;</span>;</span><br><span class="line">runQuerySql(sql);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 查询数据</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">runQuerySql</span><span class="params">(String sql)</span> </span>&#123;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">Connection conn = JdbcUtils.openConnection();</span><br><span class="line">Statement stmt = conn.createStatement();</span><br><span class="line"><span class="keyword">if</span> (<span class="keyword">null</span> != stmt) &#123;</span><br><span class="line">System.out.println(<span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;:打开连接成功...&quot;</span>);</span><br><span class="line">ResultSet rs = stmt.executeQuery(sql);</span><br><span class="line">System.out.println(<span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;:执行运行结果...&quot;</span>);</span><br><span class="line"><span class="comment">// 输出查询的结果集</span></span><br><span class="line">List list = resultSetToList(rs);</span><br><span class="line"><span class="keyword">for</span> (Object listObj : list) &#123;</span><br><span class="line">System.err.println(listObj.toString());</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 调用关闭方法释放连接</span></span><br><span class="line">JdbcUtils.closeConnection(stmt, conn);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">System.out.println(<span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;:打开连接失败...&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">catch</span> (SQLException e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"> <span class="comment">// ResultSet结果集转成list</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> List <span class="title">resultSetToList</span><span class="params">(ResultSet rs)</span> <span class="keyword">throws</span> java.sql.SQLException </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (rs == <span class="keyword">null</span>)</span><br><span class="line"><span class="keyword">return</span> Collections.EMPTY_LIST;</span><br><span class="line">ResultSetMetaData md = rs.getMetaData(); <span class="comment">// 得到结果集结构信息，比如字段数、字段名等</span></span><br><span class="line"><span class="keyword">int</span> columnCount = md.getColumnCount(); <span class="comment">// ResultSet的列数</span></span><br><span class="line">List list = <span class="keyword">new</span> ArrayList();</span><br><span class="line">Map rowData = <span class="keyword">new</span> HashMap();</span><br><span class="line"><span class="keyword">while</span> (rs.next()) &#123;</span><br><span class="line">rowData = <span class="keyword">new</span> HashMap(columnCount);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= columnCount; i++) &#123;</span><br><span class="line">rowData.put(md.getColumnName(i), rs.getObject(i));</span><br><span class="line">&#125;</span><br><span class="line">list.add(rowData);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> list;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面的查询操作都是基于以上方法，只需传入sql语句参数，使用DML的查询方法<br>1&gt;.基本查询<br>sql=”SELECT *  FROM tb_user WHERE id&gt;0”;<br><img src="https://static.oschina.net/uploads/space/2018/0116/132000_xy5l_2846946.png" alt=""></p><p>2&gt;.查看表结构<br>sql=”desc tb_user”;<br><img src="https://static.oschina.net/uploads/space/2018/0116/132150_G2XI_2846946.png" alt=""></p><p>3&gt;.统计查询<br>sql=”SELECT COUNT(id) FROM tb_user “;<br><img src="https://static.oschina.net/uploads/space/2018/0116/144906_x1vn_2846946.png" alt=""></p><p>4&gt;.表查询<br>sql=”show tables “;<br><img src="https://static.oschina.net/uploads/space/2018/0116/145456_es5O_2846946.png" alt=""><br>以下的创建删除表等操作没有rs结果，使用DLL语句的处理方法<br><img src="https://static.oschina.net/uploads/space/2018/0116/150341_WvJy_2846946.png" alt=""></p><p>代码块：   </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">// 数据操作</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">runHandleSql</span><span class="params">(String sql)</span> </span>&#123;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">Connection conn = JdbcUtils.openConnection();</span><br><span class="line">Statement stmt = conn.createStatement();</span><br><span class="line"><span class="keyword">if</span> (<span class="keyword">null</span> != stmt) &#123;</span><br><span class="line">System.out.println(<span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;:打开连接成功...&quot;</span>);</span><br><span class="line">stmt.execute(sql);</span><br><span class="line"><span class="comment">// 调用关闭方法释放连接</span></span><br><span class="line">JdbcUtils.closeConnection(stmt, conn);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">System.out.println(<span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;:打开连接失败...&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">catch</span> (SQLException e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>5&gt;.创建表<br>sql = “create table tb_test (key int, value string)  row format delimited fields terminated by ‘\t’”;<br>然后执行show tables 可以看到创建的tb_test表<br><img src="https://static.oschina.net/uploads/space/2018/0116/150657_c66U_2846946.png" alt=""></p><p>6&gt;.删除表<br>sql=”drop table if exists tb_test”;<br>然后执行show tables 可以看到创建的tb_test表已经删除<br><img src="https://static.oschina.net/uploads/space/2018/0116/151842_7mVj_2846946.png" alt=""></p><h2 id="四、文末总结"><a href="#四、文末总结" class="headerlink" title="四、文末总结"></a>四、文末总结</h2><p>以上就是本文使用Java代码通过Jdbc的方式连接Hive进行的简单的一些DLL查询和DML查询操作，在实际开发中相比之前的Hive Shell方式，使用代码去操作的方式用的更多点。本文的测试代码已经上传码云，代码地址为：<a href="https://gitee.com/MaxBill/HSDP">https://gitee.com/MaxBill/HSDP</a></p>]]></content>
    
    <summary type="html">
    
      Hive(05)使用Java对数据仓库Hive进行操作
    
    </summary>
    
    
      <category term="学大数据" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://www.maxbill.cn/marks/Hadoop/"/>
    
      <category term="大数据" scheme="https://www.maxbill.cn/marks/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Hive" scheme="https://www.maxbill.cn/marks/Hive/"/>
    
      <category term="数据仓库" scheme="https://www.maxbill.cn/marks/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>Hive(04)使用Dbeaver客户端连接Hive数据仓库</title>
    <link href="https://www.maxbill.cn/3275013893.html"/>
    <id>https://www.maxbill.cn/3275013893.html</id>
    <published>2018-01-15T06:58:34.000Z</published>
    <updated>2020-07-25T14:03:18.433Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>我们登陆Hive Shell 写复杂的长的sql语句不是很方便，没有格式化拷贝粘贴等常用操作，查询结果也不是很直观，时我们可以使用第三方的客户端连接Hive进行操作，于是我们使用支持hive的数据库客户端界面工具Dbeaver，本文我们使用其连接上面文章搭建好的Hive数据仓库服务。</p><h2 id="一、环境准备"><a href="#一、环境准备" class="headerlink" title="一、环境准备"></a>一、环境准备</h2><p>1.Hadoop集群</p><p>2.Hive元数据存储服务</p><p>3.Hive数据仓库服务</p><p>4.Dbeaver客户端工具</p><h2 id="二、实践准备"><a href="#二、实践准备" class="headerlink" title="二、实践准备"></a>二、实践准备</h2><p>1.启动Hadoop集群<br>在主节点上启动hadoop集群start-all.sh<br><img src="https://static.oschina.net/uploads/space/2018/0104/103616_9Chc_2846946.png" alt=""></p><p>2.启动元数据库服务<br>登陆元数据库服务所在主机，启动mysql服务service mysql start</p><p>3.启动Hiveserver2服务<br>在Hive机器上启动hiveserver服务：hive –service hiveserver2 或者hive –service hiveserver2 &amp;<br><img src="https://static.oschina.net/uploads/space/2018/0115/111144_ZjWm_2846946.png" alt=""></p><p>4.启动Hive Metastore服务<br>在Hive机器上启动Hive Metastore服务：hive –service metastore或者hive –service metastore &amp;<br><img src="https://static.oschina.net/uploads/space/2018/0109/132512_UL4f_2846946.png" alt=""><br>看到如下信息，说明启动完成：<br><img src="https://static.oschina.net/uploads/space/2018/0109/132641_wcjJ_2846946.png" alt=""></p><p>5.验证启动<br>在终端输入jps -ml查看：<br><img src="https://static.oschina.net/uploads/space/2018/0109/133546_Ta0S_2846946.png" alt=""><br>可以看到Hadoop集群个Hive服务启动都正常</p><h2 id="三、连接配置"><a href="#三、连接配置" class="headerlink" title="三、连接配置"></a>三、连接配置</h2><p>1.新建连接<br>打开Dbeaver工具，点击文件—&gt;新建<br><img src="https://static.oschina.net/uploads/space/2018/0115/142233_CcDF_2846946.png" alt=""><br>在新建向导点击选择Dbeaver—&gt;数据库连接<br><img src="https://static.oschina.net/uploads/space/2018/0115/142531_zJtd_2846946.png" alt=""><br>在数据库连接选择界面，点击选择Hadoop—&gt;Apache Hive<br><img src="https://static.oschina.net/uploads/space/2018/0115/142723_H3yx_2846946.png" alt=""></p><p>2.配置连接信息<br>在此处填写连接Hive服务的信息，注意端口号是Hive服务的10000，不是元数据库3306<br><img src="https://static.oschina.net/uploads/space/2018/0115/143113_ZIlY_2846946.png" alt=""><br>点击下一步，此时会自动下载Hive的启动程序<br><img src="https://static.oschina.net/uploads/space/2018/0115/135918_AKkB_2846946.png" alt=""><br>下一步网络配置我们默认就好，直接下一步<br><img src="https://static.oschina.net/uploads/space/2018/0115/143337_ktZc_2846946.png" alt=""><br>这一步没有特殊需求也默认配置，直接finish就可以了<br><img src="https://static.oschina.net/uploads/space/2018/0115/143450_Rtr4_2846946.png" alt=""></p><p>3.完成配置<br>经过以上的新建连接和配置连接，完成后就成功连接到Hive了<br><img src="https://static.oschina.net/uploads/space/2018/0115/143628_8qPz_2846946.png" alt=""></p><h2 id="四、简单验证使用"><a href="#四、简单验证使用" class="headerlink" title="四、简单验证使用"></a>四、简单验证使用</h2><p>我们使用dbeaver的sql编辑窗口编写sql语句测试几个查询操作<br>show tables<br><img src="https://static.oschina.net/uploads/space/2018/0115/144333_Gxib_2846946.png" alt=""><br>SELECT * FROM tb_user WHERE id &gt; 0<br><img src="https://static.oschina.net/uploads/space/2018/0115/144526_UEbZ_2846946.png" alt=""><br>SELECT name FROM tb_user UNION ALL SELECT name FROM tb_user_hdfs<br><img src="https://static.oschina.net/uploads/space/2018/0115/144834_oZVn_2846946.png" alt=""><br>我们这时候打开hive的webui服务，可以看到我们的连接记录、查询操作记录等<br><img src="https://static.oschina.net/uploads/space/2018/0115/145309_9oMD_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2018/0115/145358_i4LK_2846946.png" alt=""></p><h2 id="五、文末总结"><a href="#五、文末总结" class="headerlink" title="五、文末总结"></a>五、文末总结</h2><p>本文通过配置使用Dbeaver连接Hive服务，并且使用该工具进行了一些基本的查询 操作，可以看出和我们去操作数据库没什么区别，但是其实底层是不一样的，Hive查询底层是转换成MapReduce任务去操作的，在后面的深入文章中我们会详细研究下其原理。</p>]]></content>
    
    <summary type="html">
    
      Hive(04)使用Dbeaver客户端连接Hive数据仓库
    
    </summary>
    
    
      <category term="学大数据" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://www.maxbill.cn/marks/Hadoop/"/>
    
      <category term="大数据" scheme="https://www.maxbill.cn/marks/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Hive" scheme="https://www.maxbill.cn/marks/Hive/"/>
    
      <category term="数据仓库" scheme="https://www.maxbill.cn/marks/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>Hive(03)数据仓库Hive的WebUI配置使用</title>
    <link href="https://www.maxbill.cn/3275013893.html"/>
    <id>https://www.maxbill.cn/3275013893.html</id>
    <published>2018-01-15T03:42:03.000Z</published>
    <updated>2020-07-25T13:57:29.433Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>Hive有一个基于Web界面的东西，主要用于查看当前HiveServer2服务链接的会话、服务日志、配置参数等信息，这个服务更像是一个Hive提供的监控服务,更加方便对Hive的使用情况进行监控，本文我们介绍Hive2.3.2版本的webui怎么配置和使用。</p><h2 id="一、环境准备"><a href="#一、环境准备" class="headerlink" title="一、环境准备"></a>一、环境准备</h2><p>1.Hadoop集群</p><p>2.Hive完整的服务（2.3.2）</p><h2 id="二、配置过程"><a href="#二、配置过程" class="headerlink" title="二、配置过程"></a>二、配置过程</h2><p>本文使用的Hive-2.3.2的版本，其自身已经集成了HiveServer2的WEB UI服务，我们只需要在hive-site.xml中配置然后重启服务即可使用<br>使用vi /home/hive/hive-2.3.2/conf/hive-site.xml<br>然后写入一下配置 内容：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.webui.host<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdpc01<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.webui.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>10002<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.scratch.dir.permission<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>755<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p><img src="https://static.oschina.net/uploads/space/2018/0115/110902_Zggt_2846946.png" alt=""><br>在主节点上启动hadoop集群start-all.sh<br><img src="https://static.oschina.net/uploads/space/2018/0104/103616_9Chc_2846946.png" alt=""><br>启动HiveServer2服务<br><img src="https://static.oschina.net/uploads/space/2018/0115/111144_ZjWm_2846946.png" alt=""></p><h2 id="三、配置验证"><a href="#三、配置验证" class="headerlink" title="三、配置验证"></a>三、配置验证</h2><p>服务启动完成后，在浏览器中输入Hive WebUI服务的地址：192.168.1.10:10002<br><img src="https://static.oschina.net/uploads/space/2018/0115/112146_iqZP_2846946.png" alt=""></p><h2 id="四、Hive-WebUI的介绍和使用"><a href="#四、Hive-WebUI的介绍和使用" class="headerlink" title="四、Hive WebUI的介绍和使用"></a>四、Hive WebUI的介绍和使用</h2><p>主页面中显示当前的会话，包括IP、用户名、当前执行的操作（查询）数量、连接总时长、空闲时长；<br>如果会话执行查询，那么下面的Queries会显示查询的语句、执行耗时等信息<br><img src="https://static.oschina.net/uploads/space/2018/0115/112820_2BLk_2846946.png" alt=""><br>日志页面是Hive服务运行日志信息local logs<br><img src="https://static.oschina.net/uploads/space/2018/0115/112937_4nIc_2846946.png" alt=""><br>可以查看具体某一天的服务日志信息，以便在出现问题时更快的找到问题<br><img src="https://static.oschina.net/uploads/space/2018/0115/113131_Qfm2_2846946.png" alt=""><br>然后就是Hive配置信息Hive Configuration<br><img src="https://static.oschina.net/uploads/space/2018/0115/113651_Wx8K_2846946.png" alt=""><br>还有Hive服务的堆栈跟踪信息stack trace<br><img src="https://static.oschina.net/uploads/space/2018/0115/113754_tFUb_2846946.png" alt=""></p><h2 id="五、文末总结"><a href="#五、文末总结" class="headerlink" title="五、文末总结"></a>五、文末总结</h2><p> 以上就是对Hive WebUI的配置使用个简单的介绍，帮助我们更好的认识和使用下Hive WebUI服务,我们可以使用该页面监控Hive服务的使用情况,后面我们还会说到一个HWI(HIVE WEB INTERFACE)是Hive提供的基于Web图形界面的用户操作接口,可以说Hive WebUI是Hive的监控服务,hwi是Hive图形操作接口.</p>]]></content>
    
    <summary type="html">
    
      Hive(03)数据仓库Hive的WebUI配置使用
    
    </summary>
    
    
      <category term="学大数据" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://www.maxbill.cn/marks/Hadoop/"/>
    
      <category term="大数据" scheme="https://www.maxbill.cn/marks/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Hive" scheme="https://www.maxbill.cn/marks/Hive/"/>
    
      <category term="数据仓库" scheme="https://www.maxbill.cn/marks/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>Hive(02)数据仓库Hive的基本使用</title>
    <link href="https://www.maxbill.cn/3309867908.html"/>
    <id>https://www.maxbill.cn/3309867908.html</id>
    <published>2018-01-10T06:09:21.000Z</published>
    <updated>2020-07-25T13:52:53.276Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在上篇《 <a href="https://my.oschina.net/zss1993/blog/1602402">Hive(01)基于Hadoop集群的数据仓库Hive搭建实践</a> 》一文中我们搭建了分布式的数据仓库Hive服务，本文主要是在上文的基础上结合Hadoop分布式文件系统，将结构化的数据文件映射为一张数据库表，将sql语句转换为MapReduce任务进行运行的具体实践。Hive帮助无开发经验的数据分析人员，有能力处理大数据还可以构建标准化的MapReduce开发过程，因此我们学习大数据就有必要学习下Hive了。</p><h2 id="一、环境准备"><a href="#一、环境准备" class="headerlink" title="一、环境准备"></a>一、环境准备</h2><p>1.Hadoop集群环境</p><p>2.完整的Hive服务环境（连接了远程元数据库服务）<br>注：hadoop集群或者hive服务没有搭建，请从参考前面的文章</p><h2 id="二、实践准备"><a href="#二、实践准备" class="headerlink" title="二、实践准备"></a>二、实践准备</h2><p>1.启动Hadoop集群<br>启动hadoop三台机器，然后在主节点机器上启动hadoop集群：start-all.sh<br><img src="https://static.oschina.net/uploads/space/2018/0104/103616_9Chc_2846946.png" alt=""></p><p>2.启动Hiveserver服务<br>在hive机器上启动hiveserver服务：hive –service hiveserver2 或者hive –service hiveserver2 &amp;</p><p>3.启动Hive Metastore服务<br>在hive机器上启动Hive Metastore服务：hive –service metastore或者hive –service metastore &amp;<br><img src="https://static.oschina.net/uploads/space/2018/0109/132512_UL4f_2846946.png" alt=""><br>看到如下信息，说明启动完成：<br><img src="https://static.oschina.net/uploads/space/2018/0109/132641_wcjJ_2846946.png" alt=""></p><p>4.验证启动<br>在终端输入jps -ml查看：<br><img src="https://static.oschina.net/uploads/space/2018/0109/133546_Ta0S_2846946.png" alt=""><br>可以看到hadoop集群个hive服务启动都正常</p><h2 id="三、实践过程"><a href="#三、实践过程" class="headerlink" title="三、实践过程"></a>三、实践过程</h2><p>1.启动hive客户端<br>在hive机器上启动hiveserver服务：hive 或者hive shell<br><img src="https://static.oschina.net/uploads/space/2018/0109/133728_HNlj_2846946.png" alt=""></p><p>2.基本操作<br>&lt;1&gt;.创建表<br>在hive控制台输入脚本：<br>CREATE TABLE TB_USER(id int,name string,phone string) ROW FORMAT DELIMITED FIELDS TERMINATED BY ‘\t’;<br><img src="https://static.oschina.net/uploads/space/2018/0109/160325_egb7_2846946.png" alt=""></p><p>&lt;2&gt;.正则匹配查找表<br>在hive控制台输入：show tables ‘<em>user</em>‘;<br><img src="https://static.oschina.net/uploads/space/2018/0109/160829_9nWr_2846946.png" alt=""></p><p>&lt;3&gt;.查看表结构<br>在hive终端输入：desc 表名<br><img src="https://static.oschina.net/uploads/space/2018/0110/101015_6t9U_2846946.png" alt=""></p><p>&lt;4&gt;.增删表字段<br>我们给tb_user表先增加一个email字段: ALTER TABLE tb_user ADD COLUMNS (email string);<br><img src="https://static.oschina.net/uploads/space/2018/0110/102206_sv1E_2846946.png" alt=""></p><p>&lt;5&gt;.表重命名<br>我们将tb_user重新命名成tb_user_back表：ALTER TABLE tb_user RENAME TO tb_user_back;<br><img src="https://static.oschina.net/uploads/space/2018/0110/104926_M7fV_2846946.png" alt=""></p><p>&lt;6&gt;.删除表<br>首先创建一个tb_user表，然后删除tb_user_back表：DROP TABLE tb_user_back;<br><img src="https://static.oschina.net/uploads/space/2018/0110/105244_jw4a_2846946.png" alt=""></p><p>&lt;7&gt;.插入数据<br>Hive插入数据有以下几种方式：<br>1&gt;.从本地文件系统中导入数据到Hive表；<br>首先我们从本地文件系统中导入数据到Hive的tb_user表中:<br>我们在hive机器的home目录下创建user.txt文件，内容如下<img src="https://static.oschina.net/uploads/space/2018/0110/120732_66df_2846946.png" alt=""><br>然后在hive终端执行：<br>LOAD DATA LOCAL INPATH ‘/home/user.txt’ OVERWRITE INTO TABLE tb_user;<br><img src="https://static.oschina.net/uploads/space/2018/0110/120921_vCgk_2846946.png" alt=""><br>在HDFS中查看刚刚导入的数据：<br><img src="https://static.oschina.net/uploads/space/2018/0110/121306_fnCg_2846946.png" alt=""></p><p>2&gt;.从HDFS上导入数据到Hive表；<br>创建表tb_user_hdfs,然后从hdfs上导入user.txt的数据<br><img src="https://static.oschina.net/uploads/space/2018/0110/122317_78XM_2846946.png" alt=""><br>在HDFS中查看刚刚导入的数据：<br><img src="https://static.oschina.net/uploads/space/2018/0110/122434_xy2p_2846946.png" alt=""></p><p>3&gt;.从别的表中查询出相应的数据并导入到Hive表中；<br>创建表tb_user_end_tab,然后从tb_user表查询导入数据<br>CREATE TABLE TB_USER_END_TAB(id int,name string,phone string)  ROW FORMAT DELIMITED FIELDS TERMINATED BY ‘\t’;<br>INSERT OVERWRITE TABLE tb_user_end_tab SELECT * FROM tb_user;<br><img src="https://static.oschina.net/uploads/space/2018/0110/123857_kYeS_2846946.png" alt=""></p><p>4&gt;.在创建表的时候通过从别的表中查询出相应的记录并插入到所创建的表中；<br>新建  tb_user_new_tab表并从tb_user表中导入数据<br>CREATE TABLE tb_user_new_tab AS SELECT * FROM tb_user;<br><img src="https://static.oschina.net/uploads/space/2018/0110/124446_TGMH_2846946.png" alt=""><br>CREATE TABLE tb_user_new_tab LIKE tb_user;这是只克隆表结构不导数据</p><p>&lt;8&gt;.导出数据<br>1&gt;.通过Hive导出到本地文件系统<br>INSERT OVERWRITE LOCAL DIRECTORY ‘/home/user’ SELECT * FROM tb_user;<br><img src="https://static.oschina.net/uploads/space/2018/0110/130506_PIeA_2846946.png" alt="">查看导出的数据：<br><img src="https://static.oschina.net/uploads/space/2018/0110/130618_3kfg_2846946.png" alt=""></p><p>2&gt;.从hdfs中导出数据<br>参见《<a href="https://www.maxbill.cn/3224700853.html">Hadoop (02)-使用JavaApi对HDFS进行基本操作</a>》中hdfs下载文件的操作</p><p>3.查询操作<br>&lt;1&gt;.普通的条件、排序查询<br>FROM (SELECT * FROM tb_user) A SELECT A.* WHERE A.ID&gt;0 LIMIT 2;<br>FROM (SELECT * FROM tb_user) A SELECT A.* WHERE A.ID&gt;0 LIMIT 3;<br>FROM (SELECT * FROM tb_user) A SELECT A.* WHERE A.ID&gt;0 ORDER BY A.ID DESC LIMIT 2;<br><img src="https://static.oschina.net/uploads/space/2018/0110/132054_FJb1_2846946.png" alt=""></p><p>&lt;2&gt;.连接查询<br>为了测试我们给tb_user表加入多几条数据：<br><img src="https://static.oschina.net/uploads/space/2018/0110/133510_mqyr_2846946.png" alt=""><br>SELECT A.* FROM tb_user_hdfs A JOIN tb_user B ON A.ID=B.ID;<br><img src="https://static.oschina.net/uploads/space/2018/0110/134058_EXCr_2846946.png" alt=""><br>SELECT A.* FROM tb_user_hdfs A JOIN tb_user B ON A.ID=B.ID WHERE A.NAME=’xiaoming’;<br><img src="https://static.oschina.net/uploads/space/2018/0110/134347_XM9h_2846946.png" alt=""></p><p>&lt;3&gt;.聚合查询<br>SELECT COUNT(DISTINCT ID) FROM tb_user;<br><img src="https://static.oschina.net/uploads/space/2018/0110/134717_bjgb_2846946.png" alt=""></p><p>&lt;4&gt;.分组查询<br>SELECT ID,PHONE FROM tb_user GROUP BY ID,PHONE;<br><img src="https://static.oschina.net/uploads/space/2018/0110/135126_X24P_2846946.png" alt=""><br>SELECT ID,PHONE FROM tb_user GROUP BY ID,PHONE HAVING ID&gt;2;<br><img src="https://static.oschina.net/uploads/space/2018/0110/135331_i7QF_2846946.png" alt=""></p><p>4.视图操作<br>hive也有对视图的操作，下面我们进行视图的创建和删除<br><img src="https://static.oschina.net/uploads/space/2018/0110/140206_F77G_2846946.png" alt=""></p><h2 id="四、Hive终端下交互命令"><a href="#四、Hive终端下交互命令" class="headerlink" title="四、Hive终端下交互命令"></a>四、Hive终端下交互命令</h2><p>quit,exit:  退出hive终端<br>reset: 重置配置为默认值<br>set <key>=<value> : 修改特定变量的值<br>set :  输出用户覆盖的hive配置变量<br>set -v : 输出所有Hadoop和Hive的配置变量<br>add FILE[S] *, add JAR[S] *, add ARCHIVE[S] * : 添加 一个或多个 file, jar, archives到分布式缓存<br>list FILE[S], list JAR[S], list ARCHIVE[S] : 输出已经添加到分布式缓存的资源<br>list FILE[S] *, list JAR[S] *,list ARCHIVE[S] * : 检查给定的资源是否添加到分布式缓存<br>delete FILE[S] *,delete JAR[S] *,delete ARCHIVE[S] * : 从分布式缓存删除指定的资源<br>! <command> :  从Hive shell执行一个shell命令<br>dfs <dfs command> :  从Hive shell执行一个dfs命令<br><query string> : 执行一个Hive 查询，然后输出结果到标准输出<br>source FILE <filepath>:  在CLI里执行一个hive脚本文件</p><h2 id="五、文末总结"><a href="#五、文末总结" class="headerlink" title="五、文末总结"></a>五、文末总结</h2><p>本文中是对hive的一些基本操作和常用的操作的实践，在实际开发中是应用比较多的，在实践中好多地方尝试了好几遍，遇到了很多问题，通过查询网上的资料都解决了 ，在此记录帮助和我一样在学习hive的同学，同时文中有不足的地方也请大家通过留言提出来，共同学习。</p>]]></content>
    
    <summary type="html">
    
      Hive(02)数据仓库Hive的基本使用
    
    </summary>
    
    
      <category term="学大数据" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://www.maxbill.cn/marks/Hadoop/"/>
    
      <category term="大数据" scheme="https://www.maxbill.cn/marks/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Hive" scheme="https://www.maxbill.cn/marks/Hive/"/>
    
      <category term="数据仓库" scheme="https://www.maxbill.cn/marks/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>Hive(01)基于Hadoop集群的数据仓库Hive搭建实践</title>
    <link href="https://www.maxbill.cn/3275013893.html"/>
    <id>https://www.maxbill.cn/3275013893.html</id>
    <published>2018-01-04T10:23:03.000Z</published>
    <updated>2020-07-25T13:58:38.317Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在前面Hadoop的一系列文中，我们对Hadoop有了初步的认识和使用，以及可以搭建完整的集群和开发简单的MapReduce项目，下面我们开始学习基于Hadoop的数据仓库Apache Hive，将结构化的数据文件映射为一张数据库表，将sql语句转换为MapReduce任务进行运行的实践，Hadoop系列深入学习的文章还会继续。</p><h2 id="一、基本简介"><a href="#一、基本简介" class="headerlink" title="一、基本简介"></a>一、基本简介</h2><p>Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。 其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。</p><p>Hive是建立在 Hadoop 上的数据仓库基础构架。它提供了一系列的工具，可以用来进行数据提取转化加载（ETL），这是一种可以存储、查询和分析存储在 Hadoop 中的大规模数据的机制。Hive 定义了简单的类 SQL 查询语言，称为 HQL，它允许熟悉 SQL 的用户查询数据。同时，这个语言也允许熟悉 MapReduce 开发者的开发自定义的 mapper 和 reducer 来处理内建的 mapper 和 reducer 无法完成的复杂的分析工作。Hive 没有专门的数据格式。 Hive 可以很好的工作在 Thrift 之上，控制分隔符，也允许用户指定数据格式。</p><h2 id="二、应用场景"><a href="#二、应用场景" class="headerlink" title="二、应用场景"></a>二、应用场景</h2><p>Hive 构建在基于静态批处理的Hadoop 之上，Hadoop 通常都有较高的延迟并且在作业提交和调度的时候需要大量的开销。因此，Hive 并不能够在大规模数据集上实现低延迟快速的查询，例如，Hive 在几百MB 的数据集上执行查询一般有分钟级的时间延迟。因此，Hive 并不适合那些需要低延迟的应用，例如，联机事务处理（OLTP）。Hive 查询操作过程严格遵守Hadoop MapReduce 的作业执行模型，Hive 将用户的HiveQL 语句通过解释器转换为MapReduce 作业提交到Hadoop 集群上，Hadoop 监控作业执行过程，然后返回作业执行结果给用户。Hive 并非为联机事务处理而设计，Hive 并不提供实时的查询和基于行级的数据更新操作。Hive 的最佳使用场合是大数据集的批处理作业，例如，网络日志分析。</p><p>Hive 是一种底层封装了Hadoop 的数据仓库处理工具，使用类SQL 的HiveQL 语言实现数据查询，所有Hive 的数据都存储在Hadoop 兼容的文件系统（例如，Amazon S3、HDFS）中。Hive 在加载数据过程中不会对数据进行任何的修改，只是将数据移动到HDFS 中Hive 设定的目录下，因此，Hive 不支持对数据的改写和添加，所有的数据都是在加载的时候确定的。Hive 的设计特点如下：</p><p>1.支持索引，加快数据查询。<br>2.不同的存储类型，例如，纯文本文件、HBase 中的文件。<br>3.将元数据保存在关系数据库中，大大减少了在查询过程中执行语义检查的时间。<br>4.可以直接使用存储在Hadoop 文件系统中的数据。<br>5.内置大量用户函数UDF 来操作时间、字符串和其他的数据挖掘工具，支持用户扩展UDF 函数来完成内置函数无法实现的操作。<br>6.类SQL 的查询方式，将SQL 查询转换为MapReduce 的job 在Hadoop集群上执行。</p><h2 id="三、环境准备"><a href="#三、环境准备" class="headerlink" title="三、环境准备"></a>三、环境准备</h2><p>1.Hadoop集群环境</p><p>2.Mysql数据库服务</p><p>3.Mysql数据库驱动<br>下载地址：<a href="https://dev.mysql.com/downloads/connector/j/">https://dev.mysql.com/downloads/connector/j/</a></p><p>4.Apache Hive安装包<br>官网地址：<a href="https://hive.apache.org/">https://hive.apache.org/</a><br>下载地址：<a href="http://www.apache.org/dyn/closer.cgi/hive/">http://www.apache.org/dyn/closer.cgi/hive/</a><br><img src="https://static.oschina.net/uploads/space/2018/0102/174239_l0MW_2846946.png" alt=""><br>环境说明：<br>和hadoop的主节点公用机器：<br>192.168.1.10   Master主节点<br>192.168.1.50   Mysql数据库服务</p><h2 id="四、安装准备"><a href="#四、安装准备" class="headerlink" title="四、安装准备"></a>四、安装准备</h2><p>1.使用FTP上传Hive程序包到机器上<br><img src="https://static.oschina.net/uploads/space/2018/0103/130605_pLrO_2846946.png" alt=""></p><p>2.解压上传的hive程序包<br><img src="https://static.oschina.net/uploads/space/2018/0103/130724_q5ao_2846946.png" alt=""></p><p>3.删除程序包修改目录名称<br><img src="https://static.oschina.net/uploads/space/2018/0103/130828_x3tS_2846946.png" alt=""></p><h2 id="五、安装过程"><a href="#五、安装过程" class="headerlink" title="五、安装过程"></a>五、安装过程</h2><p>1.环境变量配置<br>执行vi /etc/profile输入以下hive的环境变量<br>export HIVE_HOME=/home/hive/hive-2.3.2<br>export PATH=$HIVE_HOME/bin:$PATH<br><img src="https://static.oschina.net/uploads/space/2018/0103/131236_l8j1_2846946.png" alt=""><br>执行source /etc/profile使其立即生效</p><p>2.修改Hive脚本文件<br>修改 hive-env.sh脚本文件，首先cp hive-env.sh.template  hive-env.sh<br><img src="https://static.oschina.net/uploads/space/2018/0103/132050_Yi16_2846946.png" alt=""><br>然后编辑 vi  hive-env.sh脚本，HADOOP_HOME=/home/hadoop/hadoop-2.8.2<br><img src="https://static.oschina.net/uploads/space/2018/0103/132524_8HXb_2846946.png" alt=""><br>修改hive-site.xml 配置文件，首先cp hive-default.xml.template hive-site.xml<br><img src="https://static.oschina.net/uploads/space/2018/0103/132857_bMng_2846946.png" alt=""><br>然后编辑vi hive-site.xml 配置文件，配置mysql元数据库信息</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span>  </span><br><span class="line"><span class="comment">&lt;!--源数据存储数据库地址--&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://hdpc05:3306/hive?createDatabaseIfNotExist=true<span class="symbol">&amp;amp;</span>characterEncoding=utf8<span class="symbol">&amp;amp;</span>useSSL=true<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="comment">&lt;!--源数据存储数据库驱动--&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="comment">&lt;!--源数据存储数据库用户--&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="comment">&lt;!--源数据存储数据库密码--&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>123456<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="comment">&lt;!--自动创建Schema--&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>datanucleus.autoCreateSchema<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="comment">&lt;!--自动创建Tables--&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>datanucleus.autoCreateTables<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="comment">&lt;!--自动创建Columns--&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>datanucleus.autoCreateColumns<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="comment">&lt;!--设置hive仓库的HDFS上的位置--&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="comment">&lt;!--资源临时文件存放位置--&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.downloaded.resources.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hive/hive-2.3.2/tmp/resources<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="comment">&lt;!--修改日志位置--&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.exec.local.scratchdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hive/hive-2.3.2/logs/HiveJobsLog<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.downloaded.resources.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hive/hive-2.3.2/logs/ResourcesLog<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.querylog.location<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hive/hive-2.3.2/logs/HiveRunLog<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.logging.operation.log.location<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hive/hive-2.3.2/logs/OpertitionLog<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="comment">&lt;!--配置HWI接口--&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>    </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.hwi.war.file<span class="tag">&lt;/<span class="name">name</span>&gt;</span>    </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hive/hive-2.3.2/lib/hive-hwi-2.1.1.jar<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>    </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.hwi.listen.host<span class="tag">&lt;/<span class="name">name</span>&gt;</span>    </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdpc01<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>    </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.hwi.listen.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span>    </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>9999<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="comment">&lt;!--thrift服务配置--&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.bind.host<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdpc01<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>10000<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.http.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>10001<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.http.path<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>cliservice<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="comment">&lt;!--HiveServer2的WEBUI--&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.webui.host<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdpc01<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.webui.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>10002<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.scratch.dir.permission<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>755<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p><img src="https://static.oschina.net/uploads/space/2018/0103/135534_IU5K_2846946.png" alt=""><br>由于hive是默认将元数据保存在本地内嵌的 Derby 数据库中，但是这种做法缺点也很明显，Derby不支持多会话连接，因此本文将选择mysql作为元数据存储，以上就是配置Hive使用mysq作为元数据的配置，mysql数据库服务本文已经搭建完成，可参考《<a href="https://my.oschina.net/zss1993/blog/1600715">Linux开发环境搭建之MySQL安装配置</a> 》</p><p>3.配置日志地址hive-log4j.properties文件<br>cp hive-log4j.properties.template hive-log4j.properties<br><img src="https://static.oschina.net/uploads/space/2018/0105/134604_sRjd_2846946.png" alt=""><br>然后vi hive-log4j.properties，将hive.log日志的位置改为hive下的tmp目录下：<br>property.hive.log.dir = /home/hive/hive-2.3.2/logs/${sys:user.name}<br><img src="https://static.oschina.net/uploads/space/2018/0105/135125_y75u_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2018/0105/135526_JM4O_2846946.png" alt=""></p><p>4.上传数据库驱动<br>将下载的mysql数据库驱动上传到hive的lib目录下面<br><img src="https://static.oschina.net/uploads/space/2018/0103/141349_kWVA_2846946.png" alt=""></p><p>5.Jar的拷贝<br>将hive下的新版本jline的JAR包hive/lib/jline-2.12.jar 拷贝到 hadoop/share/hadoop/yarn/lib/<br>将JAVA_HOME/lib目录下的tools.jar到hive/lib目录下</p><p>6.在主节点hosts文件中配置元数据主机地址<br>192.168.1.50 hdpc05<br><img src="https://static.oschina.net/uploads/space/2018/0104/115504_zXvI_2846946.png" alt=""></p><h2 id="六、验证服务"><a href="#六、验证服务" class="headerlink" title="六、验证服务"></a>六、验证服务</h2><p>1.启动Hadoop集群<br>在主节点上启动hadoop集群start-all.sh<br><img src="https://static.oschina.net/uploads/space/2018/0104/103616_9Chc_2846946.png" alt=""></p><p>2.启动元数据存储服务Mysql服务<br>远程连接我们的mysql主机，然后启动MYSQL服务(如果设置了自启动，则此步骤可以忽略)<br><img src="https://static.oschina.net/uploads/space/2018/0104/105934_Epd3_2846946.png" alt=""><br>启动hive服务端程序hive –service metastore<br>查看metastore服务是否启动nohup hive –service metastore &gt; metastore.log 2&gt;&amp;1 &amp;<br><img src="https://static.oschina.net/uploads/space/2018/0104/125320_QbVD_2846946.png" alt=""><br>查看hive服务是否启动nohup hive –service hiveserver2 &gt; hiveserver2.log 2&gt;&amp;1 &amp;</p><p>3.启动Hive服务<br><img src="https://static.oschina.net/uploads/space/2018/0104/125941_aocV_2846946.png" alt=""><br>使用jps -ml查看启动的服务进程：<br><img src="https://static.oschina.net/uploads/space/2018/0109/130301_TodZ_2846946.png" alt=""></p><p>4.验证Hive服务<br>在主节点执行Hive命令，然后在终端执行show databases;<br><img src="https://static.oschina.net/uploads/space/2018/0104/181638_y7Us_2846946.png" alt=""></p><h2 id="七、问题反馈"><a href="#七、问题反馈" class="headerlink" title="七、问题反馈"></a>七、问题反馈</h2><p>1.使用Hive服务时报如下错误：<br>Thu Jan 04 00:18:55 EST 2018 WARN: Establishing SSL connection without server’s identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn’t set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to ‘false’. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.<br><img src="https://static.oschina.net/uploads/space/2018/0104/132942_2mSt_2846946.png" alt=""><br>是因为MySQL 5.5.45+, 5.6.26+ and 5.7.6+版本上都要求使用ssl去连接，因此我们需要在连接时使用useSSL=true</p><p>2.启动Hive报如下错误：<br>Exception in thread “main” java.lang.RuntimeException: org.xml.sax.SAXParseException; systemId: file:/home/hive/hive-2.3.2/conf/hive-site.xml; lineNumber: 6; columnNumber: 93; The reference to entity “useSSL” must end with the ‘;’ delimiter.<br><img src="https://static.oschina.net/uploads/space/2018/0104/134153_sg3x_2846946.png" alt=""><br>因为在xml文件中 &amp;符号 需要转义 这个根据转义规则更改&amp;为&amp;于是便解决了</p><p>3.使用Hive连接元数据库报如下错误：<br>FAILED:SemanticExceptionorg.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Unable to instantiate<br>org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient<br><img src="https://static.oschina.net/uploads/space/2018/0104/134721_oRgy_2846946.png" alt=""><br>问题找到了，原来Hive2需要hive元数据库初始化，我们在终端执行：schematool -dbType mysql -initSchema<br><img src="https://static.oschina.net/uploads/space/2018/0104/135526_GiIM_2846946.png" alt=""></p><h2 id="八、文末总结"><a href="#八、文末总结" class="headerlink" title="八、文末总结"></a>八、文末总结</h2><p>本文主要是对Hive数据仓库集群的搭建实践，在过程中遇到很多问题，在上名的问题中也都列了出来，还有问题的解决办法，Hive的Metastore服务配置一般有三种方式，后面我们会有专门的一片文章来说明这三种方式，本文中使用的是第三种方式，这种方式也是生产环境中的使用方式。</p>]]></content>
    
    <summary type="html">
    
      Hive(01)基于Hadoop集群的数据仓库Hive搭建实践
    
    </summary>
    
    
      <category term="学大数据" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://www.maxbill.cn/marks/Hadoop/"/>
    
      <category term="大数据" scheme="https://www.maxbill.cn/marks/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Hive" scheme="https://www.maxbill.cn/marks/Hive/"/>
    
      <category term="数据仓库" scheme="https://www.maxbill.cn/marks/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>Linux系统开发环境搭建之MySQL安装配置</title>
    <link href="https://www.maxbill.cn/7079864490.html"/>
    <id>https://www.maxbill.cn/7079864490.html</id>
    <published>2018-01-02T08:35:14.000Z</published>
    <updated>2020-07-07T13:27:50.632Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>本文主要实践在Linux上安装和配置MySQL关系型数据库，完整的实践MySQL的下载、安装、配置、使用的过程，为后面某些文中使用做基础</p><h2 id="一、环境准备"><a href="#一、环境准备" class="headerlink" title="一、环境准备"></a>一、环境准备</h2><p>1.CentOS7发行版的Linux系统(最小化安装)</p><p>2.MySQL官方编译的安装包 mysql-5.7.20-linux-glibc2.12-x86_64<br>下载地址：<a href="https://dev.mysql.com/downloads/mysql/">https://dev.mysql.com/downloads/mysql/</a><br><img src="https://static.oschina.net/uploads/space/2018/0102/101839_NThT_2846946.png" alt=""></p><h2 id="二、安装准备"><a href="#二、安装准备" class="headerlink" title="二、安装准备"></a>二、安装准备</h2><p><strong>1.打开CentOS7发行版Linux系统</strong><br><img src="https://static.oschina.net/uploads/space/2018/0102/102319_yWg5_2846946.png" alt=""></p><p><strong>2.添加mysql组和mysql用户</strong><br>执行命令groupadd mysql 添加mysql组<br>执行命令useradd -r -g mysql mysql 添加mysql用户<br>参数说明：<br><strong>useradd -r表示mysql用户是系统用户，不可用于登录系统</strong><br><strong>useradd -g表示把mysql用户添加到mysql用户组中</strong><br><img src="https://static.oschina.net/uploads/space/2018/0102/102944_94Hq_2846946.png" alt=""><br>查看新添加的组和用户 ：groups mysql<br><img src="https://static.oschina.net/uploads/space/2018/0102/103331_wiNR_2846946.png" alt=""></p><p>3.使用FTP上传mysql安装包到我们创建的安装目录<br><img src="https://static.oschina.net/uploads/space/2018/0102/104024_aej9_2846946.png" alt=""><br>上传mysql安装包到linux系统<br><img src="https://static.oschina.net/uploads/space/2018/0102/112009_7iIK_2846946.png" alt=""></p><h2 id="三、安装过程"><a href="#三、安装过程" class="headerlink" title="三、安装过程"></a>三、安装过程</h2><p><strong>1.解压安装包到安装目录</strong><br><img src="https://static.oschina.net/uploads/space/2018/0102/112438_T8dH_2846946.png" alt=""></p><p><strong>2.更改目录名为mysql</strong><br><img src="https://static.oschina.net/uploads/space/2018/0102/112826_A4cV_2846946.png" alt=""></p><p><strong>3.修改目录权限</strong><br>进入mysql目录，修改目录拥有者为mysql用户：执行命令 chown -R mysql:mysql ./<br><img src="https://static.oschina.net/uploads/space/2018/0102/113136_653Q_2846946.png" alt=""></p><p><strong>4.安装mysql数据库</strong><br>进入mysql目录下的bin目录中，执行./mysql_install_db –user=mysql，此时系统反馈错误<br><img src="https://static.oschina.net/uploads/space/2018/0102/134136_64YK_2846946.png" alt=""><br>错误提示：需要指定data目录，因为mysql服务进程mysqld运行时都会访问data目录，所以必须由启动mysqld进程的用户，就是我们之前设置的mysql用户，执行这个脚本或者用root 执行，但是加上参数–user=mysql上文还有警告信息，说mysql_install_db 命令已经是弃用的，建议切换到mysqld –initialize命令<br>注意：mysql5.7和之前版本不同，很多资料上都是这个命令：./scripts/mysql_install_db –user=mysql，而mysql5.7的mysql_install_db命令是在bin目录下的并且建议 用 mysqld –initialize命令初始化<br>我们本文的版本是5.7.20，我们需要进入bin目录下执行初始化命令：./mysqld –initialize –user=mysql –basedir=/usr/local/deve/mysql –datadir=/usr/local/deve/mysql/data</p><p>参数解释：<br>–user  启动mysql的用户<br>–basedir  mysql安装目录<br>–datadir  mysql数据目录<br><img src="https://static.oschina.net/uploads/space/2018/0102/140445_Y58y_2846946.png" alt=""><br>[Note] A temporary password is generated for root<a href="https://my.oschina.net/u/570656">@localhost</a>: ae3Zk1&lt;1b=iu<br>注意：最后一行系统给出了root的默认密码，过会我们会修改</p><p><strong>5.修改目录权限</strong><br>将mysql目录下除了data目录的所有文件，改回root用户所有，mysql用户只需作为mysql/data/目录下所有文件的所有者<br><img src="https://static.oschina.net/uploads/space/2018/0102/141448_Sq2U_2846946.png" alt=""></p><p><strong>6.修改配置文件</strong><br>刚刚执行初始化命令，已经在系统的etc目录下生成了my.cnf配置文件<br><img src="https://static.oschina.net/uploads/space/2018/0102/143207_jmVv_2846946.png" alt=""></p><p>修改配置文件如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[client]  </span><br><span class="line">socket=/usr/<span class="built_in">local</span>/deve/mysql/tmp/mysql.sock</span><br><span class="line"></span><br><span class="line">[mysqld]  </span><br><span class="line">basedir=/usr/<span class="built_in">local</span>/deve/mysql  </span><br><span class="line">socket=/usr/<span class="built_in">local</span>/deve/imysql/tmp/mysql.sock  </span><br><span class="line">symbolic-links=0</span><br><span class="line"></span><br><span class="line">[mysqld_safe]  </span><br><span class="line">log-error=/usr/<span class="built_in">local</span>/deve/mysql/logs/mysql.log  </span><br><span class="line">pid-file=/usr/<span class="built_in">local</span>/deve/mysql/logs/mysql.pid                     </span><br><span class="line"></span><br><span class="line">!includedir /etc/my.cnf.d</span><br></pre></td></tr></table></figure><p><img src="https://static.oschina.net/uploads/space/2018/0102/154535_2kYA_2846946.png" alt=""><br>注意:tmp目录不存在就创建，否则会出错， 创建后要赋予mysql权限，chown -R mysql:mysql tmp 如果mysql.sock指定到/tmp以外的目录，需要在my.cnf中添加[client]并且指定socket位置，否则登录mysql时会报错：ERROR 2002 (HY000): Can’t connect to local MySQL server through socket ‘/tmp/mysql.sock’ (2)，默认是会找tmp目录下的sock文件</p><p><strong>7.将mysqld服务加入开机自启动项</strong><br>修改mysql.server中basedir的相关路径，改为自定义的路径<br><img src="https://static.oschina.net/uploads/space/2018/0102/150020_rrJt_2846946.png" alt=""><br>将support-files/mysql.server 拷贝为/etc/init.d/mysql并设置运行权限，这样就可以使用service mysql命令启动/停止服务，执行cp mysql.server /etc/init.d/mysql  然后执行chmod +x /etc/init.d/mysql 把mysql注册为开机启动的服务chkconfig –add mysql  验证chkconfig –list mysql<br><img src="https://static.oschina.net/uploads/space/2018/0102/150511_tCKb_2846946.png" alt=""></p><p><strong>8.mysql服务的开启和关闭</strong><br>&lt;1&gt;mysql服务启动有以下三种方式<br>#/etc/init.d/mysql start<br>serivce mysql start<br>bin/mysqld_safe&amp;  </p><p>&lt;2&gt;mysql服务停止有以下三种方式<br>#/etc/init.d/mysql stop<br>service mysql stop<br>bin/mysqladmin -uroot -p  (注意此时的root是指mysql的root用户)<br>注：脚本末尾加&amp;表示设置此进程为后台进程，区别就是在控制台输入bg，即可将当前进程转入后台</p><p><strong>9.配置环境变量</strong><br>vi /etc/profile<br>写入mysql的环境变量信息<br><img src="https://static.oschina.net/uploads/space/2018/0102/151902_qCdI_2846946.png" alt=""><br>退出保存后，执行source /etc/profile 使其生效，使用echo $PATH查看配置<br><img src="https://static.oschina.net/uploads/space/2018/0102/152123_bxMd_2846946.png" alt=""><br>注意：不添加环境变量或者建立软链接，运行mysql命令会出现   -bash: mysql:command not found</p><h2 id="四、验证安装"><a href="#四、验证安装" class="headerlink" title="四、验证安装"></a>四、验证安装</h2><p><strong>1.启动mysql服务</strong><br><img src="https://static.oschina.net/uploads/space/2018/0102/153156_Jbz2_2846946.png" alt=""></p><p><strong>2.连接mysql</strong><br>mysql -uroot -p  ae3Zk1&lt;1b=iu   （生成的密码）<br><img src="https://static.oschina.net/uploads/space/2018/0102/154744_iMTw_2846946.png" alt=""></p><p><strong>3.修改默认密码</strong><br>修改mysql的密码有很多中方法<br>&lt;1&gt;.使用客户端连接<br>直接执行  SET PASSWORD FOR ‘root’@’localhost’ = PASSWORD(‘newpass’);<br>localhost是mysql的主机ip，newpass是需要设置的新密码</p><p>&lt;2&gt;用SET PASSWORD命令<br>使用 mysql -uroot -p 连接成功后<br>SET PASSWORD FOR ‘root’@’localhost’ = PASSWORD(‘newpass’);</p><p>&lt;3&gt;用mysqladmin<br>mysqladmin -u root password “newpass”<br>如果root已经设置过密码，或者初始化生成了默认密码，采用如下方法<br>mysqladmin -u root password oldpass “newpass”</p><p>&lt;4&gt; 用UPDATE直接编辑user表<br>使用 mysql -uroot -p 连接成功后<br>mysql&gt; use mysql;<br>mysql&gt; UPDATE user SET Password = PASSWORD(‘newpass’) WHERE user = ‘root’;<br>mysql&gt; FLUSH PRIVILEGES;</p><p>&lt;5&gt;忘记root密码的时候<br>mysqld_safe –skip-grant-tables&amp;<br>mysql -u root mysql<br>mysql&gt; UPDATE user SET password=PASSWORD(“new password”) WHERE user=’root’;<br>mysql&gt; FLUSH PRIVILEGES;<br>本文直接在命令行中修改，采用上面第&lt;2&gt;中方式<br><img src="https://static.oschina.net/uploads/space/2018/0102/155354_tXne_2846946.png" alt=""></p><p><strong>4.远程连接mysql</strong><br>我们使用另一台主机的navicat进行远程连接<br><img src="https://static.oschina.net/uploads/space/2018/0102/160938_K1ht_2846946.png" alt=""><br>我们发现mysql服务不允许远程连接访问，我们需要授权远程访问，有以下两种方式：</p><p>&lt;1&gt;通过改表实现（简单）<br>使用 mysql -uroot -p 连接成功后<br>mysql&gt;use mysql;<br>mysql&gt;update user set host = ‘%’ where user = ‘root’;<br>mysql&gt;select host, user from user;<br>本文使用这种方式<br><img src="https://static.oschina.net/uploads/space/2018/0102/161917_8pxz_2846946.png" alt=""></p><p>&lt;2&gt;通过授权<br>首先在安装mysql的机器上运行：<strong>mysql -h localhost -u root</strong> ,然后在命令行执行<br>mysql&gt;GRANT ALL PRIVILEGES ON <em>.</em> TO ‘root’@’%’WITH GRANT OPTION<br>如果你想允许用户test从ip为192.168.1.100的主机连接到mysql服务器，并使用123456作为密码<br>GRANT ALL PRIVILEGES ON <em>.</em> TO ‘test’@’192.168.1.100’ IDENTIFIED BY ‘123456’ WITH GRANT OPTION;<br>然后mysql&gt;FLUSH PRIVILEGES 使修改生效<br>最后mysql&gt;EXIT退出即可<br>例如授权任何ip使用root 以123456登陆：<br>GRANT ALL PRIVILEGES ON <em>.</em> TO ‘root’@’%’ IDENTIFIED BY ‘123456’ WITH GRANT OPTION;<br>修改完成后，使用service mysql restart 重启服务，我们再次远程连接MYSQL服务，已经可以正常连接<br><img src="https://static.oschina.net/uploads/space/2018/0102/162819_fDNd_2846946.png" alt=""><br>注意：<strong>跳过密码验证</strong>，执行命令行：# /usr/bin/mysqld_safe –skip-grant-tables</p><h2 id="五、文末总结"><a href="#五、文末总结" class="headerlink" title="五、文末总结"></a>五、文末总结</h2><p>经过以上的步骤，mysql就已经正常安装可以使用了，在本文的安装配置中也遇到不少问题，经过询问别的大佬和查阅资料都完美解决，尤其是最新版的5.7.20在安装配置中和旧版本存在差异，走了很多弯路，希望本文能帮助到其他同学，如有错误也请留言提出，谢谢。</p>]]></content>
    
    <summary type="html">
    
      Linux系统开发环境搭建之MySQL安装配置
    
    </summary>
    
    
      <category term="开发运维" scheme="https://www.maxbill.cn/kinds/%E5%BC%80%E5%8F%91%E8%BF%90%E7%BB%B4/"/>
    
    
      <category term="MySQL" scheme="https://www.maxbill.cn/marks/MySQL/"/>
    
      <category term="Linux" scheme="https://www.maxbill.cn/marks/Linux/"/>
    
      <category term="数据库" scheme="https://www.maxbill.cn/marks/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="CentOS" scheme="https://www.maxbill.cn/marks/CentOS/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop(06)开发一个MapReduce项目</title>
    <link href="https://www.maxbill.cn/2716093100.html"/>
    <id>https://www.maxbill.cn/2716093100.html</id>
    <published>2017-12-28T06:44:30.000Z</published>
    <updated>2020-07-26T04:57:53.086Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在上文《<a href="https://www.maxbill.cn/1036438749.html">Hadoop(05)使用Eclipse连接远程Hadoop集群</a>》中我们主要实践了使用Eclispe开发工具安装Hadoop的开发插件，并且使用Hadoop插件连接Hadoop远程集群。本文我们要在上文搭建的Hadoop开发环境的基础上开发Hadoop的MapReduce项目。</p><h2 id="一、环境准备"><a href="#一、环境准备" class="headerlink" title="一、环境准备"></a>一、环境准备</h2><p>1.Hadoop集群</p><p>2.安装了Hadoop插件的Eclipse</p><h2 id="二、创建项目"><a href="#二、创建项目" class="headerlink" title="二、创建项目"></a>二、创建项目</h2><p>创建MapReduce项目可以通过eclispe的MapReduce插件创建，也可以使用Maven来构建，建议使用Maven来构建，可以更好的管理项目依赖等问题，下面两种方式都会进行：</p><p>1.打开Eclipse的File菜单下的New Project视图，选择建立Map/Reduce Project<br><img src="https://static.oschina.net/uploads/space/2017/1225/190331_cnCk_2846946.png" alt=""> </p><p>2.新建一个Map/Reduce项目<br><img src="https://static.oschina.net/uploads/space/2017/1225/191132_16wE_2846946.png" alt=""><br>配置默认的hadoop，点击Configure Hadoop install directory…<br><img src="https://static.oschina.net/uploads/space/2017/1225/191327_pXnJ_2846946.png" alt=""><br>设置完成默认的hadoop，点击next<br><img src="https://static.oschina.net/uploads/space/2017/1225/191416_5uho_2846946.png" alt=""><br>配置项目信息，点击完成，即可创建一个新的Map/Reduce项目<br><img src="https://static.oschina.net/uploads/space/2017/1225/191633_srx7_2846946.png" alt=""><br>注意：以上方式适合简单的Map/Reduce项目，需要手动管理项目的JAR包，建议使用Maven来构建Map/Reduce项目，文本实际上使用的是以下Maven的方式：<br>1&gt;.创建Maven项目**<br>点击File菜单下的New Project视图，选择建立Maven Project<br><img src="https://static.oschina.net/uploads/space/2017/1227/100816_qyYO_2846946.png" alt=""></p><p>2&gt;.填写项目信息，完成即可<br><img src="https://static.oschina.net/uploads/space/2017/1227/101048_Kj0z_2846946.png" alt=""><br>项目结构如下：<br><img src="https://static.oschina.net/uploads/space/2017/1227/102809_hyWK_2846946.png" alt=""><br>注：代码中项目名重构为HMRP了</p><h2 id="三、编写代码"><a href="#三、编写代码" class="headerlink" title="三、编写代码"></a>三、编写代码</h2><p>1.在上面创建的Maven项目中添加用到的hadoop开api包依赖</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.8.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-hdfs<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.8.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.8.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>pom.xml如下图：<br><img src="https://static.oschina.net/uploads/space/2017/1227/103422_RAGZ_2846946.png" alt=""><br>项目整体结构图如下：<br><img src="https://static.oschina.net/uploads/space/2017/1228/122737_MtWx_2846946.png" alt=""><br>注意：项目个类说明<br>JobBean：是用来传递作业运行所需参数的BEAN<br>WordCountMap：我们自己定义的map函数类<br>WordCountReduce：我们定义的reduce函数类<br>HdfsUtils：Hdfs操作的工具类<br>JobsUtils：作业工具类<br>WordCount：词频统计主类<br>项目源代码已经上传码云，地址：<a href="https://gitee.com/MaxBill/HMRP">https://gitee.com/MaxBill/HMRP</a></p><p>2.创建WordCount类，使用hadoop官方给出的例子代码来调试<br>本文使用的hadoop的版本是2.8.2，使用《<a href="http://hadoop.apache.org/docs/r2.8.2/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html">官方hadoop2.8.2的wordcount示例代码</a>》实践<br><img src="https://static.oschina.net/uploads/space/2017/1227/112513_NR9s_2846946.png" alt=""></p><p>3.使用java操作HDFS<br>我们对官方的例子做一些改动，官方是将写好的WordCount程序丢到hadoop上去执行，我们采用eclipse远程开发调试的方式<br>&lt;1&gt;.编写java客户端操作远程hdfs的工作类<br><img src="https://static.oschina.net/uploads/space/2017/1228/123926_czzo_2846946.png" alt=""><br>&lt;2&gt;.编写自定义map函数<br><img src="https://static.oschina.net/uploads/space/2017/1228/124225_lf1A_2846946.png" alt=""><br>&lt;3&gt;.编写自定义reduce函数<br><img src="https://static.oschina.net/uploads/space/2017/1228/124356_mIZQ_2846946.png" alt=""><br>&lt;4&gt;.编写作业工具类<br><img src="https://static.oschina.net/uploads/space/2017/1228/124626_K2ad_2846946.png" alt=""></p><p>4.我们改动后的测试主类<br><img src="https://static.oschina.net/uploads/space/2017/1228/122631_sF8S_2846946.png" alt=""></p><h2 id="四、运行调试"><a href="#四、运行调试" class="headerlink" title="四、运行调试"></a>四、运行调试</h2><p>1.准备资源数据<br>我们是统计词频程序，准备一个文本的元数据，用于我们的统计词频作业程序，在本地建一个txt文本，里面内容随便输入一些单词和句子即可<br><img src="https://static.oschina.net/uploads/space/2017/1228/125027_IOtQ_2846946.png" alt=""></p><p>2.启动hadoop集群<br><img src="https://static.oschina.net/uploads/space/2017/1227/135427_5Eww_2846946.png" alt=""></p><p>3.运行程序查看状态<br>从hdfs的web控制面板或者eclipse的hdfs插件可以看到，在数据输出目录已经产生执行完作业的数据结果了 ：<br><img src="https://static.oschina.net/uploads/space/2017/1228/125928_XfUT_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2017/1228/125821_R6ik_2846946.png" alt=""></p><p>4.查看作业执行数据结果集<br>在eclipse的插件中双击我们执行作业产生的作业结果：<br><img src="https://static.oschina.net/uploads/space/2017/1228/130202_EgPa_2846946.png" alt=""><br>和输入的元数据进行比对，统计结果正确</p><h2 id="五、问题反思"><a href="#五、问题反思" class="headerlink" title="五、问题反思"></a>五、问题反思</h2><p>*1.用户权限问题<br>Permission denied: user=hadoop, access=WRITE, inode=”/“:root:supergroup:drwxr-xr-x<br><img src="https://static.oschina.net/uploads/space/2017/1227/135250_BKmi_2846946.png" alt=""><br>解决方案：执行 hadoop fs -chmod 777 /user/hadoop，其他的操作目录也要赋权限</p><p>2.集群格式问题<br>在使用hdfs namenode -format格式化namenode的时候一定要先删除各个节点下data目录下的旧数据，不然会启动集群后无法连接datanode</p><h2 id="六、本文总结"><a href="#六、本文总结" class="headerlink" title="六、本文总结"></a>六、本文总结</h2><p>本文应用对官方WordCount的例子进行改动，实践了使用Eclispe连接远程Hadoop集群操作Hdfs以及开发运行调试了一个简单的MapReduce的项目。在项目中遇到了许多问题在文中也都列了出来，通过查资料也都顺利解决了。文中介绍了两种创建MapReduce项目的方式，实际项目中一般都会采用Maven的方式来构建，虽然完整的实践了MapReduce项目的开发过程，但是MapReduce和Hdfs是什么关 系，MapReduce运行的原理是什么，在后面的文中我们详细的讨论。</p>]]></content>
    
    <summary type="html">
    
      Hadoop(06)开发一个MapReduce项目
    
    </summary>
    
    
      <category term="学大数据" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://www.maxbill.cn/marks/Hadoop/"/>
    
      <category term="大数据" scheme="https://www.maxbill.cn/marks/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="MapReduce" scheme="https://www.maxbill.cn/marks/MapReduce/"/>
    
      <category term="分布式计算系统" scheme="https://www.maxbill.cn/marks/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop(05)使用Eclipse连接远程Hadoop集群</title>
    <link href="https://www.maxbill.cn/1036438749.html"/>
    <id>https://www.maxbill.cn/1036438749.html</id>
    <published>2017-12-22T08:37:10.000Z</published>
    <updated>2020-07-26T04:38:25.589Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在前面的文中我们分别搭建了单机和集群的Hadoop环境，今天我们将实践使用Eclispe开发工具安装Hadoop的开发插件，并且使用Hadoop插件连接Hadoop远程集群，文中有什么不对的地方，请大家指出来共同学习。</p><h2 id="一、环境准备"><a href="#一、环境准备" class="headerlink" title="一、环境准备"></a>一、环境准备</h2><p>1.Eclipse Java EE IDE for Web Developers- Oxygen.2 Release (4.7.2)</p><p>2.Eclipse的Hadoop插件hadoop-eclipse-plugin-2.6.0.jar</p><p>3.Hadoop集群环境</p><p>4.Deepin15.5稳定版linux系统</p><p>注：以上都是本次实践的版本，大家可以选择适合自己的版本</p><h2 id="二、安装Eclispe的Hadoop开发插件"><a href="#二、安装Eclispe的Hadoop开发插件" class="headerlink" title="二、安装Eclispe的Hadoop开发插件"></a>二、安装Eclispe的Hadoop开发插件</h2><p>1.下载Eclipse的Hadoop插件hadoop-eclipse-plugin-2.6.0.jar，下载地址：<br><a href="https://github.com/winghc/hadoop2x-eclipse-plugin">https://github.com/winghc/hadoop2x-eclipse-plugin</a><br><img src="https://static.oschina.net/uploads/space/2017/1221/132422_QqiL_2846946.png" alt=""></p><p>2.将插件复制到eclipse安装目录下的plugins目录<br><img src="https://static.oschina.net/uploads/space/2017/1221/132544_oT4c_2846946.png" alt=""></p><p>3.启动或者重启Eclispe开发工具<br><img src="https://static.oschina.net/uploads/space/2017/1221/132808_KHC7_2846946.png" alt=""></p><p>4.打开eclipse的show View窗口，看到了我们安装的Hadoop的插件<br><img src="https://static.oschina.net/uploads/space/2017/1221/133001_LObk_2846946.png" alt=""></p><p>5.点击Map/Reduce Locations打开视图<br><img src="https://static.oschina.net/uploads/space/2017/1221/133351_FAiM_2846946.png" alt=""><br>出现的是hadoop的Map/Reduce开发相关的视图，在视图区域右上方有蓝色小象的添加按钮，此时插件工作配置完成</p><h2 id="三、启动Hadoop集群环境"><a href="#三、启动Hadoop集群环境" class="headerlink" title="三、启动Hadoop集群环境"></a>三、启动Hadoop集群环境</h2><p>1.SSH连接Hadoop集群的master节点机器，启动hadoop集群<br><img src="https://static.oschina.net/uploads/space/2017/1222/145221_B6TA_2846946.png" alt=""></p><p>2.验证集群是否正常启动<br>在master节点执行hadoop dfsadmin -report验证<br><img src="https://static.oschina.net/uploads/space/2017/1222/152510_Cuzg_2846946.png" alt=""><br>打开yarn的web查看<br><img src="https://static.oschina.net/uploads/space/2017/1222/152346_MttV_2846946.png" alt=""><br>hadoop集群搭建可参考《<a href="https://www.maxbill.cn/8428277570.html">Hadoop(04)Hadoop集群模式搭建实践</a> 》</p><h2 id="四、创建配置Map-Reduce-Locations"><a href="#四、创建配置Map-Reduce-Locations" class="headerlink" title="四、创建配置Map/Reduce Locations"></a>四、创建配置Map/Reduce Locations</h2><p>1.打开eclispe到Map/Reduce Locations视图窗口<br><img src="https://static.oschina.net/uploads/space/2017/1222/153016_ON8n_2846946.png" alt=""></p><p>2.点击蓝色小大象按钮<br><img src="https://static.oschina.net/uploads/space/2017/1222/153141_fPDk_2846946.png" alt=""></p><p>3.配置Map/Reduce Locations信息<br><img src="https://static.oschina.net/uploads/space/2017/1222/162317_N74h_2846946.png" alt=""><br>注意填写参数：<br>Lacation Name：为该位置命名<br>MapReduce Master：与$HADOOP_DIRCONF/mapred-site.xml配置保持一致；<br>HDFS Master：与$HADOOP_DIRCONF/core-site.xml配置保持一致<br>User Name：登录hadoop用户名，可以填写其他的</p><p>4.点击完成即可<br><img src="https://static.oschina.net/uploads/space/2017/1222/153750_N5kU_2846946.png" alt=""></p><p>5.验证配置，点击DFS Locations<br><img src="https://static.oschina.net/uploads/space/2017/1222/162240_dEHg_2846946.png" alt=""></p><h2 id="五、本文总结"><a href="#五、本文总结" class="headerlink" title="五、本文总结"></a>五、本文总结</h2><p>本文主要实践了Eclispe安装Hadoop的插件，和在Eclispe下使用Hadoop插件连接远程Hadoop集群的操作，后面我们将使用改开发环境开发Hadoop的作业任务。</p>]]></content>
    
    <summary type="html">
    
      Hadoop(05)使用Eclipse连接远程Hadoop集群
    
    </summary>
    
    
      <category term="学大数据" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://www.maxbill.cn/marks/Hadoop/"/>
    
      <category term="大数据" scheme="https://www.maxbill.cn/marks/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="MapReduce" scheme="https://www.maxbill.cn/marks/MapReduce/"/>
    
      <category term="Eclipse" scheme="https://www.maxbill.cn/marks/Eclipse/"/>
    
      <category term="Deepin" scheme="https://www.maxbill.cn/marks/Deepin/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop(04)Hadoop集群模式搭建实践</title>
    <link href="https://www.maxbill.cn/8428277570.html"/>
    <id>https://www.maxbill.cn/8428277570.html</id>
    <published>2017-11-26T05:14:30.000Z</published>
    <updated>2020-07-26T04:14:22.855Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在《<a href="https://www.maxbill.cn/3609085320.html">Hadoop(01)Windows平台下Hadoop环境搭建</a>》一文中，我们在windows平台上搭建了单机模式的Hadoop，本文我们将在linux（CentOS7）下搭建Hadoop集群模式，以便实践更多场景下Hadoop的使用，尤其是在实际的生产模式中，必定是以集群模式存在。</p><h2 id="一、准备工作"><a href="#一、准备工作" class="headerlink" title="一、准备工作"></a>一、准备工作</h2><p>1.三台CentOS7-64的机器（本文已经在VM中搭建好了）</p><p>2.JDK-LINUX-64的程序包（jdk-8u151-linux-x64.tar.gz）</p><p>3.hadoop-2.8.2的程序包（hadoop-2.8.2.tar.gz）</p><p>4.SSH连接工具（git bash）</p><p>5.FTP传输工具（8uftp）<br><img src="https://static.oschina.net/uploads/space/2017/1126/113932_7YQl_2846946.png" alt=""><br>准备的三台虚拟机：<br>192.168.1.10   Master主节点<br>192.168.1.20   Slaver从节点1<br>192.168.1.30   Slaver从节点2<br>准备的相关程序包:<br><img src="https://static.oschina.net/uploads/space/2017/1124/170013_I5Z2_2846946.png" alt=""></p><h2 id="二、环境准备"><a href="#二、环境准备" class="headerlink" title="二、环境准备"></a>二、环境准备</h2><p>分别打开三台虚拟机：</p><p>1.向三台主机使用FTP传文件<br>打开FTP工具<br>注意：如果最小化安装的系统，需要在centos安装ftp服务：yum -y install vsftpd<br>特别注意：如果安装ftp服务时不能解析域名，需要配置dns解析：vi /etc/resolv.conf<br>nameserver 8.8.8.8<br>nameserver 8.8.4.4<br><img src="https://static.oschina.net/uploads/space/2017/1124/175536_vg5y_2846946.png" alt=""><br>安装完成FTP服务，这时候使用FTP服务还是连接不上，我们修改vsftpd的配置文件：vi /etc/vsftpd/vsftpd.conf<br><img src="https://static.oschina.net/uploads/space/2017/1125/214427_25ZD_2846946.png" alt=""><br>此时，使用命令： netstat -ntlp，此时FTP服务的21端口已经打开，<br><img src="https://static.oschina.net/uploads/space/2017/1125/214647_v3Rd_2846946.png" alt=""><br>使用FTP服务上传hadoop的服务包到/home/hadoop/目录下：<br><img src="https://static.oschina.net/uploads/space/2017/1125/215012_ixmR_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2017/1125/215041_GAA1_2846946.png" alt=""><br>上传JDK的程序包/home/java/目录下：<br> <img src="https://static.oschina.net/uploads/space/2017/1125/215237_pGqA_2846946.png" alt=""><br> <img src="https://static.oschina.net/uploads/space/2017/1125/215308_l15o_2846946.png" alt=""></p><p>2.因为hadoop是java环境下的，于是我们首先安装jdk环境<br>进入/home/java 目录使用 ls命令查看文件：<br><img src="https://static.oschina.net/uploads/space/2017/1125/220024_Z7MA_2846946.png" alt=""><br>这时能看到刚才使用FTP上传的hadoop的程序包，然后我们使用解压命令：tar -zxvf <file><br>经过一会解压过程，文件解压完成：<br>注：文件名太长可写首字母后用tab自动补齐<br><img src="https://static.oschina.net/uploads/space/2017/1125/220138_c6Nm_2846946.png" alt=""><br>然后在/etc/profile文件中，配置环境变量，让JDK在所有用户生效：vi /etc/profile<br>在文件的最后添加以下设置：<br>注：使用某些SSH工具可以直接ctrl+c+v操作，不用手动输入，文本使用的git bash就可以<br>export JAVA_HOME=/home/java/jdk1.8.0_151<br>export JRE_HOME=$JAVA_HOME/jre<br>export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib<br>export PATH=$JAVA_HOME/bin:$PATH<br><img src="https://static.oschina.net/uploads/space/2017/1125/220953_a0bS_2846946.png" alt=""><br>保存退出后，让修改的环境变量生效：source /etc/profile<br>此时环境变量已经生效，我们验证下jdk安装的是否成功： java -version<br><img src="https://static.oschina.net/uploads/space/2017/1125/221425_2Xrv_2846946.png" alt=""><br>特别提醒：<br>1&gt;.禁止防火墙：<br>systemctl stop firewalld.service  停止防火墙<br>systemctl disable firewalld.service 静止开机启动<br>2&gt;.禁止Selinux：<br>/usr/sbin/sestatus -v  查看Selinux状态<br>修改/etc/selinux/config 文件将SELINUX=enforcing改为SELINUX=disabled<br>此处搭建FTP服务详情可参考《<a href="https://my.oschina.net/zss1993/blog/1579994">CentOS最小安装的系统安装FTP服务</a>》</p><h2 id="三、集群搭建"><a href="#三、集群搭建" class="headerlink" title="三、集群搭建"></a>三、集群搭建</h2><p>经过前面的所有工作，此时准备工作已经完成。<br>1.解压hadoop的程序包<br>进入/home/hadoop 目录使用 ls命令查看文件：<br><img src="https://static.oschina.net/uploads/space/2017/1125/215601_1AgZ_2846946.png" alt=""><br>这时能看到刚才使用FTP上传的hadoop的程序包，然后我们使用解压命令：tar -zxvf <file><br>经过一会解压过程，文件解压完成：<br><img src="https://static.oschina.net/uploads/space/2017/1125/215901_MX3U_2846946.png" alt=""></p><p>2.配置环境变量<br>执行vi /etc/profile命令，并在文件末尾添加以下：<br>export HADOOP_HOME=/home/hadoop/hadoop-2.8.2<br>export HADOOP_CONF_HOME=$HADOOP_HOME/etc/hadoop<br>export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH<br><img src="https://static.oschina.net/uploads/space/2017/1125/223411_Ne5g_2846946.png" alt=""><br>保存退出后，让修改的环境变量生效：source /etc/profile</p><p>3.修改配置文件<br>&lt;1&gt;.修改启动脚本<br>vi /home/hadoop/hadoop-2.8.2/etc/hadoop/hadoop-env.sh<br>vi /home/hadoop/hadoop-2.8.2/etc/hadoop/yarn-env.sh<br>在这来那个文件都添加export JAVA_HOME=/home/java/jdk1.8.0_151</p><p>&lt;2&gt;.修改配置信息<br>首先配置核心文件：vi  /home/hadoop/hadoop-2.8.2/etc/hadoop/core-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hdpc01:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>io.file.buffer.size<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>131072<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/home/hadoop/hadoop-2.8.2/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">description</span>&gt;</span>Abase for other temporary directories.<span class="tag">&lt;/<span class="name">description</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p><img src="https://static.oschina.net/uploads/space/2017/1125/225501_CG0Q_2846946.png" alt=""><br>然后配置HDFS文件：vi  /home/hadoop/hadoop-2.8.2/etc/hadoop/hdfs-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/home/hadoop/hadoop-2.8.2/data/hdfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/home/hadoop/hadoop-2.8.2/data/hdfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdpc01:9001<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.webhdfs.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line">![](https://static.oschina.net/uploads/space/2017/1125/230410_ZyxZ_2846946.png)</span><br><span class="line">再配置YARN文件：vi  /home/hadoop/hadoop-2.8.2/etc/hadoop/yarn-site.xml</span><br><span class="line"></span><br><span class="line">```xml</span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services.mapreduce.shuffle.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.mapred.ShuffleHandler<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdpc01:8030<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdpc01:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.admin.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdpc01:8033<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdpc01:8035<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdpc01:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p><img src="https://static.oschina.net/uploads/space/2017/1125/231159_LXei_2846946.png" alt=""><br>使用cp mapred-site.xml.template mapred-site.xml<br>再配置Mapred文件：vi  /home/hadoop/hadoop-2.8.2/etc/hadoop/mapred-site.xml        </p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>                                                                      </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span>    </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>    </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span>    </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdpc01:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>    </span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span>    </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdpc01:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p><img src="https://static.oschina.net/uploads/space/2017/1222/160451_gB5y_2846946.png" alt=""><br>最后修改slaves配置文件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hdpc01</span><br><span class="line">hdpc02</span><br><span class="line">hdpc03</span><br></pre></td></tr></table></figure><p><img src="https://static.oschina.net/uploads/space/2017/1125/231456_jG0O_2846946.png" alt=""><br>特别注意：以上配置中的IP地址最好都使用主机名替换，防止后期ip变更会影响hadoop集群，要改配置中的IP地址，此处直接使用主机名既可以避免。</p><p>4.从节点安装<br>将刚刚主节点配置的hadoop复制到我们准备好的两个从节点的机器上，如果目录一致则不需要修改环境变量，不一样修改对应的环境变量（本文使用了快捷的方式，直接将主节点的虚拟机镜像手动克隆了两份作为从节点，该方法快捷简单，可以参考《<a href="https://my.oschina.net/zss1993/blog/1579305">VMware Workstation player 克隆多个CentOS实践</a>》），这样两个从节点也都配置好了。</p><p>5.配置主结点SSH免密登录子结点<br>在主节点机器上执行：ssh-keygen -t rsa<br>然后回车一直到完成：<br><img src="https://static.oschina.net/uploads/space/2017/1126/120100_rUjE_2846946.png" alt=""><br>将id_rsa.pub重定向到authorized_keys：cat id_rsa.pub&gt;&gt;authorized_keys<br><img src="https://static.oschina.net/uploads/space/2017/1126/120322_sN1W_2846946.png" alt=""><br>同理，两个从节点也都执行此步骤。<br><img src="https://static.oschina.net/uploads/space/2017/1205/124507_N56Z_2846946.png" alt=""><br>注：从节点hdpc03也和上图hdpc02一样处理<br>在主节点机器上将两个从节点的id_rsa.pub追加到authorized_keys<br>ssh hdpc02 cat /root/.ssh/id_rsa.pub&gt;&gt;authorized_keys<br>ssh hdpc03 cat /root/.ssh/id_rsa.pub&gt;&gt;authorized_keys<br>出现不能解析域名的问题，我们需要在三个节点的机器上配置下hosts：vi /etc/hosts<br><img src="https://static.oschina.net/uploads/space/2017/1126/122622_lYnD_2846946.png" alt=""></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">192.168.100.10   hdpc01</span><br><span class="line"></span><br><span class="line">192.168.100.20   hdpc02</span><br><span class="line"></span><br><span class="line">192.168.100.30   hdpc03</span><br></pre></td></tr></table></figure><p>然后执行：<br><img src="https://static.oschina.net/uploads/space/2017/1126/122950_btWV_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2017/1222/102738_2Mzk_2846946.png" alt=""><br>在主节点机器将authorized_keys分发到两个从节点的/root/.ssh目录下<br>scp authorized_keys hdpc02:/root/.ssh/<br>scp authorized_keys hdpc03:/root/.ssh/<br><img src="https://static.oschina.net/uploads/space/2017/1126/123624_xqB1_2846946.png" alt=""><br>此时主节点机器对两个从节点机器的免密登陆配置完成，我们测试下：<br>ssh hdpc02<br><img src="https://static.oschina.net/uploads/space/2017/1126/123812_5LvL_2846946.png" alt=""><br>ssh hdpc03<br><img src="https://static.oschina.net/uploads/space/2017/1126/123853_hC0e_2846946.png" alt=""><br>注意：上面安装其他从节点不仅可以克隆镜像，还可以在设置免密登陆后使用scp拷贝过去：<br>scp -r hadoop-2.8.2/ hdpc02:/home/hadoop/<br>scp -r hadoop-2.8.2/ hdpc03:/home/hadoop/</p><h2 id="四、集群验证"><a href="#四、集群验证" class="headerlink" title="四、集群验证"></a>四、集群验证</h2><p>1.在主节点上格式化<br>hadoop namenode -format 或者 hdfs namenode -format<br><img src="https://static.oschina.net/uploads/space/2017/1126/124428_sLpG_2846946.png" alt=""><br>此时已经成功格式化。</p><p>2.在主节点启动集群<br>执行start-all.sh<br><img src="https://static.oschina.net/uploads/space/2017/1126/153210_2T9t_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2017/1126/125959_eZiz_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2017/1126/153425_Mx4z_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2017/1126/153318_WuoU_2846946.png" alt=""><br>使用hadoop dfsadmin -report查看个节点信息：<br><img src="https://static.oschina.net/uploads/space/2017/1126/153830_aPcA_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2017/1126/153905_4x0Y_2846946.png" alt=""></p><p>3.web页面查看：192.168.100.10:50070<br><img src="https://static.oschina.net/uploads/space/2017/1126/130253_WaxP_2846946.png" alt=""></p><p>4.web查看集群信息：192.168.100.10:8088<br><img src="https://static.oschina.net/uploads/space/2017/1126/153126_cqgu_2846946.png" alt=""></p><p>5.停止集群<br>执行stop-all.sh<br><img src="https://static.oschina.net/uploads/space/2017/1126/153606_ZbzW_2846946.png" alt=""></p><h2 id="五、本文总结"><a href="#五、本文总结" class="headerlink" title="五、本文总结"></a>五、本文总结</h2><p>本文是完整的Hadoop集群搭建过程，通过这过Hadoop集群的工作方式有了更深的认识，同时也是整体能力的一个考验，为什么这么说，因为搭建过程中遇到很多额外的知识，比如我在搭建过程中遇到很多坑，FTP21号端口被防火墙拦截等问题。最后一步步解决各种问题，成功实践Hadoop集群的搭建，在此记录一下，顺道帮助更多学习的同学。</p>]]></content>
    
    <summary type="html">
    
      Hadoop(04)Hadoop集群模式搭建实践
    
    </summary>
    
    
      <category term="学大数据" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://www.maxbill.cn/marks/Hadoop/"/>
    
      <category term="大数据" scheme="https://www.maxbill.cn/marks/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="MapReduce" scheme="https://www.maxbill.cn/marks/MapReduce/"/>
    
      <category term="分布式计算系统" scheme="https://www.maxbill.cn/marks/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="Yarn" scheme="https://www.maxbill.cn/marks/Yarn/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop(03)MapReduce框架的简单实践</title>
    <link href="https://www.maxbill.cn/2839240833.html"/>
    <id>https://www.maxbill.cn/2839240833.html</id>
    <published>2017-11-19T08:16:30.000Z</published>
    <updated>2020-07-26T04:13:45.045Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>本文源码码云地址：<a href="https://gitee.com/MaxBill/hadoop">https://gitee.com/MaxBill/hadoop</a></p><p>在上篇《<a href="https://www.maxbill.cn/3224700853.html">hadoop(02)、使用JavaApi对HDFS进行基本操作</a>》中，通过JavaApi连接HDFS系统进行了基本的操作实践，本文将使用Hadoop的Map/Reduce框架进行简单的实践操作。</p><h2 id="一、MapReduce框架"><a href="#一、MapReduce框架" class="headerlink" title="一、MapReduce框架"></a>一、MapReduce框架</h2><p>Hadoop Map/Reduce是一个使用简易的软件框架，基于它写出来的应用程序能够运行在由上千个商用机器组成的大型集群上，并以一种可靠容错的方式并行处理上T级别的数据集。</p><p>一个Map/Reduce 作业（job）通常会把输入的数据集切分为若干独立的数据块，由 map任务（task）以完全并行的方式处理它们。框架会对map的输出先进行排序， 然后把结果输入给reduce任务。通常作业的输入和输出都会被存储在文件系统中。 整个框架负责任务的调度和监控，以及重新执行已经失败的任务。</p><p>通常，Map/Reduce框架和分布式文件系统是运行在一组相同的节点上的，也就是说，计算节点和存储节点通常在一起。这种配置允许框架在那些已经存好数据的节点上高效地调度任务，这可以使整个集群的网络带宽被非常高效地利用。</p><p>Map/Reduce框架由一个单独的master JobTracker 和每个集群节点一个slave TaskTracker共同组成。master负责调度构成一个作业的所有任务，这些任务分布在不同的slave上，master监控它们的执行，重新执行已经失败的任务。而slave仅负责执行由master指派的任务。</p><p>应用程序至少应该指明输入输出的位置（路径），并通过实现合适的接口或抽象类提供map和reduce函数。再加上其他作业的参数，就构成了作业配置（job configuration）。然后，Hadoop的 job client提交作业（jar包可执行程序等）和配置信息给JobTracker，后者负责分发这些软件和配置信息给slave、调度任务并监控它们的执行，同时提供状态和诊断信息给job-client。</p><p>注：以上Hadoop Map/Reduce摘自hadoop官方介绍，地址：<a href="http://hadoop.apache.org/docs/r1.0.4/cn/mapred_tutorial.html">http://hadoop.apache.org/docs/r1.0.4/cn/mapred_tutorial.html</a></p><h2 id="二、环境准备"><a href="#二、环境准备" class="headerlink" title="二、环境准备"></a>二、环境准备</h2><p>1.windows下hadoop开发环境：参见《<a href="https://www.maxbill.cn/3609085320.html">hadoop(01)、Windows平台下Hadoop环境搭建</a>》</p><p>2.IDEA 开发编辑器</p><p>3.下载一个部小说（本文使用著名小说：三国演义）</p><p>4.上一篇中的项目基础，码云地址：<em><strong>本文源码码云地址：<a href="https://gitee.com/MaxBill/hadoop">https://gitee.com/MaxBill/hadoop</a></strong></em></p><h2 id="三、开发编码"><a href="#三、开发编码" class="headerlink" title="三、开发编码"></a>三、开发编码</h2><p>1.启动hdfs服务</p><p>2.编写WordCount程序（它可以计算出指定数据集中指定单词出现的次数）</p><p>官方的例子是统计单词的，比较简单，本文则使用分词器对三国演义的指定词频进行统计。在上篇《<a href="https://www.maxbill.cn/3224700853.html">hadoop(02)、使用JavaApi对HDFS进行基本操作</a>》的基础上，打开项目，在pom文件中添加分词的依赖：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>cn.bestwu<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>ik-analyzers<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>3.开始词频统计编码<br>主要有以下几个步骤：<br>&lt;1&gt;.上传三国演义小说（分词数据集）到HDFS中<br><img src="https://static.oschina.net/uploads/space/2017/1119/160520_L4Fd_2846946.png" alt=""></p><p>&lt;2&gt;.编写统计词频代码</p><p>&lt;3&gt;.添加分词器</p><p>&lt;4&gt;.统计指定的词频<br>词频统计及测试主类代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.maxbill.hadoop.reduce;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapred.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapred.FileOutputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapred.JobClient;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapred.JobConf;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.UUID;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * @功能</span></span><br><span class="line"><span class="comment"> * @作者 MaxBill</span></span><br><span class="line"><span class="comment"> * @日期 2017/11/17</span></span><br><span class="line"><span class="comment"> * @时间 14:39</span></span><br><span class="line"><span class="comment"> * @备注 WordCountV1</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCountV1</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> String userPath = <span class="string">&quot;/user/Administrator/&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * @功能 单词统计任务</span></span><br><span class="line"><span class="comment">     * @作者 MaxBill</span></span><br><span class="line"><span class="comment">     * @日期 2017/11/16</span></span><br><span class="line"><span class="comment">     * @时间 12:12</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">wordCount</span><span class="params">(String jobName, String inputPath, String outputPath)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        JobConf jobConf = JobsUtils.getJobsConf(jobName);</span><br><span class="line">        FileInputFormat.setInputPaths(jobConf, <span class="keyword">new</span> Path(inputPath));</span><br><span class="line">        FileOutputFormat.setOutputPath(jobConf, <span class="keyword">new</span> Path(outputPath));</span><br><span class="line">        JobClient.runJob(jobConf);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * @功能 主类测试</span></span><br><span class="line"><span class="comment">     * @作者 MaxBill</span></span><br><span class="line"><span class="comment">     * @日期 2017/11/17</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        String inputPath = userPath + <span class="string">&quot;input/&quot;</span>;</span><br><span class="line">        String outputPath = userPath + <span class="string">&quot;output/&quot;</span> + UUID.randomUUID().toString().toUpperCase();</span><br><span class="line">        <span class="comment">//1.创建输入输出目录</span></span><br><span class="line">        <span class="comment">//HdfsUtils.mkdir(inputPath);</span></span><br><span class="line">        <span class="comment">//2.上传三国演义到Administrator目录下</span></span><br><span class="line">        <span class="comment">//HdfsUtils.uploadFile(&quot;D:\\\sgyy.txt&quot;, inputPath);</span></span><br><span class="line">        <span class="comment">//3.调用统计任务</span></span><br><span class="line">        wordCount(<span class="string">&quot;wordCountV1&quot;</span>, inputPath, outputPath);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Hadoop Map/Reduce操作工具类及作业配置代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.maxbill.hadoop.reduce;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapred.JobConf;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapred.TextInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapred.TextOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * @功能 Hadoop Map/Reduce操作工具类</span></span><br><span class="line"><span class="comment"> * @作者 MaxBill</span></span><br><span class="line"><span class="comment"> * @日期 2017/11/16</span></span><br><span class="line"><span class="comment"> * @时间 12:12</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JobsUtils</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> String hdfsPath = <span class="string">&quot;hdfs://127.0.0.1:10000&quot;</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> String jobsPath = <span class="string">&quot;hdfs://127.0.0.1:20000&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * @功能 获取HDFS的配置信息</span></span><br><span class="line"><span class="comment">     * @作者 MaxBill</span></span><br><span class="line"><span class="comment">     * @日期 2017/11/16</span></span><br><span class="line"><span class="comment">     * @时间 12:12</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Configuration <span class="title">getConfig</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Configuration config = <span class="keyword">new</span> Configuration();</span><br><span class="line">        config.set(<span class="string">&quot;fs.default.name&quot;</span>, hdfsPath);</span><br><span class="line">        config.set(<span class="string">&quot;mapred.job.tracker&quot;</span>, jobsPath);</span><br><span class="line">        <span class="keyword">return</span> config;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * @功能 获取HDFS的job配置信息</span></span><br><span class="line"><span class="comment">     * @作者 MaxBill</span></span><br><span class="line"><span class="comment">     * @日期 2017/11/16</span></span><br><span class="line"><span class="comment">     * @时间 12:12</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> JobConf <span class="title">getJobsConf</span><span class="params">(String jobName)</span> </span>&#123;</span><br><span class="line">        JobConf jobConf = <span class="keyword">new</span> JobConf(getConfig());</span><br><span class="line">        jobConf.setJobName(jobName);</span><br><span class="line">        jobConf.setOutputKeyClass(Text.class);</span><br><span class="line">        jobConf.setOutputValueClass(IntWritable.class);</span><br><span class="line">        jobConf.setMapperClass(MyMap.class);</span><br><span class="line">        jobConf.setCombinerClass(MyReduce.class);</span><br><span class="line">        jobConf.setReducerClass(MyReduce.class);</span><br><span class="line">        jobConf.setInputFormat(TextInputFormat.class);</span><br><span class="line">        jobConf.setOutputFormat(TextOutputFormat.class);</span><br><span class="line">        <span class="keyword">return</span> jobConf;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>MAP中使用分词器代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.maxbill.hadoop.reduce;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapred.MapReduceBase;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapred.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapred.OutputCollector;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapred.Reporter;</span><br><span class="line"><span class="keyword">import</span> org.wltea.analyzer.core.IKSegmenter;</span><br><span class="line"><span class="keyword">import</span> org.wltea.analyzer.core.Lexeme;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * @功能</span></span><br><span class="line"><span class="comment"> * @作者 MaxBill</span></span><br><span class="line"><span class="comment"> * @日期 2017/11/17</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyMap</span> <span class="keyword">extends</span> <span class="title">MapReduceBase</span> <span class="keyword">implements</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> IntWritable one = <span class="keyword">new</span> IntWritable(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">private</span> Text word = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * @作者 MaxBill</span></span><br><span class="line"><span class="comment">     * @日期 2017/11/17</span></span><br><span class="line"><span class="comment">     * @时间 14:46</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, OutputCollector&lt;Text, IntWritable&gt; output, Reporter reporter)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//未使用分词器</span></span><br><span class="line">        <span class="comment">//String line = value.toString();</span></span><br><span class="line">        <span class="comment">//StringTokenizer tokenizer = new StringTokenizer(line);</span></span><br><span class="line">        <span class="comment">// hile (tokenizer.hasMoreTokens()) &#123;</span></span><br><span class="line">        <span class="comment">//word.set(tokenizer.nextToken());</span></span><br><span class="line">        <span class="comment">//output.collect(word, one);</span></span><br><span class="line">        <span class="comment">//&#125;</span></span><br><span class="line">        <span class="comment">//使用分词器</span></span><br><span class="line">        <span class="keyword">byte</span>\[\] btValue = value.getBytes();</span><br><span class="line">        InputStream ip = <span class="keyword">new</span> ByteArrayInputStream(btValue);</span><br><span class="line">        Reader reader = <span class="keyword">new</span> InputStreamReader(ip);</span><br><span class="line">        IKSegmenter iks = <span class="keyword">new</span> IKSegmenter(reader, <span class="keyword">true</span>);</span><br><span class="line">        Lexeme lexeme;</span><br><span class="line">        <span class="keyword">while</span> ((lexeme = iks.next()) != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="comment">//打印全部分词</span></span><br><span class="line">            <span class="comment">//System.err.println(lexeme.getLexemeText());</span></span><br><span class="line">            word.set(lexeme.getLexemeText());</span><br><span class="line">            output.collect(word, one);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>过滤指定词频代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.maxbill.hadoop.reduce;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapred.MapReduceBase;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapred.OutputCollector;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapred.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapred.Reporter;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Iterator;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * @功能</span></span><br><span class="line"><span class="comment"> * @作者 MaxBill</span></span><br><span class="line"><span class="comment"> * @日期 2017/11/17</span></span><br><span class="line"><span class="comment"> * @时间 14:46</span></span><br><span class="line"><span class="comment"> * @备注 Reduce</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyReduce</span> <span class="keyword">extends</span> <span class="title">MapReduceBase</span> <span class="keyword">implements</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    List&lt;String&gt; textList = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">MyReduce</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        textList = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        textList.add(<span class="string">&quot;孙权&quot;</span>);</span><br><span class="line">        textList.add(<span class="string">&quot;姜维&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * @作者 MaxBill</span></span><br><span class="line"><span class="comment">     * @日期 2017/11/17</span></span><br><span class="line"><span class="comment">     * @时间 14:46</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterator&lt;IntWritable&gt; values, OutputCollector&lt;Text, IntWritable&gt; output, Reporter reporter)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (values.hasNext()) &#123;</span><br><span class="line">            sum += values.next().get();</span><br><span class="line">        &#125;</span><br><span class="line">        output.collect(key, <span class="keyword">new</span> IntWritable(sum));</span><br><span class="line">        String keyStr = <span class="keyword">new</span> String(key.toString());</span><br><span class="line">        <span class="keyword">boolean</span> isHas = textList.contains(keyStr);</span><br><span class="line">        <span class="keyword">if</span> (isHas) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&quot;</span> + keyStr + <span class="string">&quot; [&quot;</span> + sum + <span class="string">&quot;]&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>4.运行测试主类<br><img src="https://static.oschina.net/uploads/space/2017/1119/160237_ldGw_2846946.png" alt=""><br>从运行测试记过可以看到，已经统计出孙权和姜维在文中出现的次数。</p><h2 id="四、本文总结"><a href="#四、本文总结" class="headerlink" title="四、本文总结"></a>四、本文总结</h2><p>本文通过使用一些Map/Reduce框架提供的功能，实现的是的利用hadoop hdfs存储一个数据集，然后使用Hadoop Map/Reduce框架对数据进行简单的分析处理的一个小实践。在实践过程中也遇到了许多的问题，在查阅官方文档和网上资料中都一一解决了，对于Map/Reduce还有很多的内容，将在以后的内容中慢慢的学习补充。如有遗漏或者错误，欢迎提出！</p>]]></content>
    
    <summary type="html">
    
      Hadoop(03)MapReduce框架的简单实践
    
    </summary>
    
    
      <category term="学大数据" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="https://www.maxbill.cn/marks/Hadoop/"/>
    
      <category term="大数据" scheme="https://www.maxbill.cn/marks/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="MapReduce" scheme="https://www.maxbill.cn/marks/MapReduce/"/>
    
      <category term="分布式计算系统" scheme="https://www.maxbill.cn/marks/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop(02)使用JavaApi对HDFS进行基本操作</title>
    <link href="https://www.maxbill.cn/3224700853.html"/>
    <id>https://www.maxbill.cn/3224700853.html</id>
    <published>2017-11-16T06:55:38.000Z</published>
    <updated>2020-07-25T13:51:30.870Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>本文源码码云地址：<a href="https://gitee.com/MaxBill/Hadoop">https://gitee.com/MaxBill/Hadoop</a></p><p>在上篇《<a href="https://www.maxbill.cn/3609085320.html">Hadoop(01)-Windows平台下Hadoop环境搭建</a>》中，实践了在windows平台下使用搭建hadoop开发环境，同时搭建完毕在基于命令行的形式对HDFS进行了基本的操作，本文我们会在搭建的hadoop的基础平台上使用JAVA API来对HDFS进行简单的操作。</p><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>1.windows下hadoop开发环境：参见《<a href="https://www.maxbill.cn/3609085320.html">Hadoop(01)-Windows平台下Hadoop环境搭建</a>》<br>2.IDEA开发编辑器</p><h2 id="开发准备"><a href="#开发准备" class="headerlink" title="开发准备"></a>开发准备</h2><h3 id="建一个SpringBoot项目"><a href="#建一个SpringBoot项目" class="headerlink" title="建一个SpringBoot项目"></a>建一个SpringBoot项目</h3><p>使用IDEA新建一个SpringBoot项目，如下是我新建的项目结构：<br><img src="https://static.oschina.net/uploads/space/2017/1116/125251_dSJF_2846946.png" alt=""></p><h3 id="添加操作HDFS的依赖包"><a href="#添加操作HDFS的依赖包" class="headerlink" title="添加操作HDFS的依赖包"></a>添加操作HDFS的依赖包</h3><p>在刚建的SpringBoot项目的pom.xml文件里添加hadoop的依赖包hadoop-common, hadoop-client, hadoop-hdfs：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.8.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-hdfs<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.8.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.8.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="启动hadoop服务"><a href="#启动hadoop服务" class="headerlink" title="启动hadoop服务"></a>启动hadoop服务</h3><p>进入hadoop安装目录下的sbin中，执行脚本start-dfs.cmd<br><img src="https://static.oschina.net/uploads/space/2017/1116/113709_wcFP_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2017/1116/113758_VVEq_2846946.png" alt=""><br>这时hadoop服务已经成功启动。</p><h2 id="开始编码"><a href="#开始编码" class="headerlink" title="开始编码"></a>开始编码</h2><p>对HDFS操作设计以下几个主要的类：<br>Configuration：封装了客户端或者服务器的配置信息<br>FileSystem：此类的对象是一个文件系统对象，可以用该对象的一些方法来对文件进行操作通过FileSystem的静态方法get获得该对象，例：FileSystem hdfs = FileSystem.get(conf);<br>FSDataInputStream：这是HDFS中的输入流，通过由FileSystem的open方法获取<br>FSDataOutputStream：这是HDFS中的输出流，通过由FileSystem的create方法获取</p><h3 id="获取hadoop配置信息"><a href="#获取hadoop配置信息" class="headerlink" title="获取hadoop配置信息"></a>获取hadoop配置信息</h3><p><img src="https://static.oschina.net/uploads/space/2017/1116/130355_W3Yn_2846946.png" alt=""></p><h3 id="获取文件系统对象"><a href="#获取文件系统对象" class="headerlink" title="获取文件系统对象"></a>获取文件系统对象</h3><p><img src="https://static.oschina.net/uploads/space/2017/1116/130413_lQUL_2846946.png" alt=""><br>客户端去操作HDFS时，是有一个用户身份的,默认情况下，HDFS客户端API会从JVM中获取一个参数来作为自己的用户身份：DHADOOP_USER_NAME=hadoop<br>FileSystem hdfs = FileSystem.get(getHdfsConfig()); //默认获取<br>也可以在构造客户端fs对象时，通过参数传递进去<br>FileSystem hdfs = FileSystem.get(new URI(rootPath), getHdfsConfig(), “你的用户名”);</p><h3 id="创建文件夹操作"><a href="#创建文件夹操作" class="headerlink" title="创建文件夹操作"></a>创建文件夹操作</h3><p>先看下我们使用的用户下的目录（注：本文使用Administrator用户）：<br><img src="https://static.oschina.net/uploads/space/2017/1116/134602_ORtB_2846946.png" alt=""><br>可以看到该用户下为空目录，然后编写程序运行测试：<br><img src="https://static.oschina.net/uploads/space/2017/1116/131704_uRDl_2846946.png" alt="">)<img src="https://static.oschina.net/uploads/space/2017/1116/131728_Gg0N_2846946.png" alt=""><br>此时查看maxbill目录<br><img src="https://static.oschina.net/uploads/space/2017/1116/134516_XhDO_2846946.png" alt=""></p><h3 id="创建文件操作"><a href="#创建文件操作" class="headerlink" title="创建文件操作"></a>创建文件操作</h3><p><img src="https://static.oschina.net/uploads/space/2017/1116/134952_ISM9_2846946.png" alt=""><br>运行测试创建文件后查看目录：（在刚创建的demo目录创建maxbill.txt文件，并写入hello world）<br><img src="https://static.oschina.net/uploads/space/2017/1116/135646_Sb8m_2846946.png" alt=""></p><h3 id="读取文件内容操作"><a href="#读取文件内容操作" class="headerlink" title="读取文件内容操作"></a>读取文件内容操作</h3><p>读取刚才创建的maxbill.txt文件<br><img src="https://static.oschina.net/uploads/space/2017/1116/135943_1MKF_2846946.png" alt=""></p><h3 id="读取目录信息"><a href="#读取目录信息" class="headerlink" title="读取目录信息"></a>读取目录信息</h3><p><img src="https://static.oschina.net/uploads/space/2017/1116/141755_BLMh_2846946.png" alt="">)<img src="https://static.oschina.net/uploads/space/2017/1116/141923_kBNg_2846946.png" alt=""><br>读出那会我们创建的demo目录的详细信息：<br><img src="https://static.oschina.net/uploads/space/2017/1116/142012_CFiC_2846946.png" alt=""></p><h3 id="读取文件列表"><a href="#读取文件列表" class="headerlink" title="读取文件列表"></a>读取文件列表</h3><p><img src="https://static.oschina.net/uploads/space/2017/1116/142122_hP4F_2846946.png" alt=""><br>读出那会我们创建的demo目录下的文件：<br><img src="https://static.oschina.net/uploads/space/2017/1116/142226_Hj9z_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2017/1116/142320_Sinq_2846946.png" alt=""></p><h3 id="重命名文件"><a href="#重命名文件" class="headerlink" title="重命名文件"></a>重命名文件</h3><p><img src="https://static.oschina.net/uploads/space/2017/1116/142557_lME3_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2017/1116/142730_FewD_2846946.png" alt=""><br>运行重命名程序后，查看文件已经被重命名：<br><img src="https://static.oschina.net/uploads/space/2017/1116/142828_7veY_2846946.png" alt=""></p><h3 id="删除文件"><a href="#删除文件" class="headerlink" title="删除文件"></a>删除文件</h3><p><img src="https://static.oschina.net/uploads/space/2017/1116/143213_9zeH_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2017/1116/143125_U9qx_2846946.png" alt=""><br>运行删除程序后，查看文件已经被删除：<br><img src="https://static.oschina.net/uploads/space/2017/1116/143246_0LMU_2846946.png" alt=""></p><h3 id="上传文件"><a href="#上传文件" class="headerlink" title="上传文件"></a>上传文件</h3><p><img src="https://static.oschina.net/uploads/space/2017/1116/144655_12fp_2846946.png" alt="">)<img src="https://static.oschina.net/uploads/space/2017/1116/144051_CY1X_2846946.png" alt=""><br>运行上传程序后，查看文件已经被上传到指定目录：<br><img src="https://static.oschina.net/uploads/space/2017/1116/144222_JmCv_2846946.png" alt=""></p><h3 id="下载文件"><a href="#下载文件" class="headerlink" title="下载文件"></a>下载文件</h3><p><img src="https://static.oschina.net/uploads/space/2017/1116/144712_RDgR_2846946.png" alt=""><br>运行下载程序后，查看文件已经被下载到指定目录：<br><img src="https://static.oschina.net/uploads/space/2017/1116/145003_wjsy_2846946.png" alt=""><br>下载后多出一个crc文件，还没注意是啥作用</p><h2 id="最后总结"><a href="#最后总结" class="headerlink" title="最后总结"></a>最后总结</h2><p>通过使用java api操作hadoop的hdfs，给我的感觉是和阿里的对象存储类似的效果，hdfs可以用来架设公司的云盘等服务，也可作文件服务器使用，本文使用的单机操作，后面会使用集群来进行实践。</p>]]></content>
    
    <summary type="html">
    
      Hadoop(02)使用JavaApi对HDFS进行基本操作
    
    </summary>
    
    
      <category term="学大数据" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="分布式文件系统" scheme="https://www.maxbill.cn/marks/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="Hadoop" scheme="https://www.maxbill.cn/marks/Hadoop/"/>
    
      <category term="Hdfs" scheme="https://www.maxbill.cn/marks/Hdfs/"/>
    
      <category term="大数据" scheme="https://www.maxbill.cn/marks/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop(01)Windows平台下Hadoop环境搭建</title>
    <link href="https://www.maxbill.cn/3609085320.html"/>
    <id>https://www.maxbill.cn/3609085320.html</id>
    <published>2017-11-13T05:13:03.000Z</published>
    <updated>2020-07-15T14:23:46.772Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>hadoop是运行在linux系统下的一个由Apache基金会所开发的分布式系统基础架构。用户可以在不了解分布式底层细节的情况下，开发分布式程序，充分利用集群的威力进行高速运算和存储。今天我们要在windows环境下搭建hadoop的环境，Windows下运行Hadoop，通常有两种方式：一种是用VM方式安装一个Linux操作系统，这样基本可以实现全Linux环境的Hadoop运行；另一种是通过Cygwin模拟Linux环境。后者的好处是使用比较方便，安装过程也简单。今天我们使用第三种方式不需要虚拟机和cygwin依赖，相对简便很多。</p><h2 id="环境搭建准备"><a href="#环境搭建准备" class="headerlink" title="环境搭建准备"></a>环境搭建准备</h2><p>1.windows系统（win7及以上）<br>2.hadoop程序包（本文使用最新稳定版hadoop-2.8.2），下载地址：<br><a href="http://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-2.8.2">http://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-2.8.2</a><br>3.下载hadoop在windows上需要的winutils支持和hadoop.dll依赖库，下载地址：<br><a href="https://github.com/steveloughran/winutils">https://github.com/steveloughran/winutils</a> （注：选择自己对应的版本）</p><h2 id="开始搭建步骤"><a href="#开始搭建步骤" class="headerlink" title="开始搭建步骤"></a>开始搭建步骤</h2><h3 id="安装hadoop"><a href="#安装hadoop" class="headerlink" title="安装hadoop"></a>安装hadoop</h3><p>将刚才下载的hadoop-2.8.2程序包解压到windows的磁盘目录下（注：无空格目录，最好不要汉语）<br>然后配置hadoop的环境变量：新建HADOOP_HOME，定位到hadoop解压目录，如：<br><img src="https://static.oschina.net/uploads/space/2017/1113/110848_aXwv_2846946.png" alt=""><br>D:\tool\bigdata\hadoop （注：我的目录，大家换成自己的目录）path环境变量中增加：<br>%HADOOP_HOME%\bin;<br><img src="https://static.oschina.net/uploads/space/2017/1113/104851_gHyc_2846946.png" alt=""></p><h3 id="下载安装JDK环境"><a href="#下载安装JDK环境" class="headerlink" title="下载安装JDK环境"></a>下载安装JDK环境</h3><p>jdk安装配置此处省略，我的其他地方已经提及，或者大家自己百度搭建</p><h3 id="配置Hadoop依赖库"><a href="#配置Hadoop依赖库" class="headerlink" title="配置Hadoop依赖库"></a>配置Hadoop依赖库</h3><p>将winutils.exe放到hadoop的bin目录下，将hadoop.dll放到C盘/windows/System目录下<br>注：如果出现依赖性异常问题可以将hadoop.dll放到C盘/windows/System32解决</p><h3 id="测试hadoop环境"><a href="#测试hadoop环境" class="headerlink" title="测试hadoop环境"></a>测试hadoop环境</h3><p>在hadoop的bin目录下按住shift右击选择在此处打开命令行，输入hadoop version命令查看信息：<br><img src="https://static.oschina.net/uploads/space/2017/1113/112152_SmJS_2846946.png" alt=""></p><h3 id="配置hadoop"><a href="#配置hadoop" class="headerlink" title="配置hadoop"></a>配置hadoop</h3><p>修改hadoop核心配置文件hadoop/etc/hadoop/core-site.xml<br><img src="https://static.oschina.net/uploads/space/2017/1113/112902_F0n5_2846946.png" alt="">修改hdfs配置文件hadoop/etc/hadoop/hdfs-site.xml<br><img src="https://static.oschina.net/uploads/space/2017/1113/125413_Qwss_2846946.png" alt=""><br>修改hdfs配置文件hadoop/etc/hadoop/mapred-site.xml<br><img src="https://static.oschina.net/uploads/space/2017/1113/121008_suB2_2846946.png" alt=""><br>修改hdfs配置文件hadoop/etc/hadoop/yarn-site.xml<br><img src="https://static.oschina.net/uploads/space/2017/1113/121116_paJp_2846946.png" alt=""></p><h3 id="启动hadoop环境"><a href="#启动hadoop环境" class="headerlink" title="启动hadoop环境"></a>启动hadoop环境</h3><p>启动前先执行hdfs namenode -format格式化系统文件命令（注：hadoop/bin下执行）<br><img src="https://static.oschina.net/uploads/space/2017/1113/121545_gw8j_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2017/1113/121644_9FFJ_2846946.png" alt=""><br>此时已进行完初始化系统第一步，接下来cd到hadoop/sbin目录下，按住shift右击选择在此处打开命<br>令行执行 start-dfs 命令启动hadoop<br><img src="https://static.oschina.net/uploads/space/2017/1113/122059_7GLR_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2017/1113/122135_Jxed_2846946.png" alt=""><br>查看控制台日志发现启动报出异常，没有启动成功：查看控制台错误时缺少库文件，好像忘记把hadoop.dll文件加到hadoop的bin目录下了，于是拷贝粘贴再次执行start-dfs命令<br><img src="https://static.oschina.net/uploads/space/2017/1113/124132_fdGp_2846946.png" alt=""><br><img src="https://static.oschina.net/uploads/space/2017/1113/124206_3wEO_2846946.png" alt=""><br>此时成功启动，在浏览器地址栏输入<a href="http://127.0.0.1:50070/">http://127.0.0.1:50070/</a><br><img src="https://static.oschina.net/uploads/space/2017/1113/124335_j5Qc_2846946.png" alt=""><br>此时说明hadoop在windows平台下已经成功搭建完成。</p><h2 id="Hadoop的简单使用"><a href="#Hadoop的简单使用" class="headerlink" title="Hadoop的简单使用"></a>Hadoop的简单使用</h2><h3 id="简单操作hdfs"><a href="#简单操作hdfs" class="headerlink" title="简单操作hdfs"></a>简单操作hdfs</h3><p>由于已经在环境变量中配置了hadoop/bin目录此时在命令行中直接就可使欢乐的使用hdfs的命令了<br>&lt;1&gt;.显示文件命令：hdfs dfs -ls<br>&lt;2&gt;.创建目录（文件夹）命令：hdfs dfs -mkdir &lt;目录&gt;<br>&lt;3&gt;.文件的输入命令：hdfs dfs -put &lt;源文件目录&gt;  &lt;hdfs文件目录&gt;<br>&lt;4&gt;.文件内容显示命令：hdfs dfs -cat &lt;文件目录&gt;<br>&lt;5&gt;.删除文件命令：hdfs dfs -&lt;文件目录&gt;</p><h3 id="可视化hdfs资源"><a href="#可视化hdfs资源" class="headerlink" title="可视化hdfs资源"></a>可视化hdfs资源</h3><p>使用命令行操作可能会觉得不清晰，于是hadoop为我们提供了可视化操作：我们进入hadoop/sbin目录下输入start-yarn命令回车，然后访问<a href="http://127.0.0.1:8088">http://127.0.0.1:8088</a>就可以可视化的查看资源以及进行节点管理的操作。<br><img src="https://static.oschina.net/uploads/space/2017/1113/131214_Dhmq_2846946.png" alt=""><br>其他web管理界面地址：<br>| NameNode | <a href="http://127.0.0.1:50070/">http://127.0.0.1:50070/</a> | 默认 HTTP 端口为 50070. |<br>| ResourceManager | <a href="http://127.0.0.1:8088/">http://127.0.0.1:8088/</a> | 默认 HTTP端口为 8088 |<br>| MapReduce JobHistory Server | <a href="http://127.0.0.1:19888/">http://127.0.0.1:19888/</a> | 默认 HTTP 端口为 19888 |</p>]]></content>
    
    <summary type="html">
    
      Hadoop(01)Windows平台下Hadoop环境搭建
    
    </summary>
    
    
      <category term="学大数据" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="分布式文件系统" scheme="https://www.maxbill.cn/marks/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="Hadoop" scheme="https://www.maxbill.cn/marks/Hadoop/"/>
    
      <category term="Hdfs" scheme="https://www.maxbill.cn/marks/Hdfs/"/>
    
      <category term="大数据" scheme="https://www.maxbill.cn/marks/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot(11)注册使用Interceptor的方式</title>
    <link href="https://www.maxbill.cn/2104243669.html"/>
    <id>https://www.maxbill.cn/2104243669.html</id>
    <published>2017-07-07T02:57:15.000Z</published>
    <updated>2020-07-04T12:58:29.659Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>前面说了SpringBoot中使用servlet、过滤器（filter）、监听器（Listener），还有在web应用中使用比较多的是拦截器Interceptor，像之前的Strutrs2框架实现的核心就是一套套的拦截器，那么springBoot项目中怎么使用自定义的拦截器呢？</p><h2 id="编写自定义拦截器实现HandlerInterceptor接口"><a href="#编写自定义拦截器实现HandlerInterceptor接口" class="headerlink" title="编写自定义拦截器实现HandlerInterceptor接口"></a>编写自定义拦截器实现HandlerInterceptor接口</h2><p>自定义拦截器1：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.maxbill.core.webbox.interceptor;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.web.servlet.HandlerInterceptor;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.servlet.ModelAndView;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletRequest;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletResponse;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * @功能 自定义拦截器</span></span><br><span class="line"><span class="comment"> * @作者 zuoshuai(MaxBill)</span></span><br><span class="line"><span class="comment"> * @日期 2017/7/6</span></span><br><span class="line"><span class="comment"> * @时间 15:42</span></span><br><span class="line"><span class="comment"> * @备注 只有经过DispatcherServlet的请求，才会走拦截器链，我们自定义的Servlet请求是不会被拦截的;Servlet只要符合过滤器的过滤规则，过滤器都会过滤。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Interceptor01</span> <span class="keyword">implements</span> <span class="title">HandlerInterceptor</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 在请求处理之前进行调用（Controller方法调用之前）</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">preHandle</span><span class="params">(HttpServletRequest request, HttpServletResponse response, Object handler)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;&gt;&gt;&gt;Interceptor01&gt;&gt;&gt;&gt;&gt;&gt;&gt;在请求处理之前进行调用&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;<span class="comment">// 只有返回true才会继续向下执行，返回false取消当前请求</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 请求处理之后进行调用，但是在视图被渲染之前（Controller方法调用之后）</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">postHandle</span><span class="params">(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;&gt;&gt;&gt;Interceptor01&gt;&gt;&gt;&gt;&gt;&gt;&gt;请求处理之后进行调用&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 在整个请求结束之后被调用，也就是在DispatcherServlet 渲染了对应的视图之后执行</span></span><br><span class="line"><span class="comment">     *（主要是用于进行资源清理工作）</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">afterCompletion</span><span class="params">(HttpServletRequest request, HttpServletResponse response,  Object handler, Exception ex)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;&gt;&gt;&gt;Interceptor01&gt;&gt;&gt;&gt;&gt;&gt;&gt;在整个请求结束之后被调用&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>自定义拦截器2：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.maxbill.core.webbox.interceptor;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.web.servlet.HandlerInterceptor;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.servlet.ModelAndView;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletRequest;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletResponse;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * @功能 自定义拦截器</span></span><br><span class="line"><span class="comment"> * @作者 zuoshuai(MaxBill)</span></span><br><span class="line"><span class="comment"> * @日期 2017/7/6</span></span><br><span class="line"><span class="comment"> * @时间 15:42</span></span><br><span class="line"><span class="comment"> * @备注 只有经过DispatcherServlet的请求，才会走拦截器链，我们自定义的Servlet请求是不会被拦截的;Servlet只要符合过滤器的过滤规则，过滤器都会过滤。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Interceptor02</span> <span class="keyword">implements</span> <span class="title">HandlerInterceptor</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 在请求处理之前进行调用（Controller方法调用之前）</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">preHandle</span><span class="params">(HttpServletRequest request, HttpServletResponse response, Object handler)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;&gt;&gt;&gt;Interceptor02&gt;&gt;&gt;&gt;&gt;&gt;&gt;在请求处理之前进行调用&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;<span class="comment">// 只有返回true才会继续向下执行，返回false取消当前请求</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 请求处理之后进行调用，但是在视图被渲染之前（Controller方法调用之后）</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">postHandle</span><span class="params">(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;&gt;&gt;&gt;Interceptor02&gt;&gt;&gt;&gt;&gt;&gt;&gt;请求处理之后进行调用&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 在整个请求结束之后被调用，也就是在DispatcherServlet 渲染了对应的视图之后执行（主要是用于进行资源清理工作）</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">afterCompletion</span><span class="params">(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex)</span></span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;&gt;&gt;&gt;Interceptor02&gt;&gt;&gt;&gt;&gt;&gt;&gt;在整个请求结束之后被调用&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="编写WebMvcConfig配置类继承WebMvcConfigurerAdapter"><a href="#编写WebMvcConfig配置类继承WebMvcConfigurerAdapter" class="headerlink" title="编写WebMvcConfig配置类继承WebMvcConfigurerAdapter"></a>编写WebMvcConfig配置类继承WebMvcConfigurerAdapter</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.maxbill.core.config.webapp;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.maxbill.core.webbox.interceptor.Interceptor01;</span><br><span class="line"><span class="keyword">import</span> com.maxbill.core.webbox.interceptor.Interceptor02;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.servlet.config.annotation.InterceptorRegistry;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * @功能</span></span><br><span class="line"><span class="comment"> * @作者 zuoshuai(MaxBill)</span></span><br><span class="line"><span class="comment"> * @日期 2017/7/6</span></span><br><span class="line"><span class="comment"> * @时间 15:40</span></span><br><span class="line"><span class="comment"> * @备注 WebMvcConfig</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WebMvcConfig</span> <span class="keyword">extends</span> <span class="title">WebMvcConfigurerAdapter</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 拦截器注册</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addInterceptors</span><span class="params">(InterceptorRegistry registry)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 多个拦截器组成一个拦截器链</span></span><br><span class="line">        <span class="comment">// addPathPatterns 用于添加拦截规则</span></span><br><span class="line">        <span class="comment">// excludePathPatterns 用户排除拦截</span></span><br><span class="line">        registry.addInterceptor(<span class="keyword">new</span> Interceptor01()).addPathPatterns(<span class="string">&quot;/**&quot;</span>);</span><br><span class="line">        registry.addInterceptor(<span class="keyword">new</span> Interceptor02()).addPathPatterns(<span class="string">&quot;/**&quot;</span>);</span><br><span class="line">        <span class="keyword">super</span>.addInterceptors(registry);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="启动项目查看拦截器作用"><a href="#启动项目查看拦截器作用" class="headerlink" title="启动项目查看拦截器作用"></a>启动项目查看拦截器作用</h2><p>打印日志如下：</p><blockquote><blockquote><blockquote><p>Interceptor01&gt;&gt;&gt;&gt;&gt;&gt;&gt;在请求处理之前进行调用<br>Interceptor02&gt;&gt;&gt;&gt;&gt;&gt;&gt;在请求处理之前进行调用<br>Interceptor02&gt;&gt;&gt;&gt;&gt;&gt;&gt;请求处理之后进行调用<br>Interceptor01&gt;&gt;&gt;&gt;&gt;&gt;&gt;请求处理之后进行调用<br>Interceptor02&gt;&gt;&gt;&gt;&gt;&gt;&gt;在整个请求结束之后被调用<br>Interceptor01&gt;&gt;&gt;&gt;&gt;&gt;&gt;在整个请求结束之后被调用</p></blockquote></blockquote></blockquote><h2 id="拦截器疑点说明"><a href="#拦截器疑点说明" class="headerlink" title="拦截器疑点说明"></a>拦截器疑点说明</h2><p>启动项目后，请求昨天编写的servlet，结果发现并没有走我们的拦截器，而是走了我们昨天的过滤器，于是可以得出结论：只有经过DispatcherServlet分发的请求，才会走拦截器链；我们自定义的Servlet请求是不会被拦截的;我们的Servlet只要符合过滤器的过滤规则，过滤器都会过滤。</p>]]></content>
    
    <summary type="html">
    
      SpringBoot(11)注册使用Interceptor的方式
    
    </summary>
    
    
      <category term="学微服务" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="Java" scheme="https://www.maxbill.cn/marks/Java/"/>
    
      <category term="SpringBoot" scheme="https://www.maxbill.cn/marks/SpringBoot/"/>
    
      <category term="微服务" scheme="https://www.maxbill.cn/marks/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="Interceptor" scheme="https://www.maxbill.cn/marks/Interceptor/"/>
    
      <category term="拦截器" scheme="https://www.maxbill.cn/marks/%E6%8B%A6%E6%88%AA%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot(10)注册使用Listener的方式</title>
    <link href="https://www.maxbill.cn/1706776590.html"/>
    <id>https://www.maxbill.cn/1706776590.html</id>
    <published>2017-07-06T14:31:35.000Z</published>
    <updated>2020-07-04T12:58:29.656Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>前面都说到了springboot中应用servlet和filter，本文继续说springboot应用监听器Listener，大体上是和之前差不多的应用。</p><h2 id="实现HttpSessionListener接口"><a href="#实现HttpSessionListener接口" class="headerlink" title="实现HttpSessionListener接口"></a>实现HttpSessionListener接口</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.maxbill.core.webbox.listener;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * @功能</span></span><br><span class="line"><span class="comment"> * @作者 zuoshuai(MaxBill)</span></span><br><span class="line"><span class="comment"> * @日期 2017/7/6</span></span><br><span class="line"><span class="comment"> * @时间 15:27</span></span><br><span class="line"><span class="comment"> * @备注 MyHttpSessionListener</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.Logger;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.servlet.annotation.WebListener;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpSessionEvent;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpSessionListener;</span><br><span class="line"></span><br><span class="line"><span class="meta">@WebListener</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyHttpSessionListener</span> <span class="keyword">implements</span> <span class="title">HttpSessionListener</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    Logger log = Logger.getLogger(MyServletContextListener.class);</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sessionCreated</span><span class="params">(HttpSessionEvent se)</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;session被创建&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sessionDestroyed</span><span class="params">(HttpSessionEvent se)</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;session被销毁&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="实现ServletContextListener接口"><a href="#实现ServletContextListener接口" class="headerlink" title="实现ServletContextListener接口"></a>实现ServletContextListener接口</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.maxbill.core.webbox.listener;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.maxbill.core.webbox.filter.MyFilter;</span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.Logger;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.servlet.ServletContextEvent;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.ServletContextListener;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.annotation.WebListener;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * @功能 自定义监听器</span></span><br><span class="line"><span class="comment"> * @作者 zuoshuai(MaxBill)</span></span><br><span class="line"><span class="comment"> * @日期 2017/7/6</span></span><br><span class="line"><span class="comment"> * @时间 15:24</span></span><br><span class="line"><span class="comment"> * @备注 MyServletContextListener</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@WebListener</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyServletContextListener</span> <span class="keyword">implements</span> <span class="title">ServletContextListener</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    Logger log = Logger.getLogger(MyServletContextListener.class);</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">contextInitialized</span><span class="params">(ServletContextEvent arg)</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;ServletContex初始化&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">contextDestroyed</span><span class="params">(ServletContextEvent arg)</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;ServletContex销毁&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="增加注解"><a href="#增加注解" class="headerlink" title="增加注解"></a>增加注解</h2><p>1.在监听器上增加@WebListener</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@WebListener</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyHttpSessionListener</span> <span class="keyword">implements</span> <span class="title">HttpSessionListener</span> </span>&#123;...&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@WebListener</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyServletContextListener</span> <span class="keyword">implements</span> <span class="title">ServletContextListener</span> </span>&#123;...&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>2.然后在启动类中增加@ServletComponentScan，使项目中的Listener能够被扫描到</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.maxbill;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.SpringApplication;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.autoconfigure.SpringBootApplication;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.web.servlet.ServletComponentScan;</span><br><span class="line"></span><br><span class="line"><span class="meta">@ServletComponentScan</span></span><br><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MaxbillApplication</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String\[\] args)</span> </span>&#123;</span><br><span class="line">        SpringApplication.run(MaxbillApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>启动项目测试：<br>INFO com.maxbill.core.webbox.listener.MyServletContextListener:24 - &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;ServletContex初始化&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;</p>]]></content>
    
    <summary type="html">
    
      SpringBoot(10)注册使用Listener的方式
    
    </summary>
    
    
      <category term="学微服务" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="Java" scheme="https://www.maxbill.cn/marks/Java/"/>
    
      <category term="SpringBoot" scheme="https://www.maxbill.cn/marks/SpringBoot/"/>
    
      <category term="微服务" scheme="https://www.maxbill.cn/marks/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="Listener" scheme="https://www.maxbill.cn/marks/Listener/"/>
    
      <category term="监听器" scheme="https://www.maxbill.cn/marks/%E7%9B%91%E5%90%AC%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot(09)注册使用Filter的方式</title>
    <link href="https://www.maxbill.cn/2924577983.html"/>
    <id>https://www.maxbill.cn/2924577983.html</id>
    <published>2017-07-06T14:18:23.000Z</published>
    <updated>2020-07-04T12:58:29.656Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>上篇文章中说了SpringBoot中是如何使用servlet的，本文将讲解在SpringBoot中对过滤器Filter的实现</p><h2 id="编写MyFilter实现Filter接口"><a href="#编写MyFilter实现Filter接口" class="headerlink" title="编写MyFilter实现Filter接口"></a>编写MyFilter实现Filter接口</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.maxbill.core.webbox.filter;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.Logger;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.servlet.*;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.annotation.WebFilter;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * @功能 自定义过滤器</span></span><br><span class="line"><span class="comment"> * @作者 zuoshuai(MaxBill)</span></span><br><span class="line"><span class="comment"> * @日期 2017/7/6</span></span><br><span class="line"><span class="comment"> * @时间 15:18</span></span><br><span class="line"><span class="comment"> * @备注 MyFilter</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyFilter</span> <span class="keyword">implements</span> <span class="title">Filter</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    Logger log = Logger.getLogger(MyFilter.class);</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">(FilterConfig config)</span> <span class="keyword">throws</span> ServletException </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;过滤器初始化&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doFilter</span><span class="params">(ServletRequest request, ServletResponse response, FilterChain chain)</span> </span></span><br><span class="line"><span class="function">           <span class="keyword">throws</span> IOException, ServletException </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;执行过滤操作&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&quot;</span>);</span><br><span class="line">        chain.doFilter(request, response);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">destroy</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;过滤器销毁&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="增加注解"><a href="#增加注解" class="headerlink" title="增加注解"></a>增加注解</h2><p>1.过滤器增加@WebFilter注解，使能够被扫描到</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@WebFilter(filterName = &quot;myFilter&quot;, urlPatterns = &quot;/*&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyFilter</span> <span class="keyword">implements</span> <span class="title">Filter</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    Logger log = Logger.getLogger(MyFilter.class);</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">(FilterConfig config)</span> <span class="keyword">throws</span> ServletException </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;过滤器初始化&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doFilter</span><span class="params">(ServletRequest request, ServletResponse response, FilterChain chain)</span> </span></span><br><span class="line"><span class="function">           <span class="keyword">throws</span> IOException, ServletException </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;执行过滤操作&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&quot;</span>);</span><br><span class="line">        chain.doFilter(request, response);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">destroy</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;过滤器销毁&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>2.启动类增加@ServletComponentScan注解，扫描项目中的filter</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.maxbill;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.SpringApplication;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.autoconfigure.SpringBootApplication;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.web.servlet.ServletComponentScan;</span><br><span class="line"></span><br><span class="line"><span class="meta">@ServletComponentScan</span></span><br><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MaxbillApplication</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String\[\] args)</span> </span>&#123;</span><br><span class="line">        SpringApplication.run(MaxbillApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>启动项目测试：<br>INFO com.maxbill.core.webbox.filter.MyFilter:23 - &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;过滤器初始化&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>INFO com.maxbill.core.webbox.filter.MyFilter:29 - &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;执行过滤操作&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;</p>]]></content>
    
    <summary type="html">
    
      SpringBoot(09)注册使用Filter的方式
    
    </summary>
    
    
      <category term="学微服务" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="Java" scheme="https://www.maxbill.cn/marks/Java/"/>
    
      <category term="SpringBoot" scheme="https://www.maxbill.cn/marks/SpringBoot/"/>
    
      <category term="微服务" scheme="https://www.maxbill.cn/marks/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="Filter" scheme="https://www.maxbill.cn/marks/Filter/"/>
    
      <category term="过滤器" scheme="https://www.maxbill.cn/marks/%E8%BF%87%E6%BB%A4%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot(08)注册使用Servlet的方式</title>
    <link href="https://www.maxbill.cn/3330870275.html"/>
    <id>https://www.maxbill.cn/3330870275.html</id>
    <published>2017-07-06T14:03:19.000Z</published>
    <updated>2020-07-04T12:58:29.661Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在web应用中Servlet的应用比较多，最开始的web应用就是全部以servlet来实现的，后来出现了Struts、Struts2，到今天应用非常广泛的SpringMvc，这些web mvc框架比原来的servlet功能更加强大，开发效率而更高，但是实际上这些框架底层都是servlet在做支撑。今天我们学习如何在SpringBoot添加Servlet的应用。</p><h2 id="编写Servlet继承HttpServlet"><a href="#编写Servlet继承HttpServlet" class="headerlink" title="编写Servlet继承HttpServlet"></a>编写Servlet继承HttpServlet</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.maxbill.core.webbox.servlet;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.Logger;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.servlet.ServletException;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.annotation.WebServlet;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServlet;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletRequest;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletResponse;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * @功能 自定义servlet</span></span><br><span class="line"><span class="comment"> * @作者 zuoshuai(MaxBill)</span></span><br><span class="line"><span class="comment"> * @日期 2017/7/6</span></span><br><span class="line"><span class="comment"> * @时间 14:57</span></span><br><span class="line"><span class="comment"> * @备注 MyServlet</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyServlet</span> <span class="keyword">extends</span> <span class="title">HttpServlet</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    Logger log = Logger.getLogger(MyServlet.class);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">doGet</span><span class="params">(HttpServletRequest request, HttpServletResponse response)</span> </span></span><br><span class="line"><span class="function">              <span class="keyword">throws</span> ServletException, IOException </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;servlet通过get方式请求完成...&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里只实现了doGet请求，post、put等请求同理实现即可。</p><h2 id="注册servlet到启动类"><a href="#注册servlet到启动类" class="headerlink" title="注册servlet到启动类"></a>注册servlet到启动类</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.maxbill;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.maxbill.core.webbox.servlet.MyServlet;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.SpringApplication;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.autoconfigure.SpringBootApplication;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.web.servlet.ServletRegistrationBean;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Bean;</span><br><span class="line"></span><br><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MaxbillApplication</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 注册Servlet</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ServletRegistrationBean <span class="title">MyServlet1</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ServletRegistrationBean(<span class="keyword">new</span> MyServlet(),<span class="string">&quot;/servlet/*&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SpringApplication.run(MaxbillApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="使用注解注册servlet"><a href="#使用注解注册servlet" class="headerlink" title="使用注解注册servlet"></a>使用注解注册servlet</h2><p>首先在servlet上增加@WebServlet</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@WebServlet(urlPatterns = &quot;/servlet/*&quot;, description = &quot;&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyServlet</span> <span class="keyword">extends</span> <span class="title">HttpServlet</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    Logger log = Logger.getLogger(MyServlet.class);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">doGet</span><span class="params">(HttpServletRequest request, HttpServletResponse response)</span> <span class="keyword">throws</span> ServletException, IOException </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;servlet通过get方式请求完成...&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后在启动类中增加@ServletComponentScan，使项目中的servlet能够被扫描到</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.maxbill;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.SpringApplication;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.autoconfigure.SpringBootApplication;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.web.servlet.ServletComponentScan;</span><br><span class="line"></span><br><span class="line"><span class="meta">@ServletComponentScan</span></span><br><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MaxbillApplication</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String\[\] args)</span> </span>&#123;</span><br><span class="line">        SpringApplication.run(MaxbillApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>启动项目测试：访问<a href="http://127.0.0.1:520/servlet">http://127.0.0.1:520/servlet</a><br>控制台日志：INFO com.maxbill.core.webbox.servlet.MyServlet:25 - servlet通过get方式请求完成…</p>]]></content>
    
    <summary type="html">
    
      SpringBoot(08)注册使用Servlet的方式
    
    </summary>
    
    
      <category term="学微服务" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="Java" scheme="https://www.maxbill.cn/marks/Java/"/>
    
      <category term="SpringBoot" scheme="https://www.maxbill.cn/marks/SpringBoot/"/>
    
      <category term="微服务" scheme="https://www.maxbill.cn/marks/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="Servlet" scheme="https://www.maxbill.cn/marks/Servlet/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot(07)集成使用阿里Druid数据源</title>
    <link href="https://www.maxbill.cn/3554664425.html"/>
    <id>https://www.maxbill.cn/3554664425.html</id>
    <published>2017-07-06T13:32:12.000Z</published>
    <updated>2020-07-04T12:58:29.656Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>SpringBoot默认链接数据库的数据源是：org.apache.tomcat.jdbc.pool.DataSource，如果我们想换成阿里的Druid数据源，应该怎么集成呢？</p><h2 id="Druid数据源依赖引入"><a href="#Druid数据源依赖引入" class="headerlink" title="Druid数据源依赖引入"></a>Druid数据源依赖引入</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--druid数据源--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>druid<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>注意：好多同学在这里应用了上面这个包，在sql监控页面上看不到SQL执行的记录等相关数据，这里我们必须引入下面的springboot的依赖包，然后重新编译启动项目，此时在进行sql操作后去再去sql监控页面，就可以看到druid监控SQL执行的记录等相关数据了。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--druid数据源--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>druid-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>提示：虽然引入第一个包对于正常使用durid连接池功能上没问题，但是在druid的监控功能上会有些功能异常，比如sql监控功能</p><h2 id="Druid数据源配置文件"><a href="#Druid数据源配置文件" class="headerlink" title="Druid数据源配置文件"></a>Druid数据源配置文件</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">spring.datasource.type=com.alibaba.druid.pool.DruidDataSource</span><br><span class="line">spring.datasource.url=jdbc:mysql://localhost:3306/boot</span><br><span class="line">spring.datasource.username=root</span><br><span class="line">spring.datasource.password=admin</span><br><span class="line"># 下面为连接池的补充设置，应用到上面所有数据源中</span><br><span class="line"># 初始化大小，最小，最大</span><br><span class="line">spring.datasource.initialSize=5</span><br><span class="line">spring.datasource.minIdle=5</span><br><span class="line">spring.datasource.maxActive=20</span><br><span class="line"># 配置获取连接等待超时的时间</span><br><span class="line">spring.datasource.maxWait=60000</span><br><span class="line"># 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒</span><br><span class="line">spring.datasource.timeBetweenEvictionRunsMillis=60000</span><br><span class="line"># 配置一个连接在池中最小生存的时间，单位是毫秒</span><br><span class="line">spring.datasource.minEvictableIdleTimeMillis=300000</span><br><span class="line">spring.datasource.validationQuery=SELECT 1 FROM DUAL</span><br><span class="line">spring.datasource.testWhileIdle=true</span><br><span class="line">spring.datasource.testOnBorrow=false</span><br><span class="line">spring.datasource.testOnReturn=false</span><br><span class="line"># 打开PSCache，并且指定每个连接上PSCache的大小</span><br><span class="line">spring.datasource.poolPreparedStatements=true</span><br><span class="line">spring.datasource.maxPoolPreparedStatementPerConnectionSize=20</span><br><span class="line"># 配置监控统计拦截的filters，去掉后监控界面sql无法统计，&#x27;wall&#x27;用于防火墙</span><br><span class="line">spring.datasource.filters=stat,wall,log4j</span><br><span class="line"># 通过connectProperties属性来打开mergeSql功能；慢SQL记录</span><br><span class="line">spring.datasource.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000</span><br><span class="line"># 合并多个DruidDataSource的监控数据</span><br><span class="line">#spring.datasource.useGlobalDataSourceStat=true</span><br></pre></td></tr></table></figure><h2 id="Druid数据源监控统计配置"><a href="#Druid数据源监控统计配置" class="headerlink" title="Druid数据源监控统计配置"></a>Druid数据源监控统计配置</h2><p>在程序中编写一个配置类，并且添加@Configuration注解，使能够被扫描到。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.maxbill.core.config.datasource;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.druid.support.http.StatViewServlet;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.druid.support.http.WebStatFilter;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.web.servlet.FilterRegistrationBean;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.web.servlet.ServletRegistrationBean;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Bean;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Configuration;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * @功能 阿里druid数据源配置</span></span><br><span class="line"><span class="comment"> * @作者 zuoshuai(MaxBill)</span></span><br><span class="line"><span class="comment"> * @日期 2017/7/6</span></span><br><span class="line"><span class="comment"> * @时间 13:50</span></span><br><span class="line"><span class="comment"> * @备注 DruidConfig</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DruidConfig</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 注册DruidStatViewServle1</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ServletRegistrationBean <span class="title">DruidStatViewServle1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">//org.springframework.boot.context.embedded.ServletRegistrationBean提供类的进行注册.</span></span><br><span class="line">        ServletRegistrationBean servletRegistrationBean = <span class="keyword">new</span> ServletRegistrationBean(<span class="keyword">new</span> StatViewServlet(), <span class="string">&quot;/druid/*&quot;</span>);</span><br><span class="line">        <span class="comment">//Ip白名单</span></span><br><span class="line">        servletRegistrationBean.addInitParameter(<span class="string">&quot;allow&quot;</span>, <span class="string">&quot;127.0.0.1&quot;</span>);</span><br><span class="line">        <span class="comment">//IP黑名单(存在共同时，deny优先于allow)</span></span><br><span class="line">        servletRegistrationBean.addInitParameter(<span class="string">&quot;deny&quot;</span>, <span class="string">&quot;192.168.1.1&quot;</span>);</span><br><span class="line">        <span class="comment">//登录查看信息的账号密码</span></span><br><span class="line">        servletRegistrationBean.addInitParameter(<span class="string">&quot;loginUsername&quot;</span>, <span class="string">&quot;admin&quot;</span>);</span><br><span class="line">        servletRegistrationBean.addInitParameter(<span class="string">&quot;loginPassword&quot;</span>, <span class="string">&quot;123456&quot;</span>);</span><br><span class="line">        <span class="comment">//是否能够重置数据</span></span><br><span class="line">        servletRegistrationBean.addInitParameter(<span class="string">&quot;resetEnable&quot;</span>, <span class="string">&quot;false&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> servletRegistrationBean;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 注册druidStatFilter</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> FilterRegistrationBean <span class="title">druidStatFilter</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        FilterRegistrationBean filterRegistrationBean = <span class="keyword">new</span> FilterRegistrationBean(<span class="keyword">new</span> WebStatFilter());</span><br><span class="line">        <span class="comment">//添加过滤规则</span></span><br><span class="line">        filterRegistrationBean.addUrlPatterns(<span class="string">&quot;/*&quot;</span>);</span><br><span class="line">        <span class="comment">//添加不需要忽略的格式信息.</span></span><br><span class="line">        filterRegistrationBean.addInitParameter(<span class="string">&quot;exclusions&quot;</span>, <span class="string">&quot;*.js,*.gif,*.jpg,*.png,*.css,/druid/*&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> filterRegistrationBean;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>配置完成后，<a href="http://127.0.0.1:8080/druid2/index.html">http://127.0.0.1:8080/druid/index.html</a>即可打开监控登陆页面，登陆成功即可查看数据源的各种监控，sql监控和统计信息<br>注：还有一种方式是将配置文件的信息直接在硬编码在程序中，如果配置文件个代码中都做了配置，程序中的优先级高，配置文件中的失效。个人推荐在配置文件中配置，不在程序中硬编码。在程序中配置的方式(在上面的配置类注入数据源即可)如下:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 注册dataSouce,推荐在配置文件中</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> DataSource <span class="title">druidDataSource</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    DruidDataSource druidDataSource = <span class="keyword">new</span> DruidDataSource();</span><br><span class="line">    druidDataSource.setDriverClassName(<span class="string">&quot;&quot;</span>);</span><br><span class="line">    druidDataSource.setUrl(<span class="string">&quot;&quot;</span>);</span><br><span class="line">    druidDataSource.setUsername(<span class="string">&quot;&quot;</span>);</span><br><span class="line">    druidDataSource.setPassword(<span class="string">&quot;&quot;</span>);</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        druidDataSource.setFilters(<span class="string">&quot;stat, wall&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (SQLException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> druidDataSource;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      SpringBoot(07)集成使用阿里Druid数据源
    
    </summary>
    
    
      <category term="学微服务" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="Java" scheme="https://www.maxbill.cn/marks/Java/"/>
    
      <category term="SpringBoot" scheme="https://www.maxbill.cn/marks/SpringBoot/"/>
    
      <category term="微服务" scheme="https://www.maxbill.cn/marks/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="Druid" scheme="https://www.maxbill.cn/marks/Druid/"/>
    
      <category term="数据源" scheme="https://www.maxbill.cn/marks/%E6%95%B0%E6%8D%AE%E6%BA%90/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot(06)替换默认的Jackson解析器</title>
    <link href="https://www.maxbill.cn/4171038220.html"/>
    <id>https://www.maxbill.cn/4171038220.html</id>
    <published>2017-07-06T04:52:09.000Z</published>
    <updated>2020-07-04T12:58:29.656Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>SpringBoot和Springmvc都可以返回接送数据，SpringBoot默认是使用Jackson解析json数据的，个人觉得阿里的Fastjson性能更好点，API使用更方便，于是将SpringBoot默认的Jackson替换成阿里的Fastjson。</p><h2 id="配置类注入的方式"><a href="#配置类注入的方式" class="headerlink" title="配置类注入的方式"></a>配置类注入的方式</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.maxbill.core.config.json;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.serializer.SerializerFeature;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.support.config.FastJsonConfig;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.support.spring.FastJsonHttpMessageConverter;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.autoconfigure.web.HttpMessageConverters;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Bean;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.springframework.http.converter.HttpMessageConverter;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * @功能 JSON解析器配置</span></span><br><span class="line"><span class="comment"> * @作者 zuoshuai(MaxBill)</span></span><br><span class="line"><span class="comment"> * @日期 2017/7/6</span></span><br><span class="line"><span class="comment"> * @时间 12:24</span></span><br><span class="line"><span class="comment"> * @备注 替换默认的json框架，替换成阿里的fastjson</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JsonConfig</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> HttpMessageConverters <span class="title">fastJsonHttpMessageConverters</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        FastJsonHttpMessageConverter fastConverter = <span class="keyword">new</span> FastJsonHttpMessageConverter();</span><br><span class="line">        FastJsonConfig fastJsonConfig = <span class="keyword">new</span> FastJsonConfig();</span><br><span class="line">        fastJsonConfig.setSerializerFeatures(SerializerFeature.PrettyFormat);</span><br><span class="line">        fastConverter.setFastJsonConfig(fastJsonConfig);</span><br><span class="line">        HttpMessageConverter&lt;?&gt; converter = fastConverter;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> HttpMessageConverters(converter);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="配置类继承WebMvcConfigurerAdapter覆盖方法"><a href="#配置类继承WebMvcConfigurerAdapter覆盖方法" class="headerlink" title="配置类继承WebMvcConfigurerAdapter覆盖方法"></a>配置类继承WebMvcConfigurerAdapter覆盖方法</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.maxbill.core.config.json;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.serializer.SerializerFeature;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.support.config.FastJsonConfig;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.support.spring.FastJsonHttpMessageConverter;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.springframework.http.converter.HttpMessageConverter;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * @功能 JSON解析器配置</span></span><br><span class="line"><span class="comment"> * @作者 zuoshuai(MaxBill)</span></span><br><span class="line"><span class="comment"> * @日期 2017/7/6</span></span><br><span class="line"><span class="comment"> * @时间 12:35</span></span><br><span class="line"><span class="comment"> * @备注 替换默认的json框架，替换成阿里的fastjson</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JsonConfigBack</span> <span class="keyword">extends</span> <span class="title">WebMvcConfigurerAdapter</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configureMessageConverters</span><span class="params">(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.configureMessageConverters(converters);</span><br><span class="line">        FastJsonHttpMessageConverter fastConverter = <span class="keyword">new</span> FastJsonHttpMessageConverter();</span><br><span class="line">        FastJsonConfig fastJsonConfig = <span class="keyword">new</span> FastJsonConfig();</span><br><span class="line">        fastJsonConfig.setSerializerFeatures(SerializerFeature.PrettyFormat);</span><br><span class="line">        fastConverter.setFastJsonConfig(fastJsonConfig);</span><br><span class="line">        converters.add(fastConverter);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意：记得引入Fastjson的依赖包；在1.2.10版本以后有两个方法支持HttpMessageconvert了<br>一：FastJsonHttpMessageConverter，支持4.2以下的版本；<br>二：FastJsonHttpMessageConverter4支持4.2以上的版本。<br>所以Fastjson需要在1.2.10版本以上。</p>]]></content>
    
    <summary type="html">
    
      SpringBoot(06)替换默认的Jackson解析器
    
    </summary>
    
    
      <category term="学微服务" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="Java" scheme="https://www.maxbill.cn/marks/Java/"/>
    
      <category term="SpringBoot" scheme="https://www.maxbill.cn/marks/SpringBoot/"/>
    
      <category term="微服务" scheme="https://www.maxbill.cn/marks/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="Jackson" scheme="https://www.maxbill.cn/marks/Jackson/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot(05)集成使用PageHelper分页插件</title>
    <link href="https://www.maxbill.cn/1907517959.html"/>
    <id>https://www.maxbill.cn/1907517959.html</id>
    <published>2017-03-23T05:52:09.000Z</published>
    <updated>2020-07-04T12:58:29.656Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>前文说了Spring Boot集成持久层框架Mybatis的过程，和使用mybatis进行对数据库进行CRUD的操作，然而当对多数据进行查询时就需要进行分页了，分页技术分为客户端分页和服务器端分页（数据库分页），客户端分页是前端的数据插件对返回的数据集进行分页（bootstrup table、qui table等），客户端分页会对数据库和客户端都造成一定的性能压力，所以一般都是进行服务器分页。今天我们在Spring Boot 中集成比较好用的分页插件pagehelper，很简单的就实现了数据页。<br>注意：pagehelper是需要配合着Mybatis的拦截器实现的</p><h2 id="pagehelper分页插件简介"><a href="#pagehelper分页插件简介" class="headerlink" title="pagehelper分页插件简介"></a>pagehelper分页插件简介</h2><p>使用pagehelper插件可以很好的结合MyBatis进行分页查询，该分页插件支持任何复杂的单表、多表分页。目前支持如下数据库：</p><ol><li><code>Oracle</code></li><li><code>Mysql</code></li><li><code>MariaDB</code></li><li><code>SQLite</code></li><li><code>Hsqldb</code></li><li><code>PostgreSQL</code></li><li><code>DB2</code></li><li><code>SqlServer(2005,2008)</code></li><li><code>Informix</code></li><li><code>H2</code></li><li><code>SqlServer2012</code></li><li><code>Derby</code></li></ol><p>该插件是github上的开源项目，感兴趣的可以去看源码，该项目的github地址是：<br><a href="https://github.com/pagehelper/Mybatis-PageHelper">https://github.com/pagehelper/Mybatis-PageHelper</a><br><a href="https://github.com/pagehelper/Mybatis-PageHelper">https://github.com/pagehelper/pagehelper-spring-boot</a></p><h2 id="引入pagehelper分页插件的依赖"><a href="#引入pagehelper分页插件的依赖" class="headerlink" title="引入pagehelper分页插件的依赖"></a>引入pagehelper分页插件的依赖</h2><p>使用该插件在pom文件引入依赖即可：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.github.pagehelper<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>pagehelper<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.1.6<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>springboot中推荐使用启动器依赖</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.github.pagehelper<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>pagehelper-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span>_</span><br></pre></td></tr></table></figure><h2 id="在mybaits配置对改插件的拦截器"><a href="#在mybaits配置对改插件的拦截器" class="headerlink" title="在mybaits配置对改插件的拦截器"></a>在mybaits配置对改插件的拦截器</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@func</span> mybatis配置信息</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@user</span> MaxBill（zuishuai）</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2017-03-06</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MybatisConfig</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> SqlSessionFactory <span class="title">sqlSessionFactory</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        SqlSessionFactoryBean sqlSessionFactory = <span class="keyword">new</span> SqlSessionFactoryBean();</span><br><span class="line">        sqlSessionFactory.setDataSource(dataSource());</span><br><span class="line">        sqlSessionFactory.setFailFast(<span class="keyword">true</span>);</span><br><span class="line">        <span class="comment">// 分页插件</span></span><br><span class="line">        PageHelper pageHelper = <span class="keyword">new</span> PageHelper();</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        properties.setProperty(<span class="string">&quot;dialect&quot;</span>, <span class="string">&quot;mysql&quot;</span>);</span><br><span class="line">        properties.setProperty(<span class="string">&quot;offsetAsPageNum&quot;</span>, <span class="string">&quot;true&quot;</span>);</span><br><span class="line">        properties.setProperty(<span class="string">&quot;rowBoundsWithCount&quot;</span>, <span class="string">&quot;true&quot;</span>);</span><br><span class="line">        properties.setProperty(<span class="string">&quot;pageSizeZero&quot;</span>, <span class="string">&quot;true&quot;</span>);</span><br><span class="line">        properties.setProperty(<span class="string">&quot;reasonable&quot;</span>, <span class="string">&quot;true&quot;</span>);</span><br><span class="line">        pageHelper.setProperties(properties);</span><br><span class="line">        <span class="comment">// 添加插件</span></span><br><span class="line">        sqlSessionFactory.setPlugins(<span class="keyword">new</span> Interceptor[]&#123;pageHelper&#125;);</span><br><span class="line">        <span class="keyword">return</span> sqlSessionFactory.getObject();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> DataSourceTransactionManager <span class="title">transactionManager</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> DataSourceTransactionManager(dataSource());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@PostConstruct</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">postConstruct</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上就实现了该插件了mybatis的集成（使用了mybatis的拦截器）</p><h2 id="插件的使用方式"><a href="#插件的使用方式" class="headerlink" title="插件的使用方式"></a>插件的使用方式</h2><p>PageHelper只对紧跟着的第一个SQL语句起作用</p><h3 id="统计总数"><a href="#统计总数" class="headerlink" title="统计总数"></a>统计总数</h3><p>将SQL语句变为 select count(0) from xxx,只对简单SQL语句其效果，复杂SQL语句需要自己写</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Page&lt;?&gt; page = PageHelper.startPage(<span class="number">1</span>,-<span class="number">1</span>);</span><br><span class="line"><span class="keyword">long</span> count = page.getTotal();</span><br></pre></td></tr></table></figure><h3 id="分页操作"><a href="#分页操作" class="headerlink" title="分页操作"></a>分页操作</h3><p>A、只分页不统计(每次只执行分页语句)</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">PageHelper.startPage(pageNum,pageSize);</span><br><span class="line"><span class="comment">//pagelist就是分页之后的结果</span></span><br><span class="line">List&lt;?&gt; pagelist = queryForList( xxx.class, <span class="string">&quot;queryAll&quot;</span> , param);</span><br></pre></td></tr></table></figure><p>B、分页并统计（每次执行2条语句，一条select count语句，一条分页语句）适用于查询分页时数据发生变动，需要将实时的变动信息反映到分页结果上</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Page&lt;?&gt; page = PageHelper.startPage(pageNum,pageSize,iscount);</span><br><span class="line"><span class="comment">//也可以 List&lt;?&gt; pagelist = page.getList();  获取分页后的结果集</span></span><br><span class="line">List&lt;?&gt; pagelist = queryForList( xxx.class , <span class="string">&quot;queryAll&quot;</span> , param);</span><br><span class="line"><span class="keyword">long</span> count = page.getTotal();</span><br></pre></td></tr></table></figure><h3 id="使用PageHelper查全部（不分页）"><a href="#使用PageHelper查全部（不分页）" class="headerlink" title="使用PageHelper查全部（不分页）"></a>使用PageHelper查全部（不分页）</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PageHelper.startPage(<span class="number">1</span>,<span class="number">0</span>);</span><br><span class="line">List&lt;?&gt; alllist = queryForList( xxx.class , <span class="string">&quot;queryAll&quot;</span> , param);</span><br></pre></td></tr></table></figure><h3 id="PageHelper的其他API"><a href="#PageHelper的其他API" class="headerlink" title="PageHelper的其他API"></a>PageHelper的其他API</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">String orderBy = PageHelper.getOrderBy();    <span class="comment">//获取orderBy语句</span></span><br><span class="line">Page&lt;?&gt; page = PageHelper.startPage(Object params);</span><br><span class="line">Page&lt;?&gt; page = PageHelper.startPage(<span class="keyword">int</span> pageNum, <span class="keyword">int</span> pageSize);</span><br><span class="line">Page&lt;?&gt; page = PageHelper.startPage(<span class="keyword">int</span> pageNum, <span class="keyword">int</span> pageSize, <span class="keyword">boolean</span> isCount);</span><br><span class="line">Page&lt;?&gt; page = PageHelper.startPage(pageNum, pageSize, orderBy);</span><br><span class="line">Page&lt;?&gt; page = PageHelper.startPage(pageNum, pageSize, isCount, isReasonable); </span><br></pre></td></tr></table></figure><h3 id="默认值"><a href="#默认值" class="headerlink" title="默认值"></a>默认值</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// RowBounds参数offset作为PageNum使用 - 默认不使用</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">boolean</span> offsetAsPageNum = <span class="keyword">false</span>;</span><br><span class="line"><span class="comment">// RowBounds是否进行count查询 - 默认不查询</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">boolean</span> rowBoundsWithCount = <span class="keyword">false</span>;</span><br><span class="line"><span class="comment">// 当设置为true的时候，如果pagesize设置为0（或RowBounds的limit=0），就不执行分页，返回全部</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">boolean</span> pageSizeZero = <span class="keyword">false</span>;</span><br><span class="line"><span class="comment">// 分页合理化</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">boolean</span> reasonable = <span class="keyword">false</span>;</span><br><span class="line"><span class="comment">// 是否支持接口参数来传递分页参数，默认false</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">boolean</span> supportMethodsArguments = <span class="keyword">false</span>;  </span><br></pre></td></tr></table></figure><h2 id="需要注意的问题"><a href="#需要注意的问题" class="headerlink" title="需要注意的问题"></a>需要注意的问题</h2><p>在使用该插件的时候不要使用最新的，本文使用的是4.1.6的版本，高版本在和mybaits的拦截器集成式会有问题。<br>注意：最新版本的已经不需要复杂的配置，只需要引入依赖包，然后直接使用即可，详情可见官网文档：<a href="https://pagehelper.github.io/">https://pagehelper.github.io/</a></p><h2 id="使用实例"><a href="#使用实例" class="headerlink" title="使用实例"></a>使用实例</h2><p><img src="https://oscimg.oschina.net/oscnet/1d338ab8f7af1024159732468eaea2eb15d.jpg" alt=""><br>这是最简单的应用，在查询日志列表的前面写上：<br>Page<SysLog> pager =PageHelper.<em>startPage</em>(page, limit);<br>传入page当前页，和limit每页数量即可自动分页，无需其他额外的配置，使用方便</p>]]></content>
    
    <summary type="html">
    
      SpringBoot(05)集成使用PageHelper分页插件
    
    </summary>
    
    
      <category term="学微服务" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="Java" scheme="https://www.maxbill.cn/marks/Java/"/>
    
      <category term="SpringBoot" scheme="https://www.maxbill.cn/marks/SpringBoot/"/>
    
      <category term="微服务" scheme="https://www.maxbill.cn/marks/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="Mybatis" scheme="https://www.maxbill.cn/marks/Mybatis/"/>
    
      <category term="PageHelper" scheme="https://www.maxbill.cn/marks/PageHelper/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot(04)集成使用Mybatis操作数据库</title>
    <link href="https://www.maxbill.cn/3894408123.html"/>
    <id>https://www.maxbill.cn/3894408123.html</id>
    <published>2017-03-16T13:14:09.000Z</published>
    <updated>2020-07-04T12:58:29.656Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>前文说了SpringBoot的使用Jpa操作数据库，今天要说是SpringBoot集目前比较受欢迎的持久层框架Mybatis，我个人对mybatis是比较喜欢的，接下来我们在SpringBoot中集成它，我们依旧使用mysql做例子，编写一个简单的用户模块的CRUD的例子。</p><h2 id="项目依赖包的引入"><a href="#项目依赖包的引入" class="headerlink" title="项目依赖包的引入"></a>项目依赖包的引入</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.mybatis.spring.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mybatis-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="配置文件写入配置"><a href="#配置文件写入配置" class="headerlink" title="配置文件写入配置"></a>配置文件写入配置</h2><p>打开项目下的application.yml配置文件，添加以下配置：<br>mybatis:<br>        type-aliases-package: com.maxbill.web.model<br>        mapper-locations: classpath:com/maxbill/web/mapper/*.xml<br>注意：type-aliases-package配置别名扫描包， mapper-locations配置mapper配置文件</p><h2 id="设计数据库表结构"><a href="#设计数据库表结构" class="headerlink" title="设计数据库表结构"></a>设计数据库表结构</h2><p><img src="https://static.oschina.net/uploads/space/2017/0316/194338_ecc7_2846946.png" alt=""></p><h2 id="使用Mybatis-Generator生成相应代码"><a href="#使用Mybatis-Generator生成相应代码" class="headerlink" title="使用Mybatis-Generator生成相应代码"></a>使用Mybatis-Generator生成相应代码</h2><p>我们使用mybatis-generator插件来生成dao层的mapper文件和用户model类；mybatis-generator使用有三种方式：1.命令行，2.eclipse插件，3.maven插件；我们的工程是使用maven构建的，所以我们使用四三种方式：</p><h3 id="在pom中引入mybatis-generator依赖"><a href="#在pom中引入mybatis-generator依赖" class="headerlink" title="在pom中引入mybatis-generator依赖"></a>在pom中引入mybatis-generator依赖</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--mybatis-generator插件--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.mybatis.generator<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mybatis-generator-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.3.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">configurationFile</span>&gt;</span>src/main/resources/mybatis-generator/generatorConfig.xml<span class="tag">&lt;/<span class="name">configurationFile</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">verbose</span>&gt;</span>true<span class="tag">&lt;/<span class="name">verbose</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">overwrite</span>&gt;</span>true<span class="tag">&lt;/<span class="name">overwrite</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.mybatis.generator<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mybatis-generator-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.3.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="修改插件的配置文件"><a href="#修改插件的配置文件" class="headerlink" title="修改插件的配置文件"></a>修改插件的配置文件</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">generatorConfiguration</span></span></span><br><span class="line"><span class="meta">        <span class="meta-keyword">PUBLIC</span> <span class="meta-string">&quot;-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN&quot;</span></span></span><br><span class="line"><span class="meta">        <span class="meta-string">&quot;http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">generatorConfiguration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 数据库驱动包位置 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">classPathEntry</span> <span class="attr">location</span>=<span class="string">&quot;D:\Java\Javafiles\JAR\mysql-connector-java-5.1.7-bin.jar&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">context</span> <span class="attr">id</span>=<span class="string">&quot;DB2Tables&quot;</span> <span class="attr">targetRuntime</span>=<span class="string">&quot;MyBatis3&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">commentGenerator</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;suppressAllComments&quot;</span> <span class="attr">value</span>=<span class="string">&quot;true&quot;</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">commentGenerator</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">jdbcConnection</span></span></span><br><span class="line"><span class="tag">                <span class="attr">driverClass</span>=<span class="string">&quot;com.mysql.jdbc.Driver&quot;</span></span></span><br><span class="line"><span class="tag">                <span class="attr">connectionURL</span>=<span class="string">&quot;jdbc:mysql://127.0.0.1:3306/blog&quot;</span></span></span><br><span class="line"><span class="tag">                <span class="attr">userId</span>=<span class="string">&quot;root&quot;</span></span></span><br><span class="line"><span class="tag">                <span class="attr">password</span>=<span class="string">&quot;admin&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">jdbcConnection</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">javaTypeResolver</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;forceBigDecimals&quot;</span> <span class="attr">value</span>=<span class="string">&quot;false&quot;</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">javaTypeResolver</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- 生成模型的包名和位置 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">javaModelGenerator</span> <span class="attr">targetPackage</span>=<span class="string">&quot;com.maxbill.web.model&quot;</span> <span class="attr">targetProject</span>=<span class="string">&quot;d:\Data&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;enableSubPackages&quot;</span> <span class="attr">value</span>=<span class="string">&quot;true&quot;</span>/&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;trimStrings&quot;</span> <span class="attr">value</span>=<span class="string">&quot;true&quot;</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">javaModelGenerator</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- 生成的映射文件包名和位置 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">sqlMapGenerator</span> <span class="attr">targetPackage</span>=<span class="string">&quot;com.maxbill.web.mapper&quot;</span> <span class="attr">targetProject</span>=<span class="string">&quot;d:\Data&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;enableSubPackages&quot;</span> <span class="attr">value</span>=<span class="string">&quot;true&quot;</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">sqlMapGenerator</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- 生成DAO的包名和位置 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">javaClientGenerator</span> <span class="attr">type</span>=<span class="string">&quot;XMLMAPPER&quot;</span> <span class="attr">targetPackage</span>=<span class="string">&quot;com.maxbill.web.mapper&quot;</span> </span></span><br><span class="line"><span class="tag">                             <span class="attr">targetProject</span>=<span class="string">&quot;d:\Data&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;enableSubPackages&quot;</span> <span class="attr">value</span>=<span class="string">&quot;true&quot;</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">javaClientGenerator</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">table</span> <span class="attr">tableName</span>=<span class="string">&quot;s_user&quot;</span> <span class="attr">domainObjectName</span>=<span class="string">&quot;User&quot;</span> <span class="attr">enableCountByExample</span>=<span class="string">&quot;true&quot;</span> </span></span><br><span class="line"><span class="tag">               <span class="attr">enableUpdateByExample</span>=<span class="string">&quot;true&quot;</span></span></span><br><span class="line"><span class="tag">               <span class="attr">enableDeleteByExample</span>=<span class="string">&quot;true&quot;</span> </span></span><br><span class="line"><span class="tag">               <span class="attr">enableSelectByExample</span>=<span class="string">&quot;true&quot;</span> </span></span><br><span class="line"><span class="tag">               <span class="attr">selectByExampleQueryId</span>=<span class="string">&quot;true&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">context</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">generatorConfiguration</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="使用maven命令生成代码"><a href="#使用maven命令生成代码" class="headerlink" title="使用maven命令生成代码"></a>使用maven命令生成代码</h3><p><img src="https://static.oschina.net/uploads/space/2017/0316/201635_BiUw_2846946.png" alt=""><br>看到以下的输出日志，编译成功！  </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">[INFO] Scanning for projects...</span><br><span class="line">[INFO]                                                                         </span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Building boot 0.0.1-SNAPSHOT</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- mybatis-generator-maven-plugin:1.3.5:generate (default-cli) @ boot ---</span><br><span class="line">[INFO] Connecting to the Database</span><br><span class="line">[INFO] Introspecting table s_user</span><br><span class="line">[INFO] Generating Example class for table s_user</span><br><span class="line">[INFO] Generating Record class for table s_user</span><br><span class="line">[INFO] Generating Mapper Interface for table s_user</span><br><span class="line">[INFO] Generating SQL Map for table s_user</span><br><span class="line">[INFO] Saving file UserMapper.xml</span><br><span class="line">[INFO] Saving file UserExample.java</span><br><span class="line">[INFO] Saving file User.java</span><br><span class="line">[INFO] Saving file UserMapper.java</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 1.922 s</span><br><span class="line">[INFO] Finished at: 2017-03-16T20:16:47+08:00</span><br><span class="line">[INFO] Final Memory: 12M/155M</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br></pre></td></tr></table></figure><p>打开磁盘目录我们看到已经生成了我们需要的文件。<br>注意：mybatis-generator有人开发了gui版，github地址：<a href="https://github.com/astarring/mybatis-generator-gui，需要的可以使用gui版：">https://github.com/astarring/mybatis-generator-gui，需要的可以使用gui版：</a><br><img src="https://static.oschina.net/uploads/img/201703/23104845_D4p3.png" alt=""></p><h3 id="编写service层逻辑代码"><a href="#编写service层逻辑代码" class="headerlink" title="编写service层逻辑代码"></a>编写service层逻辑代码</h3><p>用户service接口</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.maxbill.base.service;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.maxbill.base.model.User;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">UserService</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">saveUser</span><span class="params">(User user)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">deleteUser</span><span class="params">(String userid)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">deleteUser</span><span class="params">(User user)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function">User <span class="title">findUserById</span><span class="params">(String userid)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>用户service实现类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.maxbill.base.service.impl;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.maxbill.base.mapper.UserMapper;</span><br><span class="line"><span class="keyword">import</span> com.maxbill.base.model.User;</span><br><span class="line"><span class="keyword">import</span> com.maxbill.base.service.UserService;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@func</span> 用户模块业务逻辑实现层</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@user</span> MaxBill</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2017-03-15</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@mail</span> 1370581389@qq.com</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserServiceImpl</span> <span class="keyword">implements</span> <span class="title">UserService</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> UserMapper userMapper;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 添加用户</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">saveUser</span><span class="params">(User user)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.userMapper.insertSelective(user);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 删除用户</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">deleteUser</span><span class="params">(String userid)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.userMapper.deleteByPrimaryKey(userid);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 更新用户</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">updateUser</span><span class="params">(User user)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.userMapper.updateByPrimaryKeySelective(user);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 按id查新用户</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> User <span class="title">findUserById</span><span class="params">(String userid)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.userMapper.selectByPrimaryKey(userid);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编写用户控制器接口方法，和上一章中一样，这里不再赘述。</p><h3 id="在启动器中添加mapper扫描"><a href="#在启动器中添加mapper扫描" class="headerlink" title="在启动器中添加mapper扫描"></a>在启动器中添加mapper扫描</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.maxbill;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.mybatis.spring.annotation.MapperScan;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.SpringApplication;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.autoconfigure.SpringBootApplication;</span><br><span class="line"></span><br><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="meta">@MapperScan(&quot;com.maxbill.web.mapper&quot;)</span><span class="comment">//扫描mapper</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BootApplication</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String\[\] args)</span> </span>&#123;</span><br><span class="line">        SpringApplication.run(BootApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>启动项目，测试各接口都正常。<br>以上就是Spring Boot集成Mybatis对数据库的数据的CRUD操作。下一篇主要说一下集成pagehelper分页插件。</p>]]></content>
    
    <summary type="html">
    
      SpringBoot(04)集成使用Mybatis操作数据库
    
    </summary>
    
    
      <category term="学微服务" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="Java" scheme="https://www.maxbill.cn/marks/Java/"/>
    
      <category term="SpringBoot" scheme="https://www.maxbill.cn/marks/SpringBoot/"/>
    
      <category term="微服务" scheme="https://www.maxbill.cn/marks/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="Mybatis" scheme="https://www.maxbill.cn/marks/Mybatis/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot(03)集成使用Jpa操作数据库</title>
    <link href="https://www.maxbill.cn/7158715340.html"/>
    <id>https://www.maxbill.cn/7158715340.html</id>
    <published>2017-03-12T05:03:03.000Z</published>
    <updated>2020-07-04T12:58:29.656Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>前文说了SpringBoot的编写的的第一个应用HelloWorld，是通过restful接口向客户端返回了含有HelloWorld的Json串，接下来要说的是使用SpringBoot+Jpa操作数据库。我们使用Jpa操作mysql数据库，将会以一个简单的用户模块来做例子实现Spring Boot+Jpa对数据库的CRUD操作。</p><h2 id="项目依赖包的引入"><a href="#项目依赖包的引入" class="headerlink" title="项目依赖包的引入"></a>项目依赖包的引入</h2><p>我们要使用Jpa操作数据库，首先要在项目中引入Jpa的依赖包：<br><dependency><br>        <groupId>org.springframework.boot</groupId><br>        <artifactId>spring-boot-starter-data-jpa</artifactId><br></dependency><br>然后使用mysql数据库，需要引入mysql的驱动依赖包：<br><dependency><br>        <groupId>mysql</groupId><br>        <artifactId>mysql-connector-java</artifactId><br></dependency><br> 注意：如果引入最新的mysql依赖包需要在数据库连接地址加入serverTimezone时间参数：serverTimezone=UTC，否则连接数据库时会报错的。</p><h2 id="配置数据源和Jpa属性"><a href="#配置数据源和Jpa属性" class="headerlink" title="配置数据源和Jpa属性"></a>配置数据源和Jpa属性</h2><p>在application.yml配置文件中配置mysql数据源及数据库的信息：<br><img src="https://static.oschina.net/uploads/space/2017/0312/115009_hDSN_2846946.png" alt=""><br>注意：以上数据库信息是我个人本地数据库配置信息，大家根据需求改成自己的即可<br>在application.yml配置文件中配置Jpa属性：<br><img src="https://static.oschina.net/uploads/space/2017/0312/115302_ssyK_2846946.png" alt=""></p><h2 id="新建用户模型映射生成数据库表"><a href="#新建用户模型映射生成数据库表" class="headerlink" title="新建用户模型映射生成数据库表"></a>新建用户模型映射生成数据库表</h2><p>新建User用户实体类，生成setter和getter方法，增加实体和主键注解：<br><img src="https://static.oschina.net/uploads/space/2017/0312/115802_TAhQ_2846946.png" alt=""><br>注意：以上是作为作为一个简单的用户某块的例子，实际按自己的业务需求来<br><img src="https://static.oschina.net/uploads/space/2017/0312/120414_euig_2846946.png" alt=""><br>运行项目后，数据库会多出一个user的数据表，即说明配置成功</p><h2 id="编写持久层接口"><a href="#编写持久层接口" class="headerlink" title="编写持久层接口"></a>编写持久层接口</h2><p><img src="https://static.oschina.net/uploads/space/2017/0312/120946_WyCv_2846946.png" alt=""></p><h2 id="编写业务层接口和实现"><a href="#编写业务层接口和实现" class="headerlink" title="编写业务层接口和实现"></a>编写业务层接口和实现</h2><p>用户模块业务层接口<br><img src="https://static.oschina.net/uploads/space/2017/0312/121433_r1tg_2846946.png" alt=""><br>用户模块业务层实现<br><img src="https://static.oschina.net/uploads/space/2017/0312/121703_59Ku_2846946.png" alt=""></p><h2 id="编写用户模块主控制器"><a href="#编写用户模块主控制器" class="headerlink" title="编写用户模块主控制器"></a>编写用户模块主控制器</h2><p>下面编写用户控制器，实现CRUD:使用RESTFUL风格<br><img src="https://static.oschina.net/uploads/space/2017/0312/122843_exhk_2846946.png" alt=""></p><h3 id="增加用户（POST表单提交）"><a href="#增加用户（POST表单提交）" class="headerlink" title="增加用户（POST表单提交）"></a>增加用户（POST表单提交）</h3><p><img src="https://static.oschina.net/uploads/space/2017/0312/122954_Jd3k_2846946.png" alt=""><br>启动项目在postman中测试接口：<br><img src="https://static.oschina.net/uploads/space/2017/0312/123303_2aL3_2846946.png" alt=""><br>数据库中数据变化：<br><img src="https://static.oschina.net/uploads/space/2017/0312/123504_61vm_2846946.png" alt=""><br>请求成功，Jpa返回添加成功的对象通过rest接口返回json串数据，插件数据库，数据库中也增加了词条数据。</p><h3 id="获取用户列表（GET）"><a href="#获取用户列表（GET）" class="headerlink" title="获取用户列表（GET）"></a>获取用户列表（GET）</h3><p><img src="https://static.oschina.net/uploads/space/2017/0312/123835_Af6a_2846946.png" alt=""><br>注意：为测试测接口，在数据库有多加了两条数据，数据库变化如下：<br><img src="https://static.oschina.net/uploads/space/2017/0312/124044_J750_2846946.png" alt=""><br>启动项目在postman中测试接口：<img src="https://static.oschina.net/uploads/space/2017/0312/124223_ccml_2846946.png" alt=""><br>请求成功，Jpa返回用户列表，数据完全正确。</p><h3 id="查询一个用户（GET）"><a href="#查询一个用户（GET）" class="headerlink" title="查询一个用户（GET）"></a>查询一个用户（GET）</h3><p><img src="https://static.oschina.net/uploads/space/2017/0312/125108_Tjc9_2846946.png" alt=""><br>启动项目在postman中测试接口：<br><img src="https://static.oschina.net/uploads/space/2017/0312/125037_IRnp_2846946.png" alt=""></p><h3 id="更新用户信息（PUT）"><a href="#更新用户信息（PUT）" class="headerlink" title="更新用户信息（PUT）"></a>更新用户信息（PUT）</h3><p><img src="https://static.oschina.net/uploads/space/2017/0312/125508_UDN3_2846946.png" alt=""><br>启动项目在postman中测试接口：<br><img src="https://static.oschina.net/uploads/space/2017/0312/125448_FUkL_2846946.png" alt=""><br>请求成功。数据库数据变化如下：<br><img src="https://static.oschina.net/uploads/space/2017/0312/125623_6aQM_2846946.png" alt=""></p><h3 id="删除用户信息（DELETE）"><a href="#删除用户信息（DELETE）" class="headerlink" title="删除用户信息（DELETE）"></a>删除用户信息（DELETE）</h3><p><img src="https://static.oschina.net/uploads/space/2017/0312/125931_lHUi_2846946.png" alt=""><br>启动项目在postman中测试接口：<br><img src="https://static.oschina.net/uploads/space/2017/0312/125917_U6EJ_2846946.png" alt=""><br>请求成功。数据库数据变化如下：<br><img src="https://static.oschina.net/uploads/space/2017/0312/130039_idtd_2846946.png" alt=""><br>以上就是Spring Boot+Jpa对数据库的数据的CRUD操作，后面会对Jpa操作数据库做更深的讲解，下一节将换一种方式操作数据库，使用mybatis持久层和Spring Boot整合操作数据库。</p>]]></content>
    
    <summary type="html">
    
      SpringBoot(03)集成使用Jpa操作数据库
    
    </summary>
    
    
      <category term="学微服务" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="Java" scheme="https://www.maxbill.cn/marks/Java/"/>
    
      <category term="SpringBoot" scheme="https://www.maxbill.cn/marks/SpringBoot/"/>
    
      <category term="微服务" scheme="https://www.maxbill.cn/marks/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="Jpa" scheme="https://www.maxbill.cn/marks/Jpa/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot(02)第一个程序及项目结构介绍</title>
    <link href="https://www.maxbill.cn/9635160200.html"/>
    <id>https://www.maxbill.cn/9635160200.html</id>
    <published>2017-03-10T12:44:03.000Z</published>
    <updated>2020-07-04T12:58:29.661Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>上一篇我们介绍了SpringBoot项目的环境搭建和在idea下项目的创建过程，今天要说的是SpringBoot项目的下的第一个程序HelloWorld，及SpringBoot项目结构的分析。</p><p>首先打开Spring Boot初始项目：<br><img src="https://static.oschina.net/uploads/space/2017/0310/193202_lyFm_2846946.png" alt=""><br>删除暂时不用的目录.mvn以及git配置忽略文件.gitignore、maven的mvnw和mvnw.cmd文件；展开项目目录如下：<br><img src="https://static.oschina.net/uploads/space/2017/0310/193823_kEx6_2846946.png" alt=""></p><h2 id="项目目录说明"><a href="#项目目录说明" class="headerlink" title="项目目录说明"></a>项目目录说明</h2><p>下面先就项目目录做说明：src目录下是main和test，main是后面我们主要用到的目录，使我们源码的编写目录，test目录是我们做单元测试的目录；main目录下包含java和resources，java目录就是写java源代码的目录，resources是放置配置文件和页面静态资源文件的目录；展开resources目录包含static和templates目录，static是spring boot默认的静态资源目录，templates是默认的页面模板放置目录。</p><p>java文件下默认创建了Spring Boot的启动类BootApplication，注释了@SpringBootApplication，后面的章节我们会专门分析Spring Boot的注释，启动类是包含一个Main方法，也是Spring Boot应用的启动入口，如下：<br><img src="https://static.oschina.net/uploads/space/2017/0310/195550_j22O_2846946.png" alt=""><br>resources下的application.properties是项目的配置文件我们以后不使用它，而是采用支持YAML语法的application.yml配置文件，可读性非常高，将properties文件换成yml文件，并且在yml文件中做一些基本的配置，如下：<br><img src="https://static.oschina.net/uploads/space/2017/0310/200433_GStc_2846946.png" alt=""><br>server是对服务器的信息的配置，本例配置了服务器的端口是80，地址是本机地址127.0.0.1，项目content目录是rest，待会通过启动后访问即可明白配置。</p><h2 id="SpringBoot的Maven文件依赖说明"><a href="#SpringBoot的Maven文件依赖说明" class="headerlink" title="SpringBoot的Maven文件依赖说明"></a>SpringBoot的Maven文件依赖说明</h2><p>打开项目目录下的pom.xml文件，此文件是maven构建项目的配置文件，里面定义了项目的基本信息，及依赖、插件等信息，对Maven不熟悉的同学可以先看看maven的相关知识。<br><img src="https://static.oschina.net/uploads/space/2017/0310/201524_U8Fg_2846946.png" alt=""><br>以上是项目的基本信息以及pringboot官方推荐我们使用<a href="http://lib.csdn.net/base/javaee">spring</a>-boot-starter-parent的依赖，spring-boot-starter-parent包含了以下信息：<br>1、定义了jdk编译级别<br>2、使用utf-8编码<br>3、实现了通用的测试框架junit<br>4、智能资源过滤<br>5、智能的插件配置<br><img src="https://static.oschina.net/uploads/space/2017/0310/201840_peFn_2846946.png" alt=""><br>以上是项目初始的主要依赖，还记得上一篇文中在创建项目时我们勾选了web和devtools依赖，这里就在pom计入了相关依赖，test是单元测试依赖，我们后面需要什么依赖直接在pom文件加入依赖即可。<br><img src="https://static.oschina.net/uploads/space/2017/0310/202144_jfyC_2846946.png" alt=""><br>以上是maven编译需要的spring boot编译插件：spring-boot-maven-plugin</p><h2 id="第一个SpringBoot项目之HelloWorld"><a href="#第一个SpringBoot项目之HelloWorld" class="headerlink" title="第一个SpringBoot项目之HelloWorld"></a>第一个SpringBoot项目之HelloWorld</h2><p>我们创建一个控制器，编写我们的第一个Spring Boot应用，创建主控制器，编写一个restful接口测试返回Hello World到页面，控制器如下：<br><img src="https://static.oschina.net/uploads/space/2017/0310/203351_Mjqi_2846946.png" alt=""><br>接下来我们启动程序，如下在控制台输出启动信息：<br><img src="https://static.oschina.net/uploads/space/2017/0310/203731_JZnI_2846946.png" alt=""><br>从启动输出信息可以看到我们在配置文件配置的端口是80 生效的，接下来我们在浏览器验证是否能看到输出hello world信息：<br><img src="https://static.oschina.net/uploads/space/2017/0310/203936_ommC_2846946.png" alt=""><br>通过访问项目我们发现成功输出，并且配置的80端口和rest上下文路径也生效，第一个简单的Spring Boot应用到这就实现了。下一篇将会讲解Spring Boot+jpa实现对数据库的操作。</p>]]></content>
    
    <summary type="html">
    
      SpringBoot(02)第一个程序及项目结构介绍
    
    </summary>
    
    
      <category term="学微服务" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="Java" scheme="https://www.maxbill.cn/marks/Java/"/>
    
      <category term="SpringBoot" scheme="https://www.maxbill.cn/marks/SpringBoot/"/>
    
      <category term="Idea" scheme="https://www.maxbill.cn/marks/Idea/"/>
    
      <category term="微服务" scheme="https://www.maxbill.cn/marks/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot(01)开发环境搭建及概念叙述</title>
    <link href="https://www.maxbill.cn/3443749227.html"/>
    <id>https://www.maxbill.cn/3443749227.html</id>
    <published>2017-03-08T14:28:03.000Z</published>
    <updated>2020-07-04T12:58:29.656Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p> 最近刚刚开始学习SpringBoot框架，在此记录自己的学习过程，记录自己在学习过程中遇到的坑，以及解决问题的过程，有不对的地方请各位批评指正,开始环境搭建之前先说说一些基本的概念：</p><h2 id="什么是SpringBoot"><a href="#什么是SpringBoot" class="headerlink" title="什么是SpringBoot"></a>什么是SpringBoot</h2><p>SpringBoot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。我个人初始接触SpringBoot最大的感觉就是SpringBoot能快速构建项目、极大的避免编写之前Spring开发的各种繁琐复杂的XML配置文件，给人一种简单粗暴的感觉。之前使用Servlet+jdbc的开发方式，进行一个模块的CRUD操作需要编写很多代码以及一些XML配置才能实现，而且需要一定的时间。使用SpringBoot+jpa的操作使用相对熟练点在20分钟之内编写一个小模块的CRUD是完全不是问题的。</p><h2 id="什么是微服务架构"><a href="#什么是微服务架构" class="headerlink" title="什么是微服务架构"></a>什么是微服务架构</h2><p>微服务的基本思想在于考虑围绕着业务领域组件来创建应用，这些就应用可独立地进行开发、管理和加速。在分散的组件中使用微服务云架构和平台使部署、管理和服务功能交付变得更加简单。其实我个人理解就是：微服务和传统的项目相比是将大的项目按业务需求和模块划分成各子模块成为相对独立的组件，将每个模块分开部署到云服务器中，使用相互消息通信的方式配合，说白了就是分布式，而且更加便于开发和维护。</p><h2 id="开发环境搭建"><a href="#开发环境搭建" class="headerlink" title="开发环境搭建"></a>开发环境搭建</h2><p>自己还在摸索学习的过程中，目前接触SpringBoot是深深的吸引了我，不说太多，更多的功能和优点慢慢的在以后的博文中一点一点涉及，今天先来进行基础的环境搭建。接下来开始基本的环境搭建：<br>1.Jdk安装与配置<br>2.选择适合自己的ide环境（本人使用的是idea）<br>3.Maven环境配置<br>以上你三个步骤都是很基础的，可以自己百度，有问题也可留言问我。<br>4.创建第一个SpringBoot应用：<br>创建springboot应用，选择spring initializr<br><img src="https://static.oschina.net/uploads/space/2017/0308/221159_9moe_2846946.png" alt=""><br>next，可能会由于网络原因出现以下问题，多尝试下，或者换好点的网络环境，或者使用代理服务器<br><img src="https://static.oschina.net/uploads/space/2017/0308/221601_CbVK_2846946.png" alt=""><br>如果没问题会到项目配置界面<br><img src="https://static.oschina.net/uploads/space/2017/0308/222038_Nkuc_2846946.png" alt=""><br>填写好项目基本信息就可以下一步到项目依赖组件选择<br><img src="https://static.oschina.net/uploads/space/2017/0308/222217_cnV9_2846946.png" alt=""><br>我们这里选择web和开发工具依赖，后期需要其他的可以通过pom文件增加依赖即可<br><img src="https://static.oschina.net/uploads/space/2017/0308/222316_Ha8a_2846946.png" alt=""><br>选择完项目依赖下一步就到了项目开发路径的配置（就是项目文件在本地磁盘的位置等信息）配置完成以后即可点击finish完成项目创建。<br>这样我们就创建好了第一个SpringBoot项目，下一篇我们将介绍SpringBoot编写Hello World ，并介绍项目的结构的一些基本信息。</p>]]></content>
    
    <summary type="html">
    
      SpringBoot(01)开发环境搭建及概念叙述
    
    </summary>
    
    
      <category term="学微服务" scheme="https://www.maxbill.cn/kinds/%E5%AD%A6%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
      <category term="Java" scheme="https://www.maxbill.cn/marks/Java/"/>
    
      <category term="SpringBoot" scheme="https://www.maxbill.cn/marks/SpringBoot/"/>
    
      <category term="Idea" scheme="https://www.maxbill.cn/marks/Idea/"/>
    
      <category term="微服务" scheme="https://www.maxbill.cn/marks/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
</feed>
